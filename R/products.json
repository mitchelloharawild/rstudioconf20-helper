{"admissionItems":{"e05b84ea-11dd-4252-82c3-597e5444811c":{"limitOptionalItemsToSelect":false,"isOpenForRegistration":true,"includeWaitlistSessionsTowardsMaximumLimit":false,"applicableContactTypes":["2ca4373b-d99e-467e-adbd-99afea225a86","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"limitOptionalSessionsToSelect":true,"associatedOptionalSessions":[],"applicableOptionalItems":[],"minimumNumberOfSessionsToSelect":1,"maximumNumberOfSessionsToSelect":1,"availableOptionalSessions":["5eae945f-2285-44fb-ae67-1a9e8c74b4c6","6ebe4d66-1a7e-4f69-9665-204c61f9d920","5de2683c-bb4d-46b5-8415-24556b46d105","bf7a9b49-cfcd-437d-a992-45359714bdff","5ebec1c3-9bf6-411d-8339-5b00db5c200b","de26c627-2d43-46fe-89c9-60ae17ea97e4","98251367-affe-4d4f-b30a-678291d4bb50","a76ade59-68e4-4325-9d3b-6e7f0375af3c","cf7b4ef5-4280-414e-9389-7d23eb8c0367","cab92973-3018-48e8-afba-7f21ce41d662","ac2b3992-fbfc-45d1-ac8a-8946719b5bfc","971192eb-91b7-4882-aa64-90b45dc58d1b","c49e47f4-0a47-4934-b786-ab914840a460","fd78d01e-f85c-458d-9e47-b65bc02cc1a9","a556e0c4-c3d8-41b7-a947-bd1f291b77f0","4ba63dde-c0aa-4d2a-8172-c839c49d7dca","8bfe8930-02b0-42bd-95f8-d39974cd159c","b68c60bd-4f3f-423b-aec5-d6fa140187fd","c45f84a9-65a5-4c33-ba42-fe3a8f2291c4"],"displayOrder":1,"code":"Workshop Only","description":"","id":"e05b84ea-11dd-4252-82c3-597e5444811c","capacityId":"e05b84ea-11dd-4252-82c3-597e5444811c","name":"Workshop Only","status":2,"type":"AdmissionItem","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"2110fa36-d6e6-4c1f-9258-d4ec89dc381d":{"limitOptionalItemsToSelect":false,"isOpenForRegistration":true,"includeWaitlistSessionsTowardsMaximumLimit":false,"applicableContactTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"limitOptionalSessionsToSelect":true,"associatedOptionalSessions":[],"applicableOptionalItems":[],"minimumNumberOfSessionsToSelect":0,"availableOptionalSessions":["5eae945f-2285-44fb-ae67-1a9e8c74b4c6","6ebe4d66-1a7e-4f69-9665-204c61f9d920","5de2683c-bb4d-46b5-8415-24556b46d105","bf7a9b49-cfcd-437d-a992-45359714bdff","5ebec1c3-9bf6-411d-8339-5b00db5c200b","de26c627-2d43-46fe-89c9-60ae17ea97e4","98251367-affe-4d4f-b30a-678291d4bb50","a76ade59-68e4-4325-9d3b-6e7f0375af3c","cf7b4ef5-4280-414e-9389-7d23eb8c0367","cab92973-3018-48e8-afba-7f21ce41d662","ac2b3992-fbfc-45d1-ac8a-8946719b5bfc","971192eb-91b7-4882-aa64-90b45dc58d1b","c49e47f4-0a47-4934-b786-ab914840a460","fd78d01e-f85c-458d-9e47-b65bc02cc1a9","a556e0c4-c3d8-41b7-a947-bd1f291b77f0","4ba63dde-c0aa-4d2a-8172-c839c49d7dca","8bfe8930-02b0-42bd-95f8-d39974cd159c","b68c60bd-4f3f-423b-aec5-d6fa140187fd","d7ada4ff-3ef8-4ea7-aa0a-e533d7c1f9f5","c45f84a9-65a5-4c33-ba42-fe3a8f2291c4"],"displayOrder":2,"code":"Conference + Workshop","description":"This is registration for both the conference and a workshop.","id":"2110fa36-d6e6-4c1f-9258-d4ec89dc381d","autoCloseDate":"2020-01-29T08:00:00.000Z","capacityId":"2110fa36-d6e6-4c1f-9258-d4ec89dc381d","name":"Conference + Workshop","status":2,"type":"AdmissionItem","defaultFeeId":"ed0072c1-3c21-4c9d-ab4d-0e743d8c009e","fees":{"ed0072c1-3c21-4c9d-ab4d-0e743d8c009e":{"chargePolicies":[{"maximumRefundAmount":895.0,"id":"dd3f7584-eeb2-4e1c-bf7b-9660b327fc74","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":895.0,"isBeforeCurrentDate":false},{"maximumRefundAmount":595.0,"id":"59afe54f-af3a-4bb6-83a0-6f689968fb84","isActive":true,"effectiveUntil":"2019-08-31T00:00:00.000Z","amount":595.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"fbc0a9b3-70dc-4734-bcda-2f1eed43862e","isActive":false,"effectiveUntil":"2019-12-31T00:00:00.000Z","isBeforeCurrentDate":false},{"refundType":4,"percentage":100.0,"id":"8915d52e-c34d-4a59-8df5-88a9192952e8","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0","3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Conference & Workshop","id":"ed0072c1-3c21-4c9d-ab4d-0e743d8c009e","amount":895.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"7b6e0f3f-39f2-4eb9-8ae5-7b9dcee0207f":{"limitOptionalItemsToSelect":false,"isOpenForRegistration":true,"includeWaitlistSessionsTowardsMaximumLimit":true,"applicableContactTypes":["1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9"],"limitOptionalSessionsToSelect":true,"associatedOptionalSessions":[],"applicableOptionalItems":[],"minimumNumberOfSessionsToSelect":0,"availableOptionalSessions":["d7ada4ff-3ef8-4ea7-aa0a-e533d7c1f9f5"],"displayOrder":5,"code":"Conference Only Registration","description":"","id":"7b6e0f3f-39f2-4eb9-8ae5-7b9dcee0207f","capacityId":"7b6e0f3f-39f2-4eb9-8ae5-7b9dcee0207f","name":"Conference Only Registration","status":2,"type":"AdmissionItem","defaultFeeId":"9e6a5f14-d1fd-44d2-9de5-372f86cb61b1","fees":{"9e6a5f14-d1fd-44d2-9de5-372f86cb61b1":{"chargePolicies":[{"maximumRefundAmount":450.0,"id":"41f62e92-2297-4f5a-aaba-d635697fca48","isActive":false,"effectiveUntil":"2019-02-28T00:00:00.000Z","amount":450.0,"isBeforeCurrentDate":false},{"maximumRefundAmount":895.0,"id":"7ab0e8b0-297e-43a3-9aa8-5123c647c3f3","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":895.0,"isBeforeCurrentDate":false},{"maximumRefundAmount":595.0,"id":"944d6db9-68fe-437a-8560-0ce0fc617831","isActive":true,"effectiveUntil":"2019-08-31T00:00:00.000Z","amount":595.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"7402b207-a68c-441f-92f3-a0066ff78a00","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":false,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Conference Registration","id":"9e6a5f14-d1fd-44d2-9de5-372f86cb61b1","amount":895.0,"glCodes":[{"glCodeId":"39febde6-8318-4bb6-a1f3-2530a9c13436","allocationPercentage":100}]}},"closedReasonType":"NotClosed"},"c5ec0e9e-6397-47f5-a6ee-2bc6ee404a9d":{"limitOptionalItemsToSelect":false,"isOpenForRegistration":true,"includeWaitlistSessionsTowardsMaximumLimit":true,"applicableContactTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"limitOptionalSessionsToSelect":true,"associatedOptionalSessions":[],"applicableOptionalItems":[],"minimumNumberOfSessionsToSelect":0,"availableOptionalSessions":["5eae945f-2285-44fb-ae67-1a9e8c74b4c6","6ebe4d66-1a7e-4f69-9665-204c61f9d920","5de2683c-bb4d-46b5-8415-24556b46d105","bf7a9b49-cfcd-437d-a992-45359714bdff","5ebec1c3-9bf6-411d-8339-5b00db5c200b","de26c627-2d43-46fe-89c9-60ae17ea97e4","98251367-affe-4d4f-b30a-678291d4bb50","a76ade59-68e4-4325-9d3b-6e7f0375af3c","cf7b4ef5-4280-414e-9389-7d23eb8c0367","cab92973-3018-48e8-afba-7f21ce41d662","ac2b3992-fbfc-45d1-ac8a-8946719b5bfc","971192eb-91b7-4882-aa64-90b45dc58d1b","c49e47f4-0a47-4934-b786-ab914840a460","fd78d01e-f85c-458d-9e47-b65bc02cc1a9","a556e0c4-c3d8-41b7-a947-bd1f291b77f0","4ba63dde-c0aa-4d2a-8172-c839c49d7dca","8bfe8930-02b0-42bd-95f8-d39974cd159c","b68c60bd-4f3f-423b-aec5-d6fa140187fd","d7ada4ff-3ef8-4ea7-aa0a-e533d7c1f9f5","c45f84a9-65a5-4c33-ba42-fe3a8f2291c4"],"displayOrder":6,"code":"Academic","description":"Your email registration must include an identifiable academic institution. RStudio reserves the right to cancel any registration without proof of academic credentials.","id":"c5ec0e9e-6397-47f5-a6ee-2bc6ee404a9d","capacityId":"c5ec0e9e-6397-47f5-a6ee-2bc6ee404a9d","name":"Academic","status":3,"type":"AdmissionItem","defaultFeeId":"b668bf4b-47cc-4f8e-8096-23cbbb51ccd7","fees":{"b668bf4b-47cc-4f8e-8096-23cbbb51ccd7":{"chargePolicies":[{"maximumRefundAmount":495.0,"id":"7fe3e329-d4d1-4f3e-aa1f-401bc2ce03ec","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":495.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"6d99fe38-b70e-4036-9264-e202eeefb0ff","isActive":true,"effectiveUntil":"2019-08-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Fee","id":"b668bf4b-47cc-4f8e-8096-23cbbb51ccd7","amount":495.0,"glCodes":[{"glCodeId":"d93390fb-dfb2-43c3-92a8-f079f347e5f1","allocationPercentage":100}]}},"closedReasonType":"ByCapacity"}},"sessionProducts":{"cf7b4ef5-4280-414e-9389-7d23eb8c0367":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"cf7b4ef5-4280-414e-9389-7d23eb8c0367_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2clii\",\"text\":\"It is becoming increasingly common for organizations to collect huge amounts of data over time, and existing time series analysis tools are not always suitable to handle the scale, frequency and structure of the data collected. In this workshop, we will look at some new packages and methods that have been developed to handle the analysis of large collections of time series.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9sg8o\",\"text\":\"On day 1, we will look at the tsibble data structure for flexibly managing collections of related time series. We will look at how to do data wrangling, data visualizations and exploratory data analysis.  We will explore feature-based methods to explore time series data in high dimensions. A similar feature-based approach can be used to identify anomalous time series within a collection of time series, or to cluster or classify time series Primary packages for day 1 will be tsibble, lubridate and feast (along with the tidyverse of course).   \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"98v8d\",\"text\":\"Day 2 will be about forecasting. We will look at some classical time series models and how they are automated in the fable package. We will look at creating ensemble forecasts and hybrid forecasts, as well as some new forecasting methods that have performed well in large-scale forecasting competitions.  Finally, we will look at forecast reconciliation, allowing millions of time series to be forecast in a relatively short time while accounting for constraints on how the series are related.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"qmhf\",\"text\":\"This course will be appropriate for you if you answer yes to these questions:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":77,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"fgdq8\",\"text\":\"Do you already use the tidyverse packages in R such as dplyr, tidyr, tibble and ggplot2?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":88,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8du7n\",\"text\":\"Do you need to analyse large collections of related time series?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":64,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"e5str\",\"text\":\"Would you like to learn how to use some new tidy tools for time series analysis including visualization, decomposition and forecasting?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":135,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d48fc2af-1487-4fae-900a-8d95513f1eb5":{"speakerId":"d48fc2af-1487-4fae-900a-8d95513f1eb5","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"cf7b4ef5-4280-414e-9389-7d23eb8c0367"}},"code":"Workshop1237","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">It is becoming increasingly common for organizations to collect huge amounts of data over time, and existing time series analysis tools are not always suitable to handle the scale, frequency and structure of the data collected. In this workshop, we will look at some new packages and methods that have been developed to handle the analysis of large collections of time series.&nbsp;&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">On day 1, we will look at the tsibble data structure for flexibly managing collections of related time series. We will look at how to do data wrangling, data visualizations and exploratory data analysis.&nbsp; We will explore feature-based methods to explore time series data in high dimensions. A similar feature-based approach can be used to identify anomalous time series within a collection of time series, or to cluster or classify time series Primary packages for day 1 will be tsibble, lubridate and feast (along with the tidyverse of course).&nbsp; &nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Day 2 will be about forecasting. We will look at some classical time series models and how they are automated in the fable package. We will look at creating ensemble forecasts and hybrid forecasts, as well as some new forecasting methods that have performed well in large-scale forecasting competitions.&nbsp; Finally, we will look at forecast reconciliation, allowing millions of time series to be forecast in a relatively short time while accounting for constraints on how the series are related.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This course will be appropriate for you if you answer yes to these questions:</span></p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li><span style=\"color: rgb(0,0,0);\">Do you already use the tidyverse packages in R such as dplyr, tidyr, tibble and ggplot2?</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Do you need to analyse large collections of related time series?</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Would you like to learn how to use some new tidy tools for time series analysis including visualization, decomposition and forecasting?</span></li>\r\n</ol>\r\n</div></div>","id":"cf7b4ef5-4280-414e-9389-7d23eb8c0367","capacityId":"cf7b4ef5-4280-414e-9389-7d23eb8c0367","name":"Tidy Time Series Analysis and Forecasting Workshop","status":3,"type":"Session","defaultFeeId":"b490602c-e497-4d42-9e9a-d1384fffecca","fees":{"903932d6-8d6a-49ea-b300-c7da5e5e135c":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"d4a7216c-32bd-4c88-b3d8-ea91c35cad65","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"c9079b83-b394-437f-971b-26abc166e3c1","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Tidy time series analysis and forecasting","id":"903932d6-8d6a-49ea-b300-c7da5e5e135c","amount":855.0,"glCodes":[]},"b490602c-e497-4d42-9e9a-d1384fffecca":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"fc1d76b6-1468-41cb-b98a-1b628f9bd165","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"ed02ab96-fd50-4747-8b88-332d7f10a699","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Tidy time series analysis and forecasting","id":"b490602c-e497-4d42-9e9a-d1384fffecca","amount":1500.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"c49e47f4-0a47-4934-b786-ab914840a460":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"c49e47f4-0a47-4934-b786-ab914840a460_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2eitl\",\"text\":\"Excel is a widely used and powerful tool for working with data. As automation, reproducibility, collaboration, and frequent reporting become increasingly expected in data analysis, a good option for Excel users is to extend their workflows with R. Integrating R into data analysis with Excel can bridge the technical gap between collaborators using either software. R enables use of existing tools built for specific tasks and overcomes some limitations that arise when working with large datasets or repeated analyses. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"10lnb\",\"text\":\"This course is for Excel users who want to add or integrate R and RStudio into their existing data analysis toolkit. Participants will get hands-on experience working with data across R, Excel, and Google Sheets, focusing on: data import and export, basic wrangling, visualization, and reporting with RMarkdown. Throughout, we will emphasize conventions and best practices for working reproducibly and collaboratively with data, including naming conventions, documentation, organization, all while \\\"keeping the raw data raw\\\". Whether you are working in Excel and want to get started in R, already working in R and want tools for working more seamlessly with collaborators who use Excel, or whether you are new to data analysis entirely, this is the course for you!\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4ej1q\",\"text\":\"This workshop will be appropriate for attendees who answer yes to these questions:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":82,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1bsda\",\"text\":\"Are you an Excel user who wants to expand your data analysis toolset with R?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":76,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6er72\",\"text\":\"Do you want to bridge analyses between Excel and R, whether working independently or to more easily collaborate with others who use Excel or R? \",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":144,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"u03i\",\"text\":\"Are you new to data analysis, and looking for a good place to get started?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":74,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"25f2c69c-98ba-4190-9bee-da57efedf156":{"speakerId":"25f2c69c-98ba-4190-9bee-da57efedf156","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c49e47f4-0a47-4934-b786-ab914840a460"},"15437246-6544-4142-9e18-10ae47370e48":{"speakerId":"15437246-6544-4142-9e18-10ae47370e48","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c49e47f4-0a47-4934-b786-ab914840a460"}},"code":"Workshop1241","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Excel is a widely used and powerful tool for working with data. As automation, reproducibility, collaboration, and frequent reporting become increasingly expected in data analysis, a good option for Excel users is to extend their workflows with R. Integrating R into data analysis with Excel can bridge the technical gap between collaborators using either software. R enables use of existing tools built for specific tasks and overcomes some limitations that arise when working with large datasets or repeated analyses.&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">This course is for Excel users who want to add or integrate R and RStudio into their existing data analysis toolkit. Participants will get hands-on experience working with data across R, Excel, and Google Sheets, focusing on: data import and export, basic wrangling, visualization, and reporting with RMarkdown. Throughout, we will emphasize conventions and best practices for working reproducibly and collaboratively with data, including naming conventions, documentation, organization, all while \"keeping the raw data raw\". Whether you are working in Excel and want to get started in R, already working in R and want tools for working more seamlessly with collaborators who use Excel, or whether you are new to data analysis entirely, this is the course for you!</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This workshop will be appropriate for attendees who answer yes to these questions:</span></p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li><span style=\"color: rgb(0,0,0);\">Are you an Excel user who wants to expand your data analysis toolset with R?</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Do you want to bridge analyses between Excel and R, whether working independently or to more easily collaborate with others who use Excel or R? </span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Are you new to data analysis, and looking for a good place to get started?</span></li>\r\n</ol>\r\n</div></div>","id":"c49e47f4-0a47-4934-b786-ab914840a460","capacityId":"c49e47f4-0a47-4934-b786-ab914840a460","name":"R for Excel Users Workshop","status":2,"type":"Session","defaultFeeId":"2069b9fe-2136-429a-a910-c9ad39f61c5d","fees":{"6c8a768d-309b-423d-933e-62f8523fa550":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"7fe33d55-1462-4a48-bb8d-daffb51ca75b","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"6e302cf8-3949-40f4-8965-9aec7529fc31","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic R for excel fee","id":"6c8a768d-309b-423d-933e-62f8523fa550","amount":855.0,"glCodes":[]},"2069b9fe-2136-429a-a910-c9ad39f61c5d":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"7bf323e5-3dea-429f-851e-6a3c1add8094","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"631d1e15-f1e6-4b20-b02d-70f550bd60e6","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"R for Excel Fee","id":"2069b9fe-2136-429a-a910-c9ad39f61c5d","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"fd78d01e-f85c-458d-9e47-b65bc02cc1a9":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cggad\",\"text\":\"This is a two-day hands on workshop designed for experienced R and RStudio users who want to (re)design their R lifestyle. You’ll learn holistic workflows that address the most common sources of friction in data analysis. We’ll work on project-oriented workflows, version control for data science (Git/GitHub!), and how to plan for collaboration, communication, and iteration (incl. RMarkdown). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"68mp7\",\"text\":\"In terms of your R skills, expect to come away with new knowledge of your R installation, how to maintain it, robust strategies for working with the file system, and ways to use the purrr package for repetitive tasks.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"25spm\",\"text\":\"You should take this workshop if:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":33,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"57hja\",\"text\":\"You’ve been using R for a while and you feel like writing R code is not what’s holding you back the most.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":105,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6q1qb\",\"text\":\"You’ve realized that you have more pressing \\\"meta\\\" problems that no one seems to talk about:\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":92,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"famjv\",\"text\":\"You want to know how to divide your work into projects and scripts, how to expose your work to others, and how to get more connected to the R development scene. \",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":161,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1bpbv\",\"text\":\"The tidyverse is not an explicit focus of the course (other than the purrr segment) and you can certainly work through the content without it. But you should expect a great deal of tidyverse exposure. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":201,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"16d7f039-edc0-4141-91fe-14efab4fb864":{"speakerId":"16d7f039-edc0-4141-91fe-14efab4fb864","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9"},"27dc49c5-976c-4b86-a4fa-af4a24b7030c":{"speakerId":"27dc49c5-976c-4b86-a4fa-af4a24b7030c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9"},"265ea300-54f6-46e6-a6a4-ce00d292a372":{"speakerId":"265ea300-54f6-46e6-a6a4-ce00d292a372","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9"}},"code":"Workshop1242","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This is a two-day hands on workshop designed for experienced R and RStudio users who want to (re)design their R lifestyle. You’ll learn holistic workflows that address the most common sources of friction in data analysis. We’ll work on project-oriented workflows, version control for data science (Git/GitHub!), and how to plan for collaboration, communication, and iteration (incl. RMarkdown).&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">In terms of your R skills, expect to come away with new knowledge of your R installation, how to maintain it, robust strategies for working with the file system, and ways to use the purrr package for repetitive tasks.&nbsp;&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">You should take this workshop if:</span></p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li><span style=\"color: rgb(0,0,0);\">You’ve been using R for a while and you feel like writing R code is not what’s holding you back the most.</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">You’ve realized that you have more pressing \"meta\" problems that no one seems to talk about:</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">You want to know how to divide your work into projects and scripts, how to expose your work to others, and how to get more connected to the R development scene. </span></li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The tidyverse is not an explicit focus of the course (other than the purrr segment) and you can certainly work through the content without it. But you should expect a great deal of tidyverse exposure. </span></p>\r\n</div></div>","id":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9","capacityId":"fd78d01e-f85c-458d-9e47-b65bc02cc1a9","name":"What They Forgot to Teach You about R Workshop","status":2,"type":"Session","defaultFeeId":"996bda09-b9d9-476d-8dd0-26db738b9c09","fees":{"99d2bcb9-f762-4548-835c-87816d54069e":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"ee7f6ac2-80c0-4538-b637-e0c08a19d223","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"aaabac61-3228-43f7-8a6c-a746109716e6","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic What They Forgot to Teach You About R Workshop","id":"99d2bcb9-f762-4548-835c-87816d54069e","amount":855.0,"glCodes":[]},"996bda09-b9d9-476d-8dd0-26db738b9c09":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"683e26f0-7f95-44f5-aa2f-a4d78d77199b","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"52f05741-9590-4327-b848-8b4cd134160d","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"What They Forgot to Teach You About R Workshop","id":"996bda09-b9d9-476d-8dd0-26db738b9c09","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"6ebe4d66-1a7e-4f69-9665-204c61f9d920":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"6ebe4d66-1a7e-4f69-9665-204c61f9d920_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"foe0p\",\"text\":\"This is a two-day workshop for system administrators responsible for RStudio Server Pro, RStudio Connect, and RStudio Package Manager. It is designed to cover everything you need to know to setup and administer RStudio professional products as an integrated tool chain for your R users. Topics will include installation and configuration, user, content, and process management, and advanced topics like offline deployment, high availability, DevOps integration, and security best practices. Learn how to support R users and the people who need access to their work.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eh2ii\",\"text\":\"During this course you will learn how to install and configure: \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cbs03\",\"text\":\"R, compiled from source, in order to have multiple R versions side-by-side \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5uo7i\",\"text\":\"RStudio Server Pro, integrated with LDAP authentication \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"48irn\",\"text\":\"RStudio Connect, integrated with a mail server \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9lt5d\",\"text\":\"RStudio Package Manager\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"brl9d\",\"text\":\"Pre-requirements: I assume that you are confident in managing Linux (Ubuntu).  Specifically, I assume you already know how to:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"94ivm\",\"text\":\"Edit configuration files using vim or nano\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"686k8\",\"text\":\"Tail a log file\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4d6g0\",\"text\":\"Stop and start services\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fbn1s\",\"text\":\"SSH into a remote virtual machine\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"elsra\",\"text\":\"We will not cover any of these topics in detail:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":3,\"length\":15,\"style\":\"BOLD\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"bbdr3\",\"text\":\"Vertical scaling with load balancing\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a9rq2\",\"text\":\"Docker, kubernetes and launcher\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cod0\",\"text\":\"Authentication methods other than LDAP\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"duopp\",\"text\":\"Database configuration, pro drivers\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dibb9\",\"text\":\"Setting up proxies or reverse proxies, e.g. using Nginx or Apache\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9tfq4\",\"text\":\"Automated, scripted deployment, e.g. using Chef, Puppet or Ansible\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"86a96ae7-78ba-4590-b848-d7e1b827ef1c":{"speakerId":"86a96ae7-78ba-4590-b848-d7e1b827ef1c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"6ebe4d66-1a7e-4f69-9665-204c61f9d920"}},"code":"Workshop1231","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This is a two-day workshop for system administrators responsible for RStudio Server Pro, RStudio Connect, and RStudio Package Manager. It is designed to cover everything you need to know to setup and administer RStudio professional products as an integrated tool chain for your R users. Topics will include installation and configuration, user, content, and process management, and advanced topics like offline deployment, high availability, DevOps integration, and security best practices. Learn how to support R users and the people who need access to their work.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">During this course you will learn how to install and configure:&nbsp;</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>R, compiled from source, in order to have multiple R versions side-by-side&nbsp;</li>\r\n<li>RStudio Server Pro, integrated with LDAP authentication&nbsp;</li>\r\n<li>RStudio Connect, integrated with a mail server&nbsp;</li>\r\n<li>RStudio Package Manager</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Pre-requirements: I assume that you are confident in managing Linux (Ubuntu).&nbsp; Specifically, I assume you already know how to:</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>Edit configuration files using vim or nano</li>\r\n<li>Tail a log file</li>\r\n<li>Stop and start services</li>\r\n<li>SSH into a remote virtual machine</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">We <span style=\"font-weight: bold;\">will not cover </span>any of these topics in detail:</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>Vertical scaling with load balancing</li>\r\n<li>Docker, kubernetes and launcher</li>\r\n<li>Authentication methods other than LDAP</li>\r\n<li>Database configuration, pro drivers</li>\r\n<li>Setting up proxies or reverse proxies, e.g. using Nginx or Apache</li>\r\n<li>Automated, scripted deployment, e.g. using Chef, Puppet or Ansible</li>\r\n</ul>\r\n</div></div>","id":"6ebe4d66-1a7e-4f69-9665-204c61f9d920","capacityId":"6ebe4d66-1a7e-4f69-9665-204c61f9d920","name":"RStudio Professional Products Administration Workshop","status":2,"type":"Session","defaultFeeId":"415d862f-c16e-41d7-a969-6551e2337b4a","fees":{"415d862f-c16e-41d7-a969-6551e2337b4a":{"chargePolicies":[{"maximumRefundAmount":995.0,"id":"1011abdd-98ed-4f77-800b-5875820d8e21","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":995.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"ac75197a-ab5d-4a71-ab0a-93099de67001","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"RStudio Professional Products Administration Workshop","id":"415d862f-c16e-41d7-a969-6551e2337b4a","amount":995.0,"glCodes":[]},"7c9cc17b-c314-40c9-ad91-40758325f625":{"chargePolicies":[{"maximumRefundAmount":567.0,"id":"a53ba379-d874-4dae-a51a-595fb8068fe3","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":567.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"d546e574-d3b2-48b0-9673-eabf5216c6a7","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic RStudio Professional Products Administration Workshop","id":"7c9cc17b-c314-40c9-ad91-40758325f625","amount":567.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2120g\",\"text\":\"This 2-day workshop covers how to analyze large amounts of data in R.  We will focus on scaling up our analyses using the same dplyr verbs that we use in our everyday work. We will use dplyr with data.table, databases, and Spark.  We will also cover best practices on visualizing, modeling, and sharing against these data sources.  Where applicable, we will review recommended connection settings, security best practices, and deployment options.”\\n\\nWho should attend:\\n\\nYou should take this workshop if you want to learn how to work with big data in R. This data can be in-memory, in databases (like SQL Server), or in a cluster (like Spark).\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":447,\"style\":\"color-rgb(0,0,0)\"},{\"offset\":449,\"length\":18,\"style\":\"color-rgb(0,0,0)\"},{\"offset\":469,\"length\":172,\"style\":\"color-rgb(0,0,0)\"},{\"offset\":449,\"length\":18,\"style\":\"BOLD\"}],\"entityRanges\":[],\"data\":{\"text-align\":\"start\"}},{\"key\":\"3tk5d\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3pgfd\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"2070f92a-3fe4-4b40-a6c3-9065ac7f38e0":{"speakerId":"2070f92a-3fe4-4b40-a6c3-9065ac7f38e0","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc"},"3ba212f6-f5f0-4fb5-92ab-b7757878486f":{"speakerId":"3ba212f6-f5f0-4fb5-92ab-b7757878486f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc"}},"code":"Workshop1239","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p style=\"text-align:start;\" class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This 2-day workshop covers how to analyze large amounts of data in R.  We will focus on scaling up our analyses using the same dplyr verbs that we use in our everyday work. We will use dplyr with data.table, databases, and Spark.  We will also cover best practices on visualizing, modeling, and sharing against these data sources.  Where applicable, we will review recommended connection settings, security best practices, and deployment options.”</span><br><br><span style=\"color: rgb(0,0,0);\"><span style=\"font-weight: bold;\">Who should attend:</span></span><br><br><span style=\"color: rgb(0,0,0);\">You should take this workshop if you want to learn how to work with big data in R. This data can be in-memory, in databases (like SQL Server), or in a cluster (like Spark).</span><br></p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc","capacityId":"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc","name":"Big Data with R Workshop","status":2,"type":"Session","defaultFeeId":"5d630893-d945-4fd1-b80a-c90013c7bf44","fees":{"745bdf34-7ba8-4293-8045-fb94debe4959":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"30763425-ffa2-4de4-afba-a3c0eac8da65","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"e8cba296-246d-4c4b-a601-8ac0b43462e7","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Price","id":"745bdf34-7ba8-4293-8045-fb94debe4959","amount":855.0,"glCodes":[]},"5d630893-d945-4fd1-b80a-c90013c7bf44":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"cf2165b7-b3cb-4a98-9b99-80bc3e5dfbfd","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"88795cff-3c83-4e71-937a-95f86c342832","isActive":true,"effectiveUntil":"2019-12-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Big Data with R Workshop","id":"5d630893-d945-4fd1-b80a-c90013c7bf44","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"a556e0c4-c3d8-41b7-a947-bd1f291b77f0":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"a556e0c4-c3d8-41b7-a947-bd1f291b77f0_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-28T13:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"1cjl6\",\"text\":\"This is a two-day, hands-on workshop designed for people who are brand new to R & RStudio and who learn best in person. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"72f2u\",\"text\":\"You will learn the basics of R and data science, and practice using the RStudio IDE (integrated development environment). We'll discuss much of the material from the book R for Data Science, including data visualization (ggplot2), data transformation and tidying (dplyr, tidyr), understanding special data types (stringr, forcats, lubridate), and modeling (broom). Throughout the workshop, we'll work in RMarkdown documents, and learn best practices for data computing. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c6jm\",\"text\":\"If you want to transition from coding in base R to the tidyverse, or just jump into doing data science in the tidyverse without any prior R experience, this is the workshop for you! We will have a team of TAs on hand to show you the ropes, and help you out when you get stuck.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6n6eh\",\"text\":\"To know whether this workshop is right for you, consider these questions:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e46bv\",\"text\":\"You have a dataset of prices of diamonds, as well as their size. Could you make a scatterplot of the two variables using ggplot2?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d7lg6\",\"text\":\"You have two datasets, one with information on music genres and age ranges, the other with genres and radio station call names. Can you imagine how you would join them together with a dplyr verb?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7pl9m\",\"text\":\"We want to model the wages of people in the United States, using their height and education as predictors. Then, we would like to plot model predictions for each level of educational attainment. Can you imagine how to do this in R?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dm7k4\",\"text\":\"If you answered \\\"no\\\" to any or all of those questions... great! This workshop is for you. By the end of the two days, you should be able to accomplish all those tasks. If you answered \\\"yes\\\" to all three questions, you may want to consider taking a different workshop.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6oeh2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"38c654f1-517f-4732-9b71-a3a284077946":{"speakerId":"38c654f1-517f-4732-9b71-a3a284077946","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a556e0c4-c3d8-41b7-a947-bd1f291b77f0"},"94513fe9-5def-41c2-9cb0-022850f30285":{"speakerId":"94513fe9-5def-41c2-9cb0-022850f30285","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a556e0c4-c3d8-41b7-a947-bd1f291b77f0"}},"code":"Workshop1243","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This is a two-day, hands-on workshop designed for people who are brand new to R &amp; RStudio and who learn best in person.&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">You will learn the basics of R and data science, and practice using the RStudio IDE (integrated development environment). We'll discuss much of the material from the book R for Data Science, including data visualization (ggplot2), data transformation and tidying (dplyr, tidyr), understanding special data types (stringr, forcats, lubridate), and modeling (broom). Throughout the workshop, we'll work in RMarkdown documents, and learn best practices for data computing.&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">If you want to transition from coding in base R to the tidyverse, or just jump into doing data science in the tidyverse without any prior R experience, this is the workshop for you! We will have a team of TAs on hand to show you the ropes, and help you out when you get stuck.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">To know whether this workshop is right for you, consider these questions:</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>You have a dataset of prices of diamonds, as well as their size. Could you make a scatterplot of the two variables using ggplot2?</li>\r\n<li>You have two datasets, one with information on music genres and age ranges, the other with genres and radio station call names. Can you imagine how you would join them together with a dplyr verb?</li>\r\n<li>We want to model the wages of people in the United States, using their height and education as predictors. Then, we would like to plot model predictions for each level of educational attainment. Can you imagine how to do this in R?</li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">If you answered \"no\" to any or all of those questions... great! This workshop is for you. By the end of the two days, you should be able to accomplish all those tasks. If you answered \"yes\" to all three questions, you may want to consider taking a different workshop.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"a556e0c4-c3d8-41b7-a947-bd1f291b77f0","capacityId":"a556e0c4-c3d8-41b7-a947-bd1f291b77f0","name":"Introduction to Data Science in the Tidyverse Workshop","status":3,"type":"Session","defaultFeeId":"17421fbb-ae86-4243-803f-104947c305b7","fees":{"99343d98-b018-4c5c-95cd-7b2fb8f2cb7f":{"chargePolicies":[{"maximumRefundAmount":940.0,"id":"c3a37742-4890-4e93-bb12-74aa9aa0dcee","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":940.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"6c26e3f3-a197-49dd-848f-9496ce3702ac","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Introduction to Data Science in the Tidyverse Workshop","id":"99343d98-b018-4c5c-95cd-7b2fb8f2cb7f","amount":940.0,"glCodes":[]},"17421fbb-ae86-4243-803f-104947c305b7":{"chargePolicies":[{"maximumRefundAmount":1650.0,"id":"7dd3e989-76ea-4590-89bc-72094e86dff7","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1650.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"885a4c83-7041-428f-a686-f4e0cd7b05f2","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Introduction to Data Science in the Tidyverse Workshop","id":"17421fbb-ae86-4243-803f-104947c305b7","amount":1650.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"cab92973-3018-48e8-afba-7f21ce41d662":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"cab92973-3018-48e8-afba-7f21ce41d662_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"e0pd9\",\"text\":\"Have you ever encountered text data and suspected there was useful insight latent within it but felt frustrated about how to find that insight?\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c052j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"18jb6\",\"text\":\"Are you familiar with dplyr and ggplot2, and ready to learn how unstructured text data can be analyzed within the tidyverse ecosystem?\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b72o2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4e8j8\",\"text\":\"Do you need a flexible framework for handling text data that allows you to engage in tasks from exploratory data analysis to supervised predictive modeling?\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1pmnf\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c7l4n\",\"text\":\"Text data is increasingly important in many domains, and tidy data principles and tidy tools can make text mining easier and more effective. In this workshop, learn how to manipulate, summarize, and visualize the characteristics of text using these methods and R packages from the tidy tool ecosystem. These tools are highly effective for many analytical questions and allow analysts to integrate natural language processing into effective workflows already in wide use. Explore how to implement approaches such as sentiment analysis of texts, measuring tf-idf, network analysis of words, and building both supervised and unsupervised text models.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6ku50\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"6e152e8b-5bfe-4bdd-846a-e82d3bb8c981":{"speakerId":"6e152e8b-5bfe-4bdd-846a-e82d3bb8c981","speakerCategoryId":"4d782f1f-021e-4c86-a902-deb06dd7d9ee","sessionId":"cab92973-3018-48e8-afba-7f21ce41d662"}},"code":"Workshop1238","description":"Have you ever encountered text data and suspected there was useful insight latent within it but felt frustrated about how to find that insight?\r\n\r\nAre you familiar with dplyr and ggplot2, and ready to learn how unstructured text data can be analyzed within the tidyverse ecosystem?\r\n\r\nDo you need a flexible framework for handling text data that allows you to engage in tasks from exploratory data analysis to supervised predictive modeling?\r\n\r\nText data is increasingly important in many domains, and tidy data principles and tidy tools can make text mining easier and more effective. In this workshop, learn how to manipulate, summarize, and visualize the characteristics of text using these methods and R packages from the tidy tool ecosystem. These tools are highly effective for many analytical questions and allow analysts to integrate natural language processing into effective workflows already in wide use. Explore how to implement approaches such as sentiment analysis of texts, measuring tf-idf, network analysis of words, and building both supervised and unsupervised text models.","id":"cab92973-3018-48e8-afba-7f21ce41d662","capacityId":"cab92973-3018-48e8-afba-7f21ce41d662","name":"Text Mining with Tidy Data Principles Workshop","status":2,"type":"Session","defaultFeeId":"dca5c87e-be5e-42f5-b108-8be591a076a3","fees":{"a16fc1ac-7943-47d6-b131-ccf75db59445":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"0e343274-70fa-406f-8aac-a2dd46dd4a48","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"17cbc546-8aa8-4c53-9dc9-3fb135abaf4d","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Text Mining with Tidy Data Principles Workshop","id":"a16fc1ac-7943-47d6-b131-ccf75db59445","amount":855.0,"glCodes":[]},"dca5c87e-be5e-42f5-b108-8be591a076a3":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"1ea1529f-3594-4f48-9eed-7b545509a5f9","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"9bbb70de-6edc-49c8-af23-0bab000bab53","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Text Mining with Tidy Data Principles Workshop","id":"dca5c87e-be5e-42f5-b108-8be591a076a3","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"971192eb-91b7-4882-aa64-90b45dc58d1b":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"971192eb-91b7-4882-aa64-90b45dc58d1b_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ioqb\",\"text\":\"This 2-day introductory workshop will teach students the fundamentals how to create R Markdown scripts for reports and interactive applications. Attendees will learn how to:  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4f3eb\",\"text\":\"Design R Markdown for reproducibility and reuse.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"af4bl\",\"text\":\"Craft their own R Markdown reports.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5g6ar\",\"text\":\"Parameterize R Markdown content for personalized report generation\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fe5qr\",\"text\":\"Publish R Markdown content to other servers such as RStudio Connect and RPubs. \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"brrn1\",\"text\":\"Add flexdashboard interactive elements and pages to R Markdown documents\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c5kra\",\"text\":\"Combine htmlwidgets with static content to create dynamic dashboards\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6oii5\",\"text\":\"How to add Shiny interactivity to your dashboard.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fe5pc\",\"text\":\"Structure dashboards to visualize data from real-time Web sources \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f3gdd\",\"text\":\"Design interactive applications for best performance.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"78g2t\",\"text\":\"Students will gain experience constructing several reports and dashboards from data sets provided to the class. Attendees will also participate in a master class with Xihui Xie, the creator and co-author of R Markdown, to learn the details behind how R Markdown actually works and to get answers to their thorniest R Markdown questions.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"62d1k\",\"text\":\"This class is appropriate for attendees who want to:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":52,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"fk20p\",\"text\":\"Create reproducible data analyses and reports that can be shared with a large audience.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":87,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4opae\",\"text\":\"Craft interactive dashboards for others to understand their data and analyses. \",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":79,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"a5alc\",\"text\":\"Build stand-alone Web applications that allow users to visually explore data and find insights of their own.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":108,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"9i772\",\"text\":\"While no experience with R is required for our work with R Markdown, attendees will need knowledge of R and some experience with the tidyverse to build Shiny Web applications.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":175,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9e289142-3880-47a2-9515-3b02327bf77c":{"speakerId":"9e289142-3880-47a2-9515-3b02327bf77c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"971192eb-91b7-4882-aa64-90b45dc58d1b"},"4a239a86-4d24-46f4-b7a0-e1b9379fdd8d":{"speakerId":"4a239a86-4d24-46f4-b7a0-e1b9379fdd8d","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"971192eb-91b7-4882-aa64-90b45dc58d1b"}},"code":"Workshop124","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This 2-day introductory workshop will teach students the fundamentals how to create R Markdown scripts for reports and interactive applications. Attendees will learn how to:&nbsp;&nbsp;</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>Design R Markdown for reproducibility and reuse.</li>\r\n<li>Craft their own R Markdown reports.</li>\r\n<li>Parameterize R Markdown content for personalized report generation</li>\r\n<li>Publish R Markdown content to other servers such as RStudio Connect and RPubs.&nbsp;</li>\r\n<li>Add flexdashboard interactive elements and pages to R Markdown documents</li>\r\n<li>Combine htmlwidgets with static content to create dynamic dashboards</li>\r\n<li>How to add Shiny interactivity to your dashboard.</li>\r\n<li>Structure dashboards to visualize data from real-time Web sources&nbsp;</li>\r\n<li>Design interactive applications for best performance.</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Students will gain experience constructing several reports and dashboards from data sets provided to the class. Attendees will also participate in a master class with Xihui Xie, the creator and co-author of R Markdown, to learn the details behind how R Markdown actually works and to get answers to their thorniest R Markdown questions.&nbsp;&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This class is appropriate for attendees who want to:</span></p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li><span style=\"color: rgb(0,0,0);\">Create reproducible data analyses and reports that can be shared with a large audience.</span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Craft interactive dashboards for others to understand their data and analyses. </span></li>\r\n<li><span style=\"color: rgb(0,0,0);\">Build stand-alone Web applications that allow users to visually explore data and find insights of their own.</span></li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">While no experience with R is required for our work with R Markdown, attendees will need knowledge of R and some experience with the tidyverse to build Shiny Web applications.</span></p>\r\n</div></div>","id":"971192eb-91b7-4882-aa64-90b45dc58d1b","capacityId":"971192eb-91b7-4882-aa64-90b45dc58d1b","name":"R Markdown and Interactive Dashboards Workshop","status":2,"type":"Session","defaultFeeId":"c9e958fe-b908-4327-bd5a-f851f56cfb1f","fees":{"c9e958fe-b908-4327-bd5a-f851f56cfb1f":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"3215256e-1976-4acd-b5c5-f75dc05a875a","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"8fbab6e9-d736-43ce-afae-687b475df5fd","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic R Markdown and Interactive Dashboards Workshop","id":"c9e958fe-b908-4327-bd5a-f851f56cfb1f","amount":855.0,"glCodes":[]},"a1a3543d-08b6-4685-bc14-1f12e2587449":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"93f17902-763d-497b-9343-e61b4fd546d7","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"9e1b524f-1d28-4bb0-9f8f-de0a3d4737a1","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"R Markdown and Interactive Dashboards Workshop","id":"a1a3543d-08b6-4685-bc14-1f12e2587449","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"5eae945f-2285-44fb-ae67-1a9e8c74b4c6":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"5eae945f-2285-44fb-ae67-1a9e8c74b4c6_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"80h8b\",\"text\":\"This course will teach you how to think about good data visualization, and how to do it. We begin with some core principles about how we see graphs, what makes some of them better than others, and how to begin cultivating good judgment about visualization. Then, through a series of worked examples, you will learn how to use ggplot2 to make graphs piece by piece. The emphasis throughout is on acquiring a practical feel for and good judgment about the way ggplot2 can be used, from the simplest cases to sophisticated, customized data visualizations.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7rde1\",\"text\":\"The effective use of graphs and charts is an important way to explore data for yourself and to communicate your ideas and results to others. Being able to produce effective plots from data is also the best way to develop an eye for reading and critically understanding visualizations made by others, whether presented in academia, business, policy, or the media. Learning how to visualize data effectively is more than just knowing how to write code that produces figures from data. This course will teach you how to do that. But it will also teach you how to think about the information you want to show, and how best to present it to your audience — including when the audience is yourself.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4n97q\",\"text\":\"You should take this workshop if:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"12rpl\",\"text\":\"You want to understand the basic principles behind effective data visualizations, and how they are implemented in R and ggplot2.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"61df4\",\"text\":\"You want to better develop your practical sense for why some graphs and figures work well while others do not.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ie8h\",\"text\":\"You want to feel more confident and fluent in ggplot2, in order to make, refine, and effectively present good data visualizations.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"eaa17f1e-22ff-4566-a15a-a000d3330411":{"speakerId":"eaa17f1e-22ff-4566-a15a-a000d3330411","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5eae945f-2285-44fb-ae67-1a9e8c74b4c6"}},"code":"Workshop123","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This course will teach you how to think about good data visualization, and how to do it. We begin with some core principles about how we see graphs, what makes some of them better than others, and how to begin cultivating good judgment about visualization. Then, through a series of worked examples, you will learn how to use ggplot2 to make graphs piece by piece. The emphasis throughout is on acquiring a practical feel for and good judgment about the way ggplot2 can be used, from the simplest cases to sophisticated, customized data visualizations.&nbsp;&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">The effective use of graphs and charts is an important way to explore data for yourself and to communicate your ideas and results to others. Being able to produce effective plots from data is also the best way to develop an eye for reading and critically understanding visualizations made by others, whether presented in academia, business, policy, or the media. Learning how to visualize data effectively is more than just knowing how to write code that produces figures from data. This course will teach you how to do that. But it will also teach you how to think about the information you want to show, and how best to present it to your audience — including when the audience is yourself.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">You should take this workshop if:</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>You want to understand the basic principles behind effective data visualizations, and how they are implemented in R and ggplot2.</li>\r\n<li>You want to better develop your practical sense for why some graphs and figures work well while others do not.</li>\r\n<li>You want to feel more confident and fluent in ggplot2, in order to make, refine, and effectively present good data visualizations.</li>\r\n</ol>\r\n</div></div>","id":"5eae945f-2285-44fb-ae67-1a9e8c74b4c6","capacityId":"5eae945f-2285-44fb-ae67-1a9e8c74b4c6","name":"A Practical Introduction to Data Visualization with ggplot2 Workshop","status":2,"type":"Session","defaultFeeId":"6f859a87-e974-498d-b4e7-6e4e3961073e","fees":{"d1a40e96-3b0c-4c3f-a526-e7c12ef84466":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"f8c08dd7-1f09-49c3-a12b-c1f4616ba9f9","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"dda1134f-b8d5-4c29-8f82-7e472ae7b063","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"A Practical Introduction to Data Visualization with ggplot Workshop","id":"d1a40e96-3b0c-4c3f-a526-e7c12ef84466","amount":1500.0,"glCodes":[]},"6f859a87-e974-498d-b4e7-6e4e3961073e":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"e4aa6df4-c356-4d07-8b20-9f12888def5f","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"9c9011b3-10d9-4683-b9ac-27a4b0fab4dd","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic A Practical Introduction to Data Visualization with ggplot Workshop","id":"6f859a87-e974-498d-b4e7-6e4e3961073e","amount":855.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"bf7a9b49-cfcd-437d-a992-45359714bdff":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"bf7a9b49-cfcd-437d-a992-45359714bdff_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dbqe8\",\"text\":\"This two-day workshop introduces the essential concepts of building deep learning models with TensorFlow and Keras via R. First, we’ll establish a mental model of where deep learning fits in the spectrum of machine learning, highlight its benefits and limitations, and discuss how the TensorFlow - Keras - R toolchain work together. We'll then build an understanding of deep learning through first principles and practical applications covering a variety of tasks such as computer vision, natural language processing, anomaly detection, and more. Throughout the workshop you will gain an intuitive understanding of the architectures and engines that make up deep learning models, apply a variety of deep learning algorithms (i.e. MLPs, CNNs, RNNs, LSTMs, autoencoders), understand when and how to tune the various hyperparameters, and be able to interpret model results. Leaving this workshop, you should have a firm grasp of deep learning and be able to implement a systematic approach for producing high quality modeling results.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9lhir\",\"text\":\"Is this workshop for you? If you answer \\\"yes\\\" to these three questions, then this workshop is likely a good fit:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b3081\",\"text\":\"Are you relatively new to the field of deep learning and neural networks but eager to learn? Or maybe you have applied a basic feedforward neural network but aren't familiar with the other deep learning frameworks?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1njpq\",\"text\":\"Are you an experienced R user comfortable with the tidyverse, creating functions, and applying control (i.e. if, ifelse) and iteration (i.e. for, while) statements?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1tn1j\",\"text\":\"Are you familiar with the machine learning process such as data splitting, feature engineering, resampling procedures (i.e. k-fold cross validation), hyperparameter tuning, and model validation? This workshop will provide some review of these topics but coming in with some exposure will help you stay focused on the deep learning details rather than the general modeling procedure details.\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f1029\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9bff54a5-e7a2-4461-9e62-37310a27cc84":{"speakerId":"9bff54a5-e7a2-4461-9e62-37310a27cc84","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"bf7a9b49-cfcd-437d-a992-45359714bdff"}},"code":"Workshop1232","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This two-day workshop introduces the essential concepts of building deep learning models with TensorFlow and Keras via R. First, we’ll establish a mental model of where deep learning fits in the spectrum of machine learning, highlight its benefits and limitations, and discuss how the TensorFlow - Keras - R toolchain work together. We'll then build an understanding of deep learning through first principles and practical applications covering a variety of tasks such as computer vision, natural language processing, anomaly detection, and more. Throughout the workshop you will gain an intuitive understanding of the architectures and engines that make up deep learning models, apply a variety of deep learning algorithms (i.e. MLPs, CNNs, RNNs, LSTMs, autoencoders), understand when and how to tune the various hyperparameters, and be able to interpret model results. Leaving this workshop, you should have a firm grasp of deep learning and be able to implement a systematic approach for producing high quality modeling results.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Is this workshop for you? If you answer \"yes\" to these three questions, then this workshop is likely a good fit:</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>Are you relatively new to the field of deep learning and neural networks but eager to learn? Or maybe you have applied a basic feedforward neural network but aren't familiar with the other deep learning frameworks?</li>\r\n<li>Are you an experienced R user comfortable with the tidyverse, creating functions, and applying control (i.e. if, ifelse) and iteration (i.e. for, while) statements?</li>\r\n<li>Are you familiar with the machine learning process such as data splitting, feature engineering, resampling procedures (i.e. k-fold cross validation), hyperparameter tuning, and model validation? This workshop will provide some review of these topics but coming in with some exposure will help you stay focused on the deep learning details rather than the general modeling procedure details.</li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"bf7a9b49-cfcd-437d-a992-45359714bdff","capacityId":"bf7a9b49-cfcd-437d-a992-45359714bdff","name":"Deep Learning with Keras and TensorFlow in R Workflow","status":3,"type":"Session","defaultFeeId":"deb7026e-04e5-47e6-a2ca-0adb4561ff66","fees":{"fa7700c3-e2f9-43bf-ab0b-ac748cdf61e5":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"95f0a6dc-eed6-4355-b264-f811c9041e14","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"e9f33476-42e5-44ce-85e5-f39e1c394c7f","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Deep Learning with Keras and TensorFlow in R Workflow","id":"fa7700c3-e2f9-43bf-ab0b-ac748cdf61e5","amount":855.0,"glCodes":[]},"deb7026e-04e5-47e6-a2ca-0adb4561ff66":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"2b12067e-12da-4508-ac56-6a0fe5d7cfed","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"d43be0b4-5f08-4466-99ce-2308c48c8ba4","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Deep Learning with Keras and TensorFlow in R Workflow","id":"deb7026e-04e5-47e6-a2ca-0adb4561ff66","amount":1500.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"de26c627-2d43-46fe-89c9-60ae17ea97e4":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"de26c627-2d43-46fe-89c9-60ae17ea97e4_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dl8np\",\"text\":\"Make your geospatial data come to life with R. This course will get you quickly up and running with the new R workflow for geospatial data. An explosion of packages for working with spatial data means you can ditch your GIS software and do geospatial analysis in R end-to-end. You will learn to read, manipulate and visualize spatial data and you'll be introduced to functionality that will have you saying \\\"I didn't know you could do that in R!\\\".  In addition to learning from Zev Ross, you will benefit from support during the workshop from two additional spatial analysis experts, Angela Li from the Center for Spatial Data Science and Hollie Olmstead from ZevRoss Spatial Analysis, each with extensive experience analyzing spatial data and teaching core concepts.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7da1o\",\"text\":\"During the workshop, you will learn:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2corj\",\"text\":\"Key strategies for getting spatial data into R. This includes an introduction to powerful packages for accessing data on census, climate, land cover and more— as well as functionality for reading external files (e.g., shapefiles, geojson, geopackages, grids and tiffs).\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f1jm8\",\"text\":\"The latest innovations in spatial data visualization. Participants will create both static and interactive visualizations using the flexible and feature-rich {tmap} and {mapview} as well as explore the landscape of specialized visualization packages such as {cartography}, {geogrid}, {rayshader} and {concaveman}.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"520k5\",\"text\":\"How spatial data can be integrated into data science workflows, how to manipulate, slice and dice and make sense of spatial data. You will also learn key geoprocessing techniques for both vector and raster data including buffering, clipping, masking, cropping, computing distance and others.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"20u47\",\"text\":\"Participants in the workshop do not need to have any previous geospatial experience but they must be proficient in R -- for example, they should be able to use dplyr functions such as select, filter and mutate from memory.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"erk1j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"bd0306be-5920-4f17-b415-bd3ebcbf33a6":{"speakerId":"bd0306be-5920-4f17-b415-bd3ebcbf33a6","speakerCategoryId":"4d782f1f-021e-4c86-a902-deb06dd7d9ee","sessionId":"de26c627-2d43-46fe-89c9-60ae17ea97e4"}},"code":"Workshop1234","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Make your geospatial data come to life with R. This course will get you quickly up and running with the new R workflow for geospatial data. An explosion of packages for working with spatial data means you can ditch your GIS software and do geospatial analysis in R end-to-end. You will learn to read, manipulate and visualize spatial data and you'll be introduced to functionality that will have you saying \"I didn't know you could do that in R!\".&nbsp; In addition to learning from Zev Ross, you will benefit from support during the workshop from two additional spatial analysis experts, Angela Li from the Center for Spatial Data Science and Hollie Olmstead from ZevRoss Spatial Analysis, each with extensive experience analyzing spatial data and teaching core concepts.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">During the workshop, you will learn:</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>Key strategies for getting spatial data into R. This includes an introduction to powerful packages for accessing data on census, climate, land cover and more— as well as functionality for reading external files (e.g., shapefiles, geojson, geopackages, grids and tiffs).</li>\r\n<li>The latest innovations in spatial data visualization. Participants will create both static and interactive visualizations using the flexible and feature-rich {tmap} and {mapview} as well as explore the landscape of specialized visualization packages such as {cartography}, {geogrid}, {rayshader} and {concaveman}.</li>\r\n<li>How spatial data can be integrated into data science workflows, how to manipulate, slice and dice and make sense of spatial data. You will also learn key geoprocessing techniques for both vector and raster data including buffering, clipping, masking, cropping, computing distance and others.</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Participants in the workshop do not need to have any previous geospatial experience but they must be proficient in R -- for example, they should be able to use dplyr functions such as select, filter and mutate from memory.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"de26c627-2d43-46fe-89c9-60ae17ea97e4","capacityId":"de26c627-2d43-46fe-89c9-60ae17ea97e4","name":"Modern Geospatial Data Analysis with R Workshop","status":2,"type":"Session","defaultFeeId":"92d88985-6c14-4c5f-b658-3c0199989554","fees":{"92d88985-6c14-4c5f-b658-3c0199989554":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"07e2776d-b6f3-4e4a-86b0-6f0fb4ace933","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"a51b3ade-9fde-4460-a091-eb254ac0f2e4","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Modern Geospatial Data Analysis with R","id":"92d88985-6c14-4c5f-b658-3c0199989554","amount":855.0,"glCodes":[]},"138c9c07-cbf6-4b23-b617-78a54e5a973d":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"bcad6a66-07e8-4bc6-b6ad-38ab703f0755","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"c798daa0-78ea-409b-ba17-87b93dfacf75","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Modern Geospatial Data Analysis with R","id":"138c9c07-cbf6-4b23-b617-78a54e5a973d","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"4ba63dde-c0aa-4d2a-8172-c839c49d7dca":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"4ba63dde-c0aa-4d2a-8172-c839c49d7dca_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7dot6\",\"text\":\"IIf your organization uses R, there are clear benefits to having an organizational R package. Such benefits can be realized whether there is only a single R user or dozens of them. An R package focused on the particular needs of an organization can open up a world of possibilities including easier data access, shared functions for data transformation and analysis, and a common look and feel for reporting.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cgv5n\",\"text\":\"Creating your first organizational R package can be daunting however. You may wonder:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c7vp2\",\"text\":\"What functions should be included?\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eua69\",\"text\":\"How would colleagues install the package (and updates)?\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1qk8d\",\"text\":\"What could be done to ensure there is sufficient quality control?\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"chp11\",\"text\":\"This workshop will demonstrate how to get an organizational R package off the ground. We’ll take a look at planning the package and understanding the requirements of the internal stakeholders. We'll consider how the package could fit in with existing organizational infrastructure. We'll design and implement functions for data access, data analysis, and reporting.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"aaa0o\",\"text\":\"One of the hardest parts of the process could very well be gaining and maintaining internal support for an organizational package project. To address this, we'll work through ways to communicate value and to develop an internal community of colleagues to sustain the project and to make it a valuable part of the core infrastructure.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ecisb\",\"text\":\"This workshop is appropriate for attendees who answer yes to these three questions: \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d0fep\",\"text\":\"Do you work in an organization that uses R as part of its analytical toolchain?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5h7d0\",\"text\":\"Could day-to-day data analysis tasks performed in R (at your organization) benefit from a suite of specialized R functions?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"561d5\",\"text\":\"Do you value consistency, quality, and standardization in the R work done in your organization?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"56883730-121d-467c-82cf-8a85585a8bbb":{"speakerId":"56883730-121d-467c-82cf-8a85585a8bbb","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4ba63dde-c0aa-4d2a-8172-c839c49d7dca"},"ea839a56-fca3-4a26-a97e-ec2adb44962f":{"speakerId":"ea839a56-fca3-4a26-a97e-ec2adb44962f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4ba63dde-c0aa-4d2a-8172-c839c49d7dca"}},"code":"Workshop1244","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">IIf your organization uses R, there are clear benefits to having an organizational R package. Such benefits can be realized whether there is only a single R user or dozens of them. An R package focused on the particular needs of an organization can open up a world of possibilities including easier data access, shared functions for data transformation and analysis, and a common look and feel for reporting.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">Creating your first organizational R package can be daunting however. You may wonder:</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>What functions should be included?</li>\r\n<li>How would colleagues install the package (and updates)?</li>\r\n<li>What could be done to ensure there is sufficient quality control?</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">This workshop will demonstrate how to get an organizational R package off the ground. We’ll take a look at planning the package and understanding the requirements of the internal stakeholders. We'll consider how the package could fit in with existing organizational infrastructure. We'll design and implement functions for data access, data analysis, and reporting.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">One of the hardest parts of the process could very well be gaining and maintaining internal support for an organizational package project. To address this, we'll work through ways to communicate value and to develop an internal community of colleagues to sustain the project and to make it a valuable part of the core infrastructure.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">This workshop is appropriate for attendees who answer yes to these three questions:&nbsp;</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>Do you work in an organization that uses R as part of its analytical toolchain?</li>\r\n<li>Could day-to-day data analysis tasks performed in R (at your organization) benefit from a suite of specialized R functions?</li>\r\n<li>Do you value consistency, quality, and standardization in the R work done in your organization?</li>\r\n</ol>\r\n</div></div>","id":"4ba63dde-c0aa-4d2a-8172-c839c49d7dca","capacityId":"4ba63dde-c0aa-4d2a-8172-c839c49d7dca","name":"My Organization's First R Package Workshop","status":2,"type":"Session","defaultFeeId":"8dd2d4a4-3873-4bb0-9f8e-c415b4799e31","fees":{"8dd2d4a4-3873-4bb0-9f8e-c415b4799e31":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"b379f41a-61bc-4741-9f77-40683eb31daf","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"3f057f03-2183-4bb5-9e4f-d5ec6ac66cda","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"My Organization's First R Package Workshop Details","id":"8dd2d4a4-3873-4bb0-9f8e-c415b4799e31","amount":1500.0,"glCodes":[]},"408eeddc-a1c3-4795-b288-fdfc2f309c1d":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"847103ae-9ea4-474a-b5fc-0f72d4790fe8","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"2039baf1-2be8-4fd7-b1ae-313a84d7afc9","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic My Organization's First R Package Workshop Details","id":"408eeddc-a1c3-4795-b288-fdfc2f309c1d","amount":855.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"8bfe8930-02b0-42bd-95f8-d39974cd159c":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"8bfe8930-02b0-42bd-95f8-d39974cd159c_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7dfuq\",\"text\":\"This workshop provides a gentle introduction to machine learning and to the tidyverse packages that do machine learning. You'll learn how to train and assess predictive models with several common machine learning algorithms, as well as how to do feature engineering to improve the predictive accuracy of your models. We will focus on learning the basic theory and best practices that support machine learning, and we will do it with a modern suite of R packages known as tidymodels. Tidymodels packages, like parsnip, recipes, and rsample provide a grammar for modeling and work seamlessly with R's tidyverse packages.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c7gal\",\"text\":\"This workshop is appropriate for attendees who answer yes to the questions below:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f42j6\",\"text\":\"Can you use mutate and purrr to transform a data frame that contains list columns?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4pdv\",\"text\":\"Can you use the ggplot2 package to make a large variety of graphs?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2m6gq\",\"text\":\"If you answered no to either question, you can brush up on these topics by working through the online tutorials at https://rstudio.cloud/learn/primers.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"47s8n\",\"text\":\"If you already use machine learning methods like random forests, neural networks, cross-validation or feature engineering, this course is NOT for you; register for Max Kuhn's Applied Machine Learning Workshop instead.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"baeecacf-c42a-4789-80fb-76eaad16815f":{"speakerId":"baeecacf-c42a-4789-80fb-76eaad16815f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"8bfe8930-02b0-42bd-95f8-d39974cd159c"},"66de89b5-e2ef-4ff3-943d-2a09aa88a1c5":{"speakerId":"66de89b5-e2ef-4ff3-943d-2a09aa88a1c5","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"8bfe8930-02b0-42bd-95f8-d39974cd159c"}},"code":"Workshop1245","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">This workshop provides a gentle introduction to machine learning and to the tidyverse packages that do machine learning. You'll learn how to train and assess predictive models with several common machine learning algorithms, as well as how to do feature engineering to improve the predictive accuracy of your models. We will focus on learning the basic theory and best practices that support machine learning, and we will do it with a modern suite of R packages known as tidymodels. Tidymodels packages, like parsnip, recipes, and rsample provide a grammar for modeling and work seamlessly with R's tidyverse packages.</p><p class=\"carina-rte-public-DraftStyleDefault-block\">This workshop is appropriate for attendees who answer yes to the questions below:</p><ol class=\"carina-rte-public-DraftStyleDefault-ol\"><li>Can you use mutate and purrr to transform a data frame that contains list columns?</li><li>Can you use the ggplot2 package to make a large variety of graphs?</li></ol><p class=\"carina-rte-public-DraftStyleDefault-block\">If you answered no to either question, you can brush up on these topics by working through the online tutorials at https://rstudio.cloud/learn/primers.</p><p class=\"carina-rte-public-DraftStyleDefault-block\">If you already use machine learning methods like random forests, neural networks, cross-validation or feature engineering, this course is NOT for you; register for Max Kuhn's Applied Machine Learning Workshop instead.</p></div></div>","id":"8bfe8930-02b0-42bd-95f8-d39974cd159c","capacityId":"8bfe8930-02b0-42bd-95f8-d39974cd159c","name":"Introduction to Machine Learning with the Tidyverse Workshop","status":3,"type":"Session","defaultFeeId":"66d49b86-b7ae-46c0-9428-a0c76ef78a04","fees":{"66d49b86-b7ae-46c0-9428-a0c76ef78a04":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"ba24e030-6fc1-4444-80e7-d875675533b0","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"448fb459-e1b1-4835-a017-45f103674c76","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Introduction to Machine Learning with the Tidyverse","id":"66d49b86-b7ae-46c0-9428-a0c76ef78a04","amount":1500.0,"glCodes":[]},"0835e325-6086-4457-a428-331ad2b59746":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"4814cee4-60b6-43c3-b721-0800a1726bbc","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"c21e03fe-7f23-4e1a-a78b-68a8a6be99cd","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Introduction to Machine Learning with the Tidyverse","id":"0835e325-6086-4457-a428-331ad2b59746","amount":855.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"b68c60bd-4f3f-423b-aec5-d6fa140187fd":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"b68c60bd-4f3f-423b-aec5-d6fa140187fd_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"5a76j\",\"text\":\"Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn't available in the `shiny` package. Fortunately, we can use the building blocks of the web — JavaScript, HTML, and CSS — to extend Shiny's capabilities and create engaging Shiny apps. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fq9t4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cv95g\",\"text\":\"This two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript's syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an `htmlwidget` and as we learn how to incorporate our own or packaged JavaScript code into Shiny apps and RMarkdown documents, and how to simultaneously manage JavaScript and R dependencies.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e510a\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fovob\",\"text\":\"This workshop is for the Shiny user who boldly waded into the *Customizing Shiny* section of shiny.rstudio.com/articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but she is overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3pra0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d578ee8b-4d45-4743-99a3-4e58ba77315b":{"speakerId":"d578ee8b-4d45-4743-99a3-4e58ba77315b","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b68c60bd-4f3f-423b-aec5-d6fa140187fd"}},"code":"Workshop1246","description":"Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn't available in the `shiny` package. Fortunately, we can use the building blocks of the web — JavaScript, HTML, and CSS — to extend Shiny's capabilities and create engaging Shiny apps. \r\n\r\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript's syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an `htmlwidget` and as we learn how to incorporate our own or packaged JavaScript code into Shiny apps and RMarkdown documents, and how to simultaneously manage JavaScript and R dependencies.\r\n\r\nThis workshop is for the Shiny user who boldly waded into the *Customizing Shiny* section of shiny.rstudio.com/articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but she is overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop.","id":"b68c60bd-4f3f-423b-aec5-d6fa140187fd","capacityId":"b68c60bd-4f3f-423b-aec5-d6fa140187fd","name":"JavaScript for Shiny Users Workshop","status":3,"type":"Session","defaultFeeId":"ea64f18d-2c6c-4320-98d2-b3c22bf75733","fees":{"ea64f18d-2c6c-4320-98d2-b3c22bf75733":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"314fda1f-4323-4e4e-b2b3-01e8b8d08b3f","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"f17fc574-fd27-45eb-a538-81d7967f8e7c","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"JavaScript for Shiny Users Workshop","id":"ea64f18d-2c6c-4320-98d2-b3c22bf75733","amount":1500.0,"glCodes":[]},"d175e43f-10e7-46c6-8077-3465dbf6c9cc":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"0ce0e6cd-2a38-45ca-a6f7-2d6215d45b32","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"0eb32a9e-a917-4f3b-adfd-1ccbfbe62565","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic JavaScript for Shiny Users Workshop","id":"d175e43f-10e7-46c6-8077-3465dbf6c9cc","amount":855.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"5ebec1c3-9bf6-411d-8339-5b00db5c200b":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"5ebec1c3-9bf6-411d-8339-5b00db5c200b_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ck4te\",\"text\":\"Success in data science and statistics is dependent on the development of both analytical and computational skills, and the demand for educators who are proficient at teaching both these skills is growing. The goal of this workshop is to equip educators with concrete information on content, workflows, and infrastructure for painlessly introducing modern computation with R and RStudio within a data science curriculum. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ff7l1\",\"text\":\"In addition to gaining technical knowledge, participants will engage in discussion around the decisions that go into developing a data science curriculum and choosing workflows and infrastructure that best support the curriculum and allow for scalability. Workshop attendees will work through several exercises from existing courses and get first-hand experience with using relevant tool-chains and techniques, including running a course on RStudio Cloud, and literate programming with R Markdown, and workflows for collaboration, version control, and automated feedback with Git/GitHub. We will also discuss best practices for configuring and deploying classroom infrastructures to support these tools. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d7eem\",\"text\":\"This workshop is aimed primarily at participants teaching data science in an academic setting in semester-long courses, however much of the information and tooling we introduce is applicable for shorter teaching experiences like workshops and bootcamps as well. Basic knowledge of R is assumed and familiarity with Git is preferred.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4sv94\",\"text\":\"If your answer to the following questions is \\\"yes\\\", then this is the right course for you.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"16amt\",\"text\":\"Do you want to learn / discuss curriculum, pedagogy, and computing infrastructure design for teaching data science with R and RStudio?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9trg5\",\"text\":\"Are you interested in setting up your class in RStudio Cloud?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4rk90\",\"text\":\"Do you want to integrate version control with git into your teaching and learn about tools and best practices for running your course on GitHub?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"12kic\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"199e49f7-dbc2-4165-b700-4a47dc09bba2":{"speakerId":"199e49f7-dbc2-4165-b700-4a47dc09bba2","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5ebec1c3-9bf6-411d-8339-5b00db5c200b"}},"code":"Workshop1233","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Success in data science and statistics is dependent on the development of both analytical and computational skills, and the demand for educators who are proficient at teaching both these skills is growing. The goal of this workshop is to equip educators with concrete information on content, workflows, and infrastructure for painlessly introducing modern computation with R and RStudio within a data science curriculum.&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">In addition to gaining technical knowledge, participants will engage in discussion around the decisions that go into developing a data science curriculum and choosing workflows and infrastructure that best support the curriculum and allow for scalability. Workshop attendees will work through several exercises from existing courses and get first-hand experience with using relevant tool-chains and techniques, including running a course on RStudio Cloud, and literate programming with R Markdown, and workflows for collaboration, version control, and automated feedback with Git/GitHub. We will also discuss best practices for configuring and deploying classroom infrastructures to support these tools.&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">This workshop is aimed primarily at participants teaching data science in an academic setting in semester-long courses, however much of the information and tooling we introduce is applicable for shorter teaching experiences like workshops and bootcamps as well. Basic knowledge of R is assumed and familiarity with Git is preferred.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">If your answer to the following questions is \"yes\", then this is the right course for you.</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>Do you want to learn / discuss curriculum, pedagogy, and computing infrastructure design for teaching data science with R and RStudio?</li>\r\n<li>Are you interested in setting up your class in RStudio Cloud?</li>\r\n<li>Do you want to integrate version control with git into your teaching and learn about tools and best practices for running your course on GitHub?</li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"5ebec1c3-9bf6-411d-8339-5b00db5c200b","capacityId":"5ebec1c3-9bf6-411d-8339-5b00db5c200b","name":"Designing the Data Science Classroom Workshop","status":2,"type":"Session","defaultFeeId":"a4f27c02-2406-4242-90e3-c47a916a37bd","fees":{"04fc41a3-d435-4985-b8e3-e987ddb81f0b":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"f8af5874-ed6b-4e73-bc1a-6031a9f440a6","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"10851a2a-100a-412b-a3d3-9f4632bb8a41","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Designing the Data Science Class Academic","id":"04fc41a3-d435-4985-b8e3-e987ddb81f0b","amount":855.0,"glCodes":[]},"a4f27c02-2406-4242-90e3-c47a916a37bd":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"632fb84c-7dcd-465c-8099-99a5ccdccc62","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"8f1aee29-5b2e-433b-9ae9-700b0326cd1b","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Designing the Data Science Classroom Workshop Fee","id":"a4f27c02-2406-4242-90e3-c47a916a37bd","amount":1500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"885ji\",\"text\":\"Shiny is the leading R-based system for writing interactive web-based apps. These give your clients, users, or students the power and sophistication of R with a friendly, no-code interface custom designed to your purpose. The workshop will start at the beginning: designing and creating user interfaces, learning and mastering the reactive model that connects your R code to the interface, and deploying apps publicly and privately. Then we'll work with intermediate-level tools: communicating with outside files and databases, debugging, modularizing. You'll build a range of (closely related) app formats in wide use: interactive Rmd, browser-page apps, tutorials, and dashboards. In the end, you'll be a confident Shiny craftsperson, able to design interactive apps to achieve your purpose and produce a polished and professional implementation.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8egqo\",\"text\":\"If your answer to the following questions is \\\"yes\\\", then this is the right course for you.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ucr3\",\"text\":\"Do you have experience writing functions in R?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ainkt\",\"text\":\"Do you, or members of your team, know how to apply R to solve the data manipulation, graphics, and modeling problems needed to accomplish your purpose? (Shiny provides the means to embed your data solutions in an interactive framework, but you provide the solutions themselves!)\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ao0fh\",\"text\":\"Do you have a use case for Shiny, that is, a notion of the kinds of user-facing facilities you would like to build with Shiny?\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3gcb2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"5e6f6041-dd99-4d58-b668-87462ebe1b41":{"speakerId":"5e6f6041-dd99-4d58-b668-87462ebe1b41","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4"}},"code":"Workshop1247","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Shiny is the leading R-based system for writing interactive web-based apps. These give your clients, users, or students the power and sophistication of R with a friendly, no-code interface custom designed to your purpose. The workshop will start at the beginning: designing and creating user interfaces, learning and mastering the reactive model that connects your R code to the interface, and deploying apps publicly and privately. Then we'll work with intermediate-level tools: communicating with outside files and databases, debugging, modularizing. You'll build a range of (closely related) app formats in wide use: interactive Rmd, browser-page apps, tutorials, and dashboards. In the end, you'll be a confident Shiny craftsperson, able to design interactive apps to achieve your purpose and produce a polished and professional implementation.</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">If your answer to the following questions is \"yes\", then this is the right course for you.</p>\r\n<ol class=\"carina-rte-public-DraftStyleDefault-ol\">\r\n<li>Do you have experience writing functions in R?</li>\r\n<li>Do you, or members of your team, know how to apply R to solve the data manipulation, graphics, and modeling problems needed to accomplish your purpose? (Shiny provides the means to embed your data solutions in an interactive framework, but you provide the solutions themselves!)</li>\r\n<li>Do you have a use case for Shiny, that is, a notion of the kinds of user-facing facilities you would like to build with Shiny?</li>\r\n</ol>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">&nbsp;</p>\r\n</div></div>","id":"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4","capacityId":"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4","name":"Shiny from Start to Finish Workshop","status":3,"type":"Session","defaultFeeId":"2528b3c4-2041-422e-b65d-8db4914d5657","fees":{"2528b3c4-2041-422e-b65d-8db4914d5657":{"chargePolicies":[{"maximumRefundAmount":1500.0,"id":"f56fb777-912a-418f-954e-a02e6d0a5c2f","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"2e7a1cfc-cbde-4465-b5c4-3c753fd1c8e8","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Shiny from start to finish Workshop","id":"2528b3c4-2041-422e-b65d-8db4914d5657","amount":1500.0,"glCodes":[]},"61028c58-64c6-425c-819d-a55d6a600f35":{"chargePolicies":[{"maximumRefundAmount":855.0,"id":"e002d197-f2ac-4f46-adee-795d16c95ec9","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":855.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"f4980b01-f684-4df5-894f-6a7ac8d229c7","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Shiny from start to finish Workshop","id":"61028c58-64c6-425c-819d-a55d6a600f35","amount":855.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"98251367-affe-4d4f-b30a-678291d4bb50":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"98251367-affe-4d4f-b30a-678291d4bb50_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"fmlj0\",\"text\":\"Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast-growing fields of research in the world of data science. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7nhr3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3cup\",\"text\":\"This two-day course will provide an overview of using R for supervised learning. The session will step through the process of building, visualizing, testing, and comparing models that are focused on prediction.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"48q7i\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9n32m\",\"text\":\"The goal of the course is to provide a thorough workflow in R that can be used with many different regression or classification techniques. Case studies on real data will be used to illustrate the functionality and several different predictive models are illustrated.  The course focuses on both low- and high-level approaches to modeling using the tidyverse and uses several types of models for illustration. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4ujll\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"sh5t\",\"text\":\"Basic familiarity with R and the tidyverse is required.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"5e87d90e-8603-42d6-9699-1cc9ddda1a93":{"speakerId":"5e87d90e-8603-42d6-9699-1cc9ddda1a93","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"98251367-affe-4d4f-b30a-678291d4bb50"},"9b18744b-7d17-4cee-bc1e-870f54ddd598":{"speakerId":"9b18744b-7d17-4cee-bc1e-870f54ddd598","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"98251367-affe-4d4f-b30a-678291d4bb50"}},"code":"Workshop1235","description":"Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast-growing fields of research in the world of data science. \r\n\r\nThis two-day course will provide an overview of using R for supervised learning. The session will step through the process of building, visualizing, testing, and comparing models that are focused on prediction.\r\n\r\nThe goal of the course is to provide a thorough workflow in R that can be used with many different regression or classification techniques. Case studies on real data will be used to illustrate the functionality and several different predictive models are illustrated.  The course focuses on both low- and high-level approaches to modeling using the tidyverse and uses several types of models for illustration. \r\n\r\nBasic familiarity with R and the tidyverse is required.","id":"98251367-affe-4d4f-b30a-678291d4bb50","capacityId":"98251367-affe-4d4f-b30a-678291d4bb50","name":"Applied Machine Learning Workshop","status":3,"type":"Session","defaultFeeId":"415b5991-23b6-43b6-a4a1-83acf61751f6","fees":{"415b5991-23b6-43b6-a4a1-83acf61751f6":{"chargePolicies":[{"maximumRefundAmount":1650.0,"id":"de49d7d6-5241-4378-80ab-f1b502c64b94","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1650.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"a001bb0c-f3eb-42ee-a637-007172953892","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Applied Machine Learning Workshop","id":"415b5991-23b6-43b6-a4a1-83acf61751f6","amount":1650.0,"glCodes":[]},"03a834a2-907b-4b72-a067-469dd972d0ec":{"chargePolicies":[{"maximumRefundAmount":940.0,"id":"6d2d87ef-43b1-41c6-bdce-c69328fabca5","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":940.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"888ef669-f375-4446-a675-182f6ff8650a","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Applied Machine Learning Workshop","id":"03a834a2-907b-4b72-a067-469dd972d0ec","amount":940.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"a76ade59-68e4-4325-9d3b-6e7f0375af3c":{"categoryId":"75d43f72-95fd-4059-b815-55dcb412727a","waitlistCapacityId":"a76ade59-68e4-4325-9d3b-6e7f0375af3c_waitlist","startTime":"2020-01-27T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"qig6\",\"text\":\"Have you written a few of your own R functions?  Are you ready to start sharing your code (or data) through R packages? Are you curious what you can do to make your first R packages easy for your users to use, and for you to maintain?  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1svai\",\"text\":\"This is a two-day hands on workshop for those who have embraced the tidyverse and now want to expand it to meet their own needs. We'll discuss API design, functional programming tools, the basics of object design in S3, and the tidy eval system for NSE.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"vqo9\",\"text\":\"Learn efficient workflows for developing high-quality R functions, using the set of conventions codified by a package. You'll also learn workflows for unit testing, which helps ensure that your functions do exactly what you think they do.  \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"14lhu\",\"text\":\"Master the art of writing functions that do one thing well and can be fluently combined together to solve more complex problems. We'll cover common function writing pitfalls and how to avoid them.  \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"164r6\",\"text\":\"Learn how to write collections of functions that work well together, and adhere to existing conventions so they're easy to pick up for newcomers.  \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dcj8u\",\"text\":\"You should take this workshop if you have experience programming in R and want to learn how to tackle larger scale problems. You'll get the most from it if you're already familiar with functions and are comfortable with R’s basic data structures (vectors, matrices, arrays, lists, and data frames). Note: There is ~30% overlap in the material with Hadley Wickham's previous \\\"R Masterclass\\\". However, the material has been substantially reorganised, so if you've taken the R Masterclass in the past, you'll still learn a lot in this class.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"e40a8bfe-1322-4f10-949a-3e85628b1701":{"speakerId":"e40a8bfe-1322-4f10-949a-3e85628b1701","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a76ade59-68e4-4325-9d3b-6e7f0375af3c"},"94513fe9-5def-41c2-9cb0-022850f30285":{"speakerId":"94513fe9-5def-41c2-9cb0-022850f30285","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a76ade59-68e4-4325-9d3b-6e7f0375af3c"}},"code":"Workshop1236","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Have you written a few of your own R functions?&nbsp; Are you ready to start sharing your code (or data) through R packages? Are you curious what you can do to make your first R packages easy for your users to use, and for you to maintain?&nbsp;&nbsp;</p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">This is a two-day hands on workshop for those who have embraced the tidyverse and now want to expand it to meet their own needs. We'll discuss API design, functional programming tools, the basics of object design in S3, and the tidy eval system for NSE.&nbsp;&nbsp;</p>\r\n<ul class=\"carina-rte-public-DraftStyleDefault-ul\">\r\n<li>Learn efficient workflows for developing high-quality R functions, using the set of conventions codified by a package. You'll also learn workflows for unit testing, which helps ensure that your functions do exactly what you think they do.&nbsp;&nbsp;</li>\r\n<li>Master the art of writing functions that do one thing well and can be fluently combined together to solve more complex problems. We'll cover common function writing pitfalls and how to avoid them.&nbsp;&nbsp;</li>\r\n<li>Learn how to write collections of functions that work well together, and adhere to existing conventions so they're easy to pick up for newcomers.&nbsp;&nbsp;</li>\r\n</ul>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">You should take this workshop if you have experience programming in R and want to learn how to tackle larger scale problems. You'll get the most from it if you're already familiar with functions and are comfortable with R’s basic data structures (vectors, matrices, arrays, lists, and data frames). Note: There is ~30% overlap in the material with Hadley Wickham's previous \"R Masterclass\". However, the material has been substantially reorganised, so if you've taken the R Masterclass in the past, you'll still learn a lot in this class.</p>\r\n</div></div>","id":"a76ade59-68e4-4325-9d3b-6e7f0375af3c","capacityId":"a76ade59-68e4-4325-9d3b-6e7f0375af3c","name":"Building Tidy Tools Workshop","status":3,"type":"Session","defaultFeeId":"3839c3cb-6984-45cb-8957-29e7a8867405","fees":{"372c5cfc-b87b-41bf-8cd6-c52848d8db59":{"chargePolicies":[{"maximumRefundAmount":940.0,"id":"2113cb5e-4c22-4d7f-8f52-e983370cee03","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":940.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"0de18311-fab1-48de-b689-fd876acbea87","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic Building Tidy Tools Workshop","id":"372c5cfc-b87b-41bf-8cd6-c52848d8db59","amount":940.0,"glCodes":[]},"3839c3cb-6984-45cb-8957-29e7a8867405":{"chargePolicies":[{"maximumRefundAmount":1650.0,"id":"a617cc92-be5f-49ed-bad8-9bb4967e1651","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":1650.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"a44559cb-1a03-4311-9afb-5c972d085194","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"Building Tidy Tools Workshop","id":"3839c3cb-6984-45cb-8957-29e7a8867405","amount":1650.0,"glCodes":[]}},"closedReasonType":"ByCapacity"},"5de2683c-bb4d-46b5-8415-24556b46d105":{"categoryId":"ab3bf356-6dc2-427d-8ca2-110bde05b6f5","waitlistCapacityId":"5de2683c-bb4d-46b5-8415-24556b46d105_waitlist","startTime":"2020-01-28T17:00:00.000Z","endTime":"2020-01-29T01:00:00.000Z","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":["00000000-0000-0000-0000-000000000000","dcf558aa-35e6-419b-a513-2856494f80e3","2ca4373b-d99e-467e-adbd-99afea225a86","1d7d7fbc-4961-4a86-be84-afe206bc8dbf","3059d9ec-f377-4cbd-b800-c32de43d53b9","47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8djt\",\"text\":\"This one-day workshop is the first step toward becoming a certified RStudio trainer.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":84,\"style\":\"color-rgb(0,0,0)\"},{\"offset\":5,\"length\":16,\"style\":\"BOLD\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"53oui\",\"text\":\"RStudio’s instructor training and certification program helps people apply modern evidence-based teaching practices to teach data science using R and RStudio’s products, and helps people who need such training find the trainers they need. Candidates must be proficient in the technical skills and tools they wish to teach\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"344eef0a-8f17-4470-8eae-ea78434d8c52":{"speakerId":"344eef0a-8f17-4470-8eae-ea78434d8c52","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5de2683c-bb4d-46b5-8415-24556b46d105"}},"code":"Workshop1248","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This <span style=\"font-weight: bold;\">one-day workshop</span> is the first step toward becoming a certified RStudio trainer.</span></p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\">RStudio’s instructor training and certification program helps people apply modern evidence-based teaching practices to teach data science using R and RStudio’s products, and helps people who need such training find the trainers they need. Candidates must be proficient in the technical skills and tools they wish to teach</p>\r\n</div></div>","id":"5de2683c-bb4d-46b5-8415-24556b46d105","capacityId":"5de2683c-bb4d-46b5-8415-24556b46d105","name":"RStudio Instructor Training Workshop","status":2,"type":"Session","defaultFeeId":"57d017af-bb62-4a25-85f9-c6893092e063","fees":{"f1c76c02-d684-4029-b46c-24b83841e1cf":{"chargePolicies":[{"maximumRefundAmount":500.0,"id":"23b95c7f-e79c-4465-898c-bcb0b78fd657","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"4f6d5c89-45d6-446d-b00b-06bd742b59e5","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["47e14ab0-6dad-41dc-993f-ea2c7891bec0"],"name":"Academic RStudio Instructor Training Certification Workshop","id":"f1c76c02-d684-4029-b46c-24b83841e1cf","amount":500.0,"glCodes":[]},"57d017af-bb62-4a25-85f9-c6893092e063":{"chargePolicies":[{"maximumRefundAmount":500.0,"id":"7367d9cd-bf4e-48c7-af5e-0dabd6f20258","isActive":true,"effectiveUntil":"2999-12-31T00:00:00.000Z","amount":500.0,"isBeforeCurrentDate":false}],"refundPolicies":[{"refundType":4,"percentage":100.0,"id":"0e02aa94-65cf-4247-9609-6b2c0767b1ea","isActive":true,"effectiveUntil":"2019-10-31T00:00:00.000Z","isBeforeCurrentDate":false}],"isActive":true,"isRefundable":true,"displayOnFeePage":true,"registrationTypes":["3059d9ec-f377-4cbd-b800-c32de43d53b9"],"name":"RStudio Instructor Training Certification Workshop","id":"57d017af-bb62-4a25-85f9-c6893092e063","amount":500.0,"glCodes":[]}},"closedReasonType":"NotClosed"},"430f24c8-2860-4158-840c-49198318dfa2":{"categoryId":"00000000-0000-0000-0000-000000000000","waitlistCapacityId":"430f24c8-2860-4158-840c-49198318dfa2_waitlist","startTime":"2020-01-29T17:00:00.000Z","endTime":"2020-01-29T17:05:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"94513fe9-5def-41c2-9cb0-022850f30285":{"speakerId":"94513fe9-5def-41c2-9cb0-022850f30285","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"430f24c8-2860-4158-840c-49198318dfa2"}},"code":"","description":"","id":"430f24c8-2860-4158-840c-49198318dfa2","capacityId":"430f24c8-2860-4158-840c-49198318dfa2","name":"Welcome to rstudio::conf 2020","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"362fca53-0b9d-462c-b702-ea85c9ea10b2":{"categoryId":"c32f17f6-2464-476b-859b-d8ab4d26556b","waitlistCapacityId":"362fca53-0b9d-462c-b702-ea85c9ea10b2_waitlist","startTime":"2020-01-29T17:05:00.000Z","endTime":"2020-01-29T18:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"469in\",\"text\":\"Open-source software is fundamentally necessary to ensure that the tools of data science are broadly accessible, and to provide a reliable and trustworthy foundation for reproducible research. This talk will delve into why open source software is so important and discuss the role of corporations as stewards of open source software. I'll also talk about how RStudio is structured and organized to pursue its mission of creating open source software for data science.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":467,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ab9d20d5-76aa-4a02-8260-6118b93cc80c":{"speakerId":"ab9d20d5-76aa-4a02-8260-6118b93cc80c","speakerCategoryId":"4d782f1f-021e-4c86-a902-deb06dd7d9ee","sessionId":"362fca53-0b9d-462c-b702-ea85c9ea10b2"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Open-source software is fundamentally necessary to ensure that the tools of data science are broadly accessible, and to provide a reliable and trustworthy foundation for reproducible research. This talk will delve into why open source software is so important and discuss the role of corporations as stewards of open source software. I'll also talk about how RStudio is structured and organized to pursue its mission of creating open source software for data science.</span></p>\r\n</div></div>","id":"362fca53-0b9d-462c-b702-ea85c9ea10b2","capacityId":"362fca53-0b9d-462c-b702-ea85c9ea10b2","name":"Open Source Software for Data Science","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d8d901d9-bdb6-4392-83a9-3ad5addbbf53":{"categoryId":"c32f17f6-2464-476b-859b-d8ab4d26556b","waitlistCapacityId":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53_waitlist","startTime":"2020-01-29T18:00:00.000Z","endTime":"2020-01-29T19:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"bges0\",\"text\":\"Recent progress in machine learning has raised a series of urgent questions: How can we train and debug deep learning models? How can we understand what is going on inside a neural network? And, perhaps most important, how can we design systems that serve people best? We'll show a series of examples from the People+AI Research (PAIR) initiative at Google--ranging from data visualizations for researchers, to tools for medical practitioners, to guidelines for designers--that illustrate how thinking carefully about data can lead to better tools, more effective design, and help humans and AI work together.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":609,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"310ea87b-1917-4252-a3f0-10c737b5a73a":{"speakerId":"310ea87b-1917-4252-a3f0-10c737b5a73a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53"},"3cb4488b-81dd-4ad3-b94a-90987821825c":{"speakerId":"3cb4488b-81dd-4ad3-b94a-90987821825c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Recent progress in machine learning has raised a series of urgent questions: How can we train and debug deep learning models? How can we understand what is going on inside a neural network? And, perhaps most important, how can we design systems that serve people best? We'll show a series of examples from the People+AI Research (PAIR) initiative at Google--ranging from data visualizations for researchers, to tools for medical practitioners, to guidelines for designers--that illustrate how thinking carefully about data can lead to better tools, more effective design, and help humans and AI work together.</span></p>\r\n</div></div>","id":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53","capacityId":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53","name":"Data, visualization, and designing with AI","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"81b467b6-5239-4f3a-b67a-d8f58d33efbc":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"81b467b6-5239-4f3a-b67a-d8f58d33efbc_waitlist","startTime":"2020-01-29T19:30:00.000Z","endTime":"2020-01-29T19:52:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"d4kdg\",\"text\":\"The path to becoming a world-class, data-driven organization is daunting. The challenges you will likely face along the way can be thorny, and in some cases, seem outright impossible to overcome. How do you get teams that traditionally butt heads, such as IT and data science, to complement each other and work in unison? How can you efficiently scale the scope and reach of your data products as requirements change? Your time should be spent doing truly valuable work instead of updating charts and reports. How do you prevent the support structure behind your platform from toppling like a house of cards? Despite these challenges, we think that the end result is worth it: an organization that is equipped to make important decisions, with confidence, using data analysis that comes from a sustainable environment. We see this outcome every day.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":849,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"a0adc9d5-b91f-4594-afa3-c2fc306e725f":{"speakerId":"a0adc9d5-b91f-4594-afa3-c2fc306e725f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"81b467b6-5239-4f3a-b67a-d8f58d33efbc"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The path to becoming a world-class, data-driven organization is daunting. The challenges you will likely face along the way can be thorny, and in some cases, seem outright impossible to overcome. How do you get teams that traditionally butt heads, such as IT and data science, to complement each other and work in unison? How can you efficiently scale the scope and reach of your data products as requirements change? Your time should be spent doing truly valuable work instead of updating charts and reports. How do you prevent the support structure behind your platform from toppling like a house of cards? Despite these challenges, we think that the end result is worth it: an organization that is equipped to make important decisions, with confidence, using data analysis that comes from a sustainable environment. We see this outcome every day.</span></p>\r\n</div></div>","id":"81b467b6-5239-4f3a-b67a-d8f58d33efbc","capacityId":"81b467b6-5239-4f3a-b67a-d8f58d33efbc","name":"Professional Case Studies","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"1a28b485-9971-4c62-ac32-6603f7a6ce35":{"categoryId":"9de8e8e4-8bc5-4410-a290-9dae53e47e5a","waitlistCapacityId":"1a28b485-9971-4c62-ac32-6603f7a6ce35_waitlist","startTime":"2020-01-29T19:30:00.000Z","endTime":"2020-01-29T19:52:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"9ggm1\",\"text\":\"At RStudio, we wake up and go to bed thinking about the positive impact that open source work and data science has had and can have on the world. To maximize this impact, we find three areas of investment absolutely critical to ensure our open source community keeps up with the world’s changes and outlives us all: 1. Find ways to make R more approachable. 2. Enable teams of all types & sizes (educational, professional, etc.) to be able to leverage the work they’re doing in R, and effortlessly communicate that work to others. 3. Extend the language so our open-source community can continue to be at the forefront of innovation, no matter their preference of tool or language. Underpinning these investments is also the core belief that every data scientist, regardless of skill level, use-case, or professional experience, is an asset to our community. Whether you’re a student currently learning R, a Python fan looking to become multilingual, or the Head of Data Science at NASA, we want you to become a part of our journey. In return, we’ll do our best to ensure that journey is a fulfilling endeavor. This presentation will take a deeper dive into the ways in which you can utilize RStudio's educational offerings and enterprise toolchain in personal, educational, and corporate settings. educational offerings and enterprise toolchain in personal, educational, and corporate settings.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1395,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"bc4da16d-1f47-4ded-b84b-d566c8388a8c":{"speakerId":"bc4da16d-1f47-4ded-b84b-d566c8388a8c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"1a28b485-9971-4c62-ac32-6603f7a6ce35"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">At RStudio, we wake up and go to bed thinking about the positive impact that open source work and data science has had and can have on the world. To maximize this impact, we find three areas of investment absolutely critical to ensure our open source community keeps up with the world’s changes and outlives us all: 1. Find ways to make R more approachable. 2. Enable teams of all types &amp; sizes (educational, professional, etc.) to be able to leverage the work they’re doing in R, and effortlessly communicate that work to others. 3. Extend the language so our open-source community can continue to be at the forefront of innovation, no matter their preference of tool or language. Underpinning these investments is also the core belief that every data scientist, regardless of skill level, use-case, or professional experience, is an asset to our community. Whether you’re a student currently learning R, a Python fan looking to become multilingual, or the Head of Data Science at NASA, we want you to become a part of our journey. In return, we’ll do our best to ensure that journey is a fulfilling endeavor. This presentation will take a deeper dive into the ways in which you can utilize RStudio's educational offerings and enterprise toolchain in personal, educational, and corporate settings. educational offerings and enterprise toolchain in personal, educational, and corporate settings.</span></p>\r\n</div></div>","id":"1a28b485-9971-4c62-ac32-6603f7a6ce35","capacityId":"1a28b485-9971-4c62-ac32-6603f7a6ce35","name":"Meet You Where You R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"4f68c74e-57cc-4ce4-b940-0730ce426b4d":{"categoryId":"9d4be07d-7f4d-4fd4-bcf2-b8bdc223ed4a","waitlistCapacityId":"4f68c74e-57cc-4ce4-b940-0730ce426b4d_waitlist","startTime":"2020-01-29T19:30:00.000Z","endTime":"2020-01-29T19:52:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"951c6\",\"text\":\"It’s easier than ever to craft a complete R-centric data science pipeline thanks to packages like Shiny, Plumber, and Pins. In this talk, you’ll learn how to use R to bring your modeling and visualization work into production. You’ll walk away with recipes, tips, and tricks to deploy data, models, and apps to ensure your work is as impactful as possible.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":356,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9ed5b98b-e100-4c38-b6f3-0642bba6c3b9":{"speakerId":"9ed5b98b-e100-4c38-b6f3-0642bba6c3b9","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4f68c74e-57cc-4ce4-b940-0730ce426b4d"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">It’s easier than ever to craft a complete R-centric data science pipeline thanks to packages like Shiny, Plumber, and Pins. In this talk, you’ll learn how to use R to bring your modeling and visualization work into production. You’ll walk away with recipes, tips, and tricks to deploy data, models, and apps to ensure your work is as impactful as possible.</span></p>\r\n</div></div>","id":"4f68c74e-57cc-4ce4-b940-0730ce426b4d","capacityId":"4f68c74e-57cc-4ce4-b940-0730ce426b4d","name":"Deploying End-To-End Data Science with Shiny, Plumber, and Pins","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"0b879607-6d0d-4e66-8811-e8b853f79624":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"0b879607-6d0d-4e66-8811-e8b853f79624_waitlist","startTime":"2020-01-29T19:30:00.000Z","endTime":"2020-01-29T19:52:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"2b17ffe6-3bef-4162-bd8d-af5120a9b29d":{"speakerId":"2b17ffe6-3bef-4162-bd8d-af5120a9b29d","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"0b879607-6d0d-4e66-8811-e8b853f79624"}},"code":"","description":"Ensuring the quality of data we deliver to customers or provide as inputs to models is often one of the most under-appreciated and yet time-consuming responsibilities of a modern data scientist. This task is challenging enough when working with static data, but when we have access to dynamic, longitudinal, continuously updating data, that complexity can become an asset. We will demonstrate how to to simplify data quality monitoring of dynamic data with a functional programming approach that enables early and actionable detection of data quality concerns. \r\n\r\nUsing purrr as well as tidyr and nested tibbles, we will illustrate the five key pillars of enjoyable, user-friendly data quality monitoring with relevant R code: Readability, Reproducibility, Efficiency, Robustness, and Compositionality. \r\n\r\nReadability: FP empowers us to abstract away from the mechanics and implementation of comparing two or more related datasets and move towards declaring the intent of features and metrics we want to compare. \r\n\r\nReproducibility: By avoiding side-effects and dependencies on external states and inputs, and using functional units which can be easily tested over a variety of inputs, FP reduces the burden to create reproducible code. Perhaps more importantly, FP supports not just reproducibility of results, but reproducibility of workflows that can be continually applied to dynamic datasets.\r\n\r\nEfficiency: FP enables more efficient code through lazy evaluation, caching, and simplifying implementation over parallel backends.\r\n\r\nRobustness: FP allows greater testability of our code through modularization and elegant error-handling, with customized fail-safes for data that differs in expected ways over time. \r\n\r\nCompositionality: FP encourages higher-level reasoning with functions, which in turn drives both readability--through higher-level, more abstract code--and robustness, through modifying function behavior in case errors are encountered.","id":"0b879607-6d0d-4e66-8811-e8b853f79624","capacityId":"0b879607-6d0d-4e66-8811-e8b853f79624","name":"Simplified Data Quality Monitoring of Dynamic Longitudinal Data: A Functional Programming Approach","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"ed336435-51ae-4af8-adc0-4e755d531fca":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"ed336435-51ae-4af8-adc0-4e755d531fca_waitlist","startTime":"2020-01-29T19:53:00.000Z","endTime":"2020-01-29T20:15:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"18vr0\",\"text\":\"Vibrant Emotional Health is the mental health not-for-profit behind the US National Suicide Prevention Lifeline, New York City's NYC Well program, and various other emotional health contact center programs and direct services. We engage in emotionally charged conversations with people experiencing a wide variety of mental health and emotional concerns, our programs vary in scope, in resources, and span several technologies. In addition, our data collection and reporting requirements change dynamically in response to emerging clinical needs and reporting requirements from our sponsors. In short, the data we collect is complex, often unstructured, and stored in a variety of sources. In this context, R Markdown Documents have allowed us to interface directly with multiple databases, Google Sheets, API's, csv's, and JSON stores to generate integrated reports. Organizing these reports into R packages with accompanying functions that standardize the calculation of KPI's and apply consistent themes across analyses has allowed us to improve the clarity and aesthetics of our reporting while reducing manual work that was previously needed to produce these reports. Building on this framework we have developed functions to standardize data connections, create reusable data visualizations, and generate reproducible analyses in response to ad hoc analytic requests. These same functions also facilitate the creation of Shiny dashboards where core visualizations that were previously only available in static reports can be manipulated directly by end users to explore clinical and operational trends. These dashboards also facilitate self service reporting by end users. We present here the framework we have developed for our organization wide and program specific packages, the types of functions and artifacts they include and our plans for future development.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1871,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"382be892-5c7a-4180-a151-64070cdf4d73":{"speakerId":"382be892-5c7a-4180-a151-64070cdf4d73","speakerCategoryId":"4d782f1f-021e-4c86-a902-deb06dd7d9ee","sessionId":"ed336435-51ae-4af8-adc0-4e755d531fca"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Vibrant Emotional Health is the mental health not-for-profit behind the US National Suicide Prevention Lifeline, New York City's NYC Well program, and various other emotional health contact center programs and direct services. We engage in emotionally charged conversations with people experiencing a wide variety of mental health and emotional concerns, our programs vary in scope, in resources, and span several technologies. In addition, our data collection and reporting requirements change dynamically in response to emerging clinical needs and reporting requirements from our sponsors. In short, the data we collect is complex, often unstructured, and stored in a variety of sources. In this context, R Markdown Documents have allowed us to interface directly with multiple databases, Google Sheets, API's, csv's, and JSON stores to generate integrated reports. Organizing these reports into R packages with accompanying functions that standardize the calculation of KPI's and apply consistent themes across analyses has allowed us to improve the clarity and aesthetics of our reporting while reducing manual work that was previously needed to produce these reports. Building on this framework we have developed functions to standardize data connections, create reusable data visualizations, and generate reproducible analyses in response to ad hoc analytic requests. These same functions also facilitate the creation of Shiny dashboards where core visualizations that were previously only available in static reports can be manipulated directly by end users to explore clinical and operational trends. These dashboards also facilitate self service reporting by end users. We present here the framework we have developed for our organization wide and program specific packages, the types of functions and artifacts they include and our plans for future development.</span></p>\r\n</div></div>","id":"ed336435-51ae-4af8-adc0-4e755d531fca","capacityId":"ed336435-51ae-4af8-adc0-4e755d531fca","name":"How Vibrant Emotional Health Connected Siloed Data Sources and Streamlined Reporting Using R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"dd568377-e7e0-4baf-b63e-470e13508466":{"categoryId":"9de8e8e4-8bc5-4410-a290-9dae53e47e5a","waitlistCapacityId":"dd568377-e7e0-4baf-b63e-470e13508466_waitlist","startTime":"2020-01-29T19:53:00.000Z","endTime":"2020-01-29T20:15:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"d2u0p\",\"text\":\"More people are learning data science every day, and there are more ways for them to learn than ever before. To understand where we are and where we might be going, this talk looks at what data science education could look like two years from now: far enough away that we can dream, but close enough that we can only dream a little. We explore the balance between automated and collaborative learning, different ways to deliver different kinds of lessons to different kinds of people, and ways in which our tools and practices could improve.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":541,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"344eef0a-8f17-4470-8eae-ea78434d8c52":{"speakerId":"344eef0a-8f17-4470-8eae-ea78434d8c52","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"dd568377-e7e0-4baf-b63e-470e13508466"},"4a239a86-4d24-46f4-b7a0-e1b9379fdd8d":{"speakerId":"4a239a86-4d24-46f4-b7a0-e1b9379fdd8d","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"dd568377-e7e0-4baf-b63e-470e13508466"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">More people are learning data science every day, and there are more ways for them to learn than ever before. To understand where we are and where we might be going, this talk looks at what data science education could look like two years from now: far enough away that we can dream, but close enough that we can only dream a little. We explore the balance between automated and collaborative learning, different ways to deliver different kinds of lessons to different kinds of people, and ways in which our tools and practices could improve.</span></p>\r\n</div></div>","id":"dd568377-e7e0-4baf-b63e-470e13508466","capacityId":"dd568377-e7e0-4baf-b63e-470e13508466","name":"Data Science Education in 2022","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a572c454-fd91-4ed3-8609-abd06af157c4":{"categoryId":"9d4be07d-7f4d-4fd4-bcf2-b8bdc223ed4a","waitlistCapacityId":"a572c454-fd91-4ed3-8609-abd06af157c4_waitlist","startTime":"2020-01-29T19:53:00.000Z","endTime":"2020-01-29T20:15:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"5b4ah\",\"text\":\"Often reserved for Elite Engineers, production can be a perilous place for R users - but never fear! For the past year, we at T-Mobile have been sludging through production outages, nation-wide product launches, and all of the muck that floods from R models being hit over a million times every day. From “we’re strictly a java shop” to a devops team that proudly states “we support Java, node, and R,” this talk will cover the technical hiccups, interdisciplinary communication struggles, and an open-source R package {loadtest} that’s changed the way our team views performance testing. You too can dazzle your enterprise with the power of R.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":644,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"f11fc94d-d195-4fe7-9889-d67452120afe":{"speakerId":"f11fc94d-d195-4fe7-9889-d67452120afe","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a572c454-fd91-4ed3-8609-abd06af157c4"},"8fafd7f1-850b-4b49-9c7e-a15ea1509baa":{"speakerId":"8fafd7f1-850b-4b49-9c7e-a15ea1509baa","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a572c454-fd91-4ed3-8609-abd06af157c4"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Often reserved for Elite Engineers, production can be a perilous place for R users - but never fear! For the past year, we at T-Mobile have been sludging through production outages, nation-wide product launches, and all of the muck that floods from R models being hit over a million times every day. From “we’re strictly a java shop” to a devops team that proudly states “we support Java, node, and R,” this talk will cover the technical hiccups, interdisciplinary communication struggles, and an open-source R package {loadtest} that’s changed the way our team views performance testing. You too can dazzle your enterprise with the power of R.</span></p>\r\n</div></div>","id":"a572c454-fd91-4ed3-8609-abd06af157c4","capacityId":"a572c454-fd91-4ed3-8609-abd06af157c4","name":"We’re hitting R a million times a day so we made a talk about it","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"90ef231d-c201-41cb-a91e-8918c05b22d7":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"90ef231d-c201-41cb-a91e-8918c05b22d7_waitlist","startTime":"2020-01-29T19:53:00.000Z","endTime":"2020-01-29T20:15:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8mcss\",\"text\":\"The base R types of vectors enable the representation of an amazingly wide array of data types. There is so much you can do with R. However, there may be times when your data does not fit into one of the base types and/or you want to add metadata to vectors. vctrs is a developer-focused package that provides a clear path for creating your own S3-vector class, while ensuring that the classes you build integrate into user expectations for how vectors work in R. This presentation will discuss the why and how of using vctrs through the example of debkeepr, a package for integrating historical non-decimal currencies such as pounds, shillings, and pence into R. The presentation will provide a step-by-step process for developing various types of vectors and thinking through the design process of how vectors of different classes should work together.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":854,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"92547efc-70e2-4d5c-be9f-16f93f41752b":{"speakerId":"92547efc-70e2-4d5c-be9f-16f93f41752b","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"90ef231d-c201-41cb-a91e-8918c05b22d7"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The base R types of vectors enable the representation of an amazingly wide array of data types. There is so much you can do with R. However, there may be times when your data does not fit into one of the base types and/or you want to add metadata to vectors. vctrs is a developer-focused package that provides a clear path for creating your own S3-vector class, while ensuring that the classes you build integrate into user expectations for how vectors work in R. This presentation will discuss the why and how of using vctrs through the example of debkeepr, a package for integrating historical non-decimal currencies such as pounds, shillings, and pence into R. The presentation will provide a step-by-step process for developing various types of vectors and thinking through the design process of how vectors of different classes should work together.</span></p>\r\n</div></div>","id":"90ef231d-c201-41cb-a91e-8918c05b22d7","capacityId":"90ef231d-c201-41cb-a91e-8918c05b22d7","name":"vctrs: Creating custom vector classes with the vctrs package","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9071622c-13bc-4f15-964a-8d3b537a248e":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"9071622c-13bc-4f15-964a-8d3b537a248e_waitlist","startTime":"2020-01-29T20:16:00.000Z","endTime":"2020-01-29T20:38:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"4i4q0\",\"text\":\"We have recently implemented a new Data Science workflow and pipeline, using RStudio Connect and Google Cloud Services. This has vastly decreased our pipeline complexity, allowing us to bring our models and products into scheduled production more quickly. In addition, our workflow, working closely together as a team on all projects on a regular two-week sprint cycle, has increased the range of projects we have been able to take on and complete. To detail some of the key lessons we’ve learned (and some of the difficulties!), we’ll walk you through one of our recent sprints, where we productionalised the generation of a suite of behavioural and demographic features so that they can be more easily plugged in to a range of models and used across the business by the FT’s platform and product teams.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":804,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9353eba8-5276-4ed9-bd7a-d4e1519b7a68":{"speakerId":"9353eba8-5276-4ed9-bd7a-d4e1519b7a68","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9071622c-13bc-4f15-964a-8d3b537a248e"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">We have recently implemented a new Data Science workflow and pipeline, using RStudio Connect and Google Cloud Services. This has vastly decreased our pipeline complexity, allowing us to bring our models and products into scheduled production more quickly. In addition, our workflow, working closely together as a team on all projects on a regular two-week sprint cycle, has increased the range of projects we have been able to take on and complete. To detail some of the key lessons we’ve learned (and some of the difficulties!), we’ll walk you through one of our recent sprints, where we productionalised the generation of a suite of behavioural and demographic features so that they can be more easily plugged in to a range of models and used across the business by the FT’s platform and product teams.</span></p>\r\n</div></div>","id":"9071622c-13bc-4f15-964a-8d3b537a248e","capacityId":"9071622c-13bc-4f15-964a-8d3b537a248e","name":"Building a new data science pipeline for the FT with RStudio Connect","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"b6430542-cb37-4d31-8371-42ad803918ca":{"categoryId":"9de8e8e4-8bc5-4410-a290-9dae53e47e5a","waitlistCapacityId":"b6430542-cb37-4d31-8371-42ad803918ca_waitlist","startTime":"2020-01-29T20:16:00.000Z","endTime":"2020-01-29T20:38:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"af38dc10-e426-4829-8fa2-c91672923a6c":{"speakerId":"af38dc10-e426-4829-8fa2-c91672923a6c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b6430542-cb37-4d31-8371-42ad803918ca"}},"code":"","description":"","id":"b6430542-cb37-4d31-8371-42ad803918ca","capacityId":"b6430542-cb37-4d31-8371-42ad803918ca","name":"Data science education as an economic and public health intervention in East Baltimore","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"ad815977-9392-4542-8274-f006cf237fcc":{"categoryId":"9d4be07d-7f4d-4fd4-bcf2-b8bdc223ed4a","waitlistCapacityId":"ad815977-9392-4542-8274-f006cf237fcc_waitlist","startTime":"2020-01-29T20:16:00.000Z","endTime":"2020-01-29T20:38:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"bp4ae\",\"text\":\"Salesforce is not only a cloud software solution out of the box, but also a highly customizable platform that can be modified for a wide range of use cases. In addition to complexity, customer trust is our #1 company value and customer data privacy is abstracted from everyone outside of the customer. Product and Growth Analytics is an emerging field separate from business analytics and data science and focuses on building software product that improve user retention and engagement. Companies like Facebook and AirBnB have robust data science teams focused on product analytics. At Salesforce however, given the scale, customization, and privacy values, product data science is not so straightforward. Utilizing R and Rstudio tools for collaboration and reproducible analytics, the Data Intelligence team is able to solve complex problems at enterprise scale. This talk will preview anonymized predictive and growth analytics work while also highlighting how we work and collaborate cross platform and languages (Python via reticulate).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1040,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"00d26e91-3676-4357-b2a9-6b950f9ff785":{"speakerId":"00d26e91-3676-4357-b2a9-6b950f9ff785","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"ad815977-9392-4542-8274-f006cf237fcc"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Salesforce is not only a cloud software solution out of the box, but also a highly customizable platform that can be modified for a wide range of use cases. In addition to complexity, customer trust is our #1 company value and customer data privacy is abstracted from everyone outside of the customer. Product and Growth Analytics is an emerging field separate from business analytics and data science and focuses on building software product that improve user retention and engagement. Companies like Facebook and AirBnB have robust data science teams focused on product analytics. At Salesforce however, given the scale, customization, and privacy values, product data science is not so straightforward. Utilizing R and Rstudio tools for collaboration and reproducible analytics, the Data Intelligence team is able to solve complex problems at enterprise scale. This talk will preview anonymized predictive and growth analytics work while also highlighting how we work and collaborate cross platform and languages (Python via reticulate).</span></p>\r\n</div></div>","id":"ad815977-9392-4542-8274-f006cf237fcc","capacityId":"ad815977-9392-4542-8274-f006cf237fcc","name":"Growth Hacking with R - Product Analytics at Scale using R and RStudio","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"5fec742c-53f3-45b6-8c87-ff4bad5e5257":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"5fec742c-53f3-45b6-8c87-ff4bad5e5257_waitlist","startTime":"2020-01-29T20:16:00.000Z","endTime":"2020-01-29T20:38:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"u0og\",\"text\":\"Writing regular R code is straightforward: you tell R to do something, it does it, and then it returns control back to you. This is called synchronous programming. However, if you use R to coordinate threads, processes, or network communication, the regular model may be unable to do what you want, or it may only be able to do it with a significant performance penalty. In this talk I'll explain how asynchronous programming with the later package can handle these kinds of programming problems. I'll also show how to provide a synchronous interface for asynchronous code, so that users will have a simple, familiar way to use your code.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":401,\"length\":12,\"style\":\"ITALIC\"},{\"offset\":435,\"length\":5,\"style\":\"BOLD\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"8966aa31-9858-4e54-bb51-be3a156a0f98":{"speakerId":"8966aa31-9858-4e54-bb51-be3a156a0f98","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5fec742c-53f3-45b6-8c87-ff4bad5e5257"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\">Writing regular R code is straightforward: you tell R to do something, it does it, and then it returns control back to you. This is called synchronous programming. However, if you use R to coordinate threads, processes, or network communication, the regular model may be unable to do what you want, or it may only be able to do it with a significant performance penalty. In this talk I'll explain how <span style=\"font-style: italic;\">asynchronous</span> programming with the <span style=\"font-weight: bold;\">later</span> package can handle these kinds of programming problems. I'll also show how to provide a synchronous interface for asynchronous code, so that users will have a simple, familiar way to use your code.</p>\r\n</div></div>","id":"5fec742c-53f3-45b6-8c87-ff4bad5e5257","capacityId":"5fec742c-53f3-45b6-8c87-ff4bad5e5257","name":"Asynchronous programming in R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"577654d1-fcb3-4f67-9be3-bc46ab816ce3":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"577654d1-fcb3-4f67-9be3-bc46ab816ce3_waitlist","startTime":"2020-01-29T20:39:00.000Z","endTime":"2020-01-29T20:59:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"3u3h4\",\"text\":\"Anyone reading a newspaper or listening to the news is led to believe that AI is the solution to all problems. From self-driving cars to detecting disease to catching fraud, there doesn’t seem to be a situation that AI can’t tackle. Once “big data” is thrown into the mix, the AI solution is all but certain. But is AI always needed? Over the last eighteen months, Jumping Rivers has entered (and won) four Hackathons. All Hackathons were characterised with “big data” and the need to improve prediction. All Hackathons were won without using AI (or any sort of machine learning). This talk will focus on one particular competition around reducing leakage at Northumbrian Water. Using a combination of R, Shiny, and tidyverse (and a few other tricks), we were able to demonstrate within the short Hackathon time frame that clear presentation of data to the front line engineers was more likely to reduce leakage, than simply providing vague estimates of a potential future leak\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":977,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"5de96bf0-a129-44ca-90c9-7f38c18e9740":{"speakerId":"5de96bf0-a129-44ca-90c9-7f38c18e9740","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"577654d1-fcb3-4f67-9be3-bc46ab816ce3"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Anyone reading a newspaper or listening to the news is led to believe that AI is the solution to all problems. From self-driving cars to detecting disease to catching fraud, there doesn’t seem to be a situation that AI can’t tackle. Once “big data” is thrown into the mix, the AI solution is all but certain. But is AI always needed? Over the last eighteen months, Jumping Rivers has entered (and won) four Hackathons. All Hackathons were characterised with “big data” and the need to improve prediction. All Hackathons were won without using AI (or any sort of machine learning). This talk will focus on one particular competition around reducing leakage at Northumbrian Water. Using a combination of R, Shiny, and tidyverse (and a few other tricks), we were able to demonstrate within the short Hackathon time frame that clear presentation of data to the front line engineers was more likely to reduce leakage, than simply providing vague estimates of a potential future leak</span></p>\r\n</div></div>","id":"577654d1-fcb3-4f67-9be3-bc46ab816ce3","capacityId":"577654d1-fcb3-4f67-9be3-bc46ab816ce3","name":"How to win an AI Hackathon, without using AI","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d":{"categoryId":"9de8e8e4-8bc5-4410-a290-9dae53e47e5a","waitlistCapacityId":"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d_waitlist","startTime":"2020-01-29T20:39:00.000Z","endTime":"2020-01-29T20:59:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"563vb\",\"text\":\"How do you make your R Markdown lessons feel friendly for learners you’ll never meet? How do you make it engaging so they sit and stay a while? How do you make it memorable so they come back to visit again? In this talk, I’ll share lessons learned from my experience of making a series of online statistics modules (co-authored by Hasse Walum) that feel accessible and fun-- housed entirely in an R Markdown site, complete with a whimsical, illustrated narrative about teacup giraffes. I’ll show how adding good characters with your audience in mind, good design, and good play helped me make the most of HTML output. To help you get started, I’ll share resources that Alison Hill and I have developed--including a series of cookbooks and out-of-the-box templates-- so that you will have a leg up on applying these ideas to R Markdown collections of your own.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":859,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"66a9b678-6bd0-472e-8be2-9acb40643c09":{"speakerId":"66a9b678-6bd0-472e-8be2-9acb40643c09","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">How do you make your R Markdown lessons feel friendly for learners you’ll never meet? How do you make it engaging so they sit and stay a while? How do you make it memorable so they come back to visit again? In this talk, I’ll share lessons learned from my experience of making a series of online statistics modules (co-authored by Hasse Walum) that feel accessible and fun-- housed entirely in an R Markdown site, complete with a whimsical, illustrated narrative about teacup giraffes. I’ll show how adding good characters with your audience in mind, good design, and good play helped me make the most of HTML output. To help you get started, I’ll share resources that Alison Hill and I have developed--including a series of cookbooks and out-of-the-box templates-- so that you will have a leg up on applying these ideas to R Markdown collections of your own.</span></p>\r\n</div></div>","id":"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d","capacityId":"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d","name":"Of Teacups, Giraffes, & R Markdown","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"cbe85c76-9313-43d7-bcd3-ba4f7816526f":{"categoryId":"9d4be07d-7f4d-4fd4-bcf2-b8bdc223ed4a","waitlistCapacityId":"cbe85c76-9313-43d7-bcd3-ba4f7816526f_waitlist","startTime":"2020-01-29T20:39:00.000Z","endTime":"2020-01-29T20:59:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7hfrq\",\"text\":\"Plumber is a package that allows R users to create APIs out of R functions. This flexible approach allows R processes to be accessed by toolchains and frameworks outside of R. In this talk, we'll look at useful patterns for developing and working with robust APIs built in R using Plumber.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"3ba212f6-f5f0-4fb5-92ab-b7757878486f":{"speakerId":"3ba212f6-f5f0-4fb5-92ab-b7757878486f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"cbe85c76-9313-43d7-bcd3-ba4f7816526f"}},"code":"","description":"Plumber is a package that allows R users to create APIs out of R functions. This flexible approach allows R processes to be accessed by toolchains and frameworks outside of R. In this talk, we'll look at useful patterns for developing and working with robust APIs built in R using Plumber.","id":"cbe85c76-9313-43d7-bcd3-ba4f7816526f","capacityId":"cbe85c76-9313-43d7-bcd3-ba4f7816526f","name":"Practical Plumber Patterns","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"f6bc2b7a-ea99-4778-a513-9659f50c9d68":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"f6bc2b7a-ea99-4778-a513-9659f50c9d68_waitlist","startTime":"2020-01-29T20:39:00.000Z","endTime":"2020-01-29T20:59:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"12a25\",\"text\":\"Open source R packages on GitHub often take advantage of continuous integration services to automatically check their packages for errors. This is very useful to catch things quickly, as well and increasing confidence for proposed changes, as the Pull Requests can be checked before they are merged. Travis-CI and Appveyor are the most popular current methods. However newer services, Azure Pipelines and GitHub Actions, show promise for being more powerful and simpler to configure and debug. I will discuss these services and demonstrate some of their capabilities and how to configure them for your own use in packages and reports.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"27dc49c5-976c-4b86-a4fa-af4a24b7030c":{"speakerId":"27dc49c5-976c-4b86-a4fa-af4a24b7030c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"f6bc2b7a-ea99-4778-a513-9659f50c9d68"}},"code":"","description":"Open source R packages on GitHub often take advantage of continuous integration services to automatically check their packages for errors. This is very useful to catch things quickly, as well and increasing confidence for proposed changes, as the Pull Requests can be checked before they are merged. Travis-CI and Appveyor are the most popular current methods. However newer services, Azure Pipelines and GitHub Actions, show promise for being more powerful and simpler to configure and debug. I will discuss these services and demonstrate some of their capabilities and how to configure them for your own use in packages and reports.","id":"f6bc2b7a-ea99-4778-a513-9659f50c9d68","capacityId":"f6bc2b7a-ea99-4778-a513-9659f50c9d68","name":"Azure Pipelines and GitHub Actions","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"03d95381-eafd-47d2-9fc5-1603b17254ae":{"categoryId":"6d12298b-53af-4b4d-88b6-bb95130cbcb2","waitlistCapacityId":"03d95381-eafd-47d2-9fc5-1603b17254ae_waitlist","startTime":"2020-01-29T22:15:00.000Z","endTime":"2020-01-29T22:37:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"3798i\",\"text\":\"Why did you learn R? Chances are good that if you're an attendee of rstudio::conf, you've found a community of R coders who are willing to share their knowledge and learn with you. While it's possible to develop expert R coding skills in isolation, most software development and data analysis projects benefit from groups of people working collaboratively, and R communities are unparalleled in their inclusivity and commitment to learning collectively. Such communities, whether they support R coders at a single institution, geographic region, or online, require deliberate planning and effort to develop and sustain. How do you create a group culture that encompasses R users of various skill levels who may be working on diverse problems? How do you assess what members of a community need or prefer? How do you encourage investment and cohesion so the group will sustain itself? This talk will describe potential pitfalls and impediments to creating and facilitating cooperative learning communities for R coding, and will allow you to identify potential strategies for overcoming these challenges so you can continue giving back to the R communities that supported you along the way.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1189,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"618952a5-70b2-4d46-a94a-97adebc8784c":{"speakerId":"618952a5-70b2-4d46-a94a-97adebc8784c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"03d95381-eafd-47d2-9fc5-1603b17254ae"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Why did you learn R? Chances are good that if you're an attendee of rstudio::conf, you've found a community of R coders who are willing to share their knowledge and learn with you. While it's possible to develop expert R coding skills in isolation, most software development and data analysis projects benefit from groups of people working collaboratively, and R communities are unparalleled in their inclusivity and commitment to learning collectively. Such communities, whether they support R coders at a single institution, geographic region, or online, require deliberate planning and effort to develop and sustain. How do you create a group culture that encompasses R users of various skill levels who may be working on diverse problems? How do you assess what members of a community need or prefer? How do you encourage investment and cohesion so the group will sustain itself? This talk will describe potential pitfalls and impediments to creating and facilitating cooperative learning communities for R coding, and will allow you to identify potential strategies for overcoming these challenges so you can continue giving back to the R communities that supported you along the way.</span></p>\r\n</div></div>","id":"03d95381-eafd-47d2-9fc5-1603b17254ae","capacityId":"03d95381-eafd-47d2-9fc5-1603b17254ae","name":"If you build it, they will come...but then what? Facilitating communities of practice in R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"e056bbd6-c45e-4d83-bfb8-6878748f9984":{"categoryId":"ee69d256-3431-4764-9a02-05542b84f62c","waitlistCapacityId":"e056bbd6-c45e-4d83-bfb8-6878748f9984_waitlist","startTime":"2020-01-29T22:15:00.000Z","endTime":"2020-01-29T22:37:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cj5f7\",\"text\":\"Use of R in the investment industry is established and growing. This talk will discuss changes seen in 15 years of practice within asset management firms. I hope discussion of lessons learned and recommendations will benefit those currently in finance and those interested in hearing how the flexibility of R manifests in the financial world.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":342,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"5d02373a-2f00-4929-bb50-0be2a8c2a25a":{"speakerId":"5d02373a-2f00-4929-bb50-0be2a8c2a25a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"e056bbd6-c45e-4d83-bfb8-6878748f9984"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Use of R in the investment industry is established and growing. This talk will discuss changes seen in 15 years of practice within asset management firms. I hope discussion of lessons learned and recommendations will benefit those currently in finance and those interested in hearing how the flexibility of R manifests in the financial world.</span></p>\r\n</div></div>","id":"e056bbd6-c45e-4d83-bfb8-6878748f9984","capacityId":"e056bbd6-c45e-4d83-bfb8-6878748f9984","name":"15 Years of R in Quantitative Finance","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9ee77f71-184c-40e2-b7cf-c0974427749b":{"categoryId":"7e8567f3-f428-4618-8b11-80600b5a4fc1","waitlistCapacityId":"9ee77f71-184c-40e2-b7cf-c0974427749b_waitlist","startTime":"2020-01-29T22:15:00.000Z","endTime":"2020-01-29T22:37:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"93tji\",\"text\":\"The Apache Arrow project is a cross-language development platform for in-memory data designed to improve system performance, memory use, and interoperability. This talk presents recent developments in the 'arrow' package, which provides an R interface to the Arrow C++ library. We'll cover the goals of the broader Arrow project, how to get started with the 'arrow' package in R, some general concepts for working with data efficiently in Arrow, and a brief overview of upcoming features.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":488,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"7bac5f42-bf76-47da-b4c3-1a9eccf70722":{"speakerId":"7bac5f42-bf76-47da-b4c3-1a9eccf70722","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9ee77f71-184c-40e2-b7cf-c0974427749b"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The Apache Arrow project is a cross-language development platform for in-memory data designed to improve system performance, memory use, and interoperability. This talk presents recent developments in the 'arrow' package, which provides an R interface to the Arrow C++ library. We'll cover the goals of the broader Arrow project, how to get started with the 'arrow' package in R, some general concepts for working with data efficiently in Arrow, and a brief overview of upcoming features.</span></p>\r\n</div></div>","id":"9ee77f71-184c-40e2-b7cf-c0974427749b","capacityId":"9ee77f71-184c-40e2-b7cf-c0974427749b","name":"Accelerating Analytics with Apache Arrow","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"4723a69d-7a95-4e44-94bf-964972e221cf":{"categoryId":"ca4b6aec-4d63-4c6e-b368-d553e77a6497","waitlistCapacityId":"4723a69d-7a95-4e44-94bf-964972e221cf_waitlist","startTime":"2020-01-29T22:15:00.000Z","endTime":"2020-01-29T22:38:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ft9da\",\"text\":\"Shiny is an amazing tool when it comes to creating web applications with R. Almost anybody can get a small Shiny App in a matter of minutes, provided they have a basic knowledge of R. As of today, we can safely tell that it has become the de-facto tool for web application in the R world. Building a proof-of-concept application is easy, but things change when the application becomes larger and more complex, and especially when it comes to sending that app to production—until recently there hasn't been any real framework for building and deploying production-grade Shiny Apps. This is where 'golem' comes into play: offering Shiny developers an opinionated framework for creating production-ready Shiny Applications. With 'golem', Shiny developers now have a toolkit for making a stable, easy-to-maintain, and robust for production web application with R. 'golem' has been developed to abstract away the most common engineering tasks (for example, module creation, addition of external CSS or JavaScript file, ...), so you can focus on what matters: building the application. And once your application is ready to be deployed, 'golem' guides you through testing, and brings you tools for deploying to common platforms. In this talk, Colin and Vincent will present the 'golem' package, first talking about the \\\"why 'golem'?\\\", then presenting the general philosophy behind this framework, and help you get started building your first Shiny App with 'golem'.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1459,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"a8e73fa2-28c9-4292-ac25-4e69a5137573":{"speakerId":"a8e73fa2-28c9-4292-ac25-4e69a5137573","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4723a69d-7a95-4e44-94bf-964972e221cf"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Shiny is an amazing tool when it comes to creating web applications with R. Almost anybody can get a small Shiny App in a matter of minutes, provided they have a basic knowledge of R. As of today, we can safely tell that it has become the de-facto tool for web application in the R world. Building a proof-of-concept application is easy, but things change when the application becomes larger and more complex, and especially when it comes to sending that app to production—until recently there hasn't been any real framework for building and deploying production-grade Shiny Apps. This is where 'golem' comes into play: offering Shiny developers an opinionated framework for creating production-ready Shiny Applications. With 'golem', Shiny developers now have a toolkit for making a stable, easy-to-maintain, and robust for production web application with R. 'golem' has been developed to abstract away the most common engineering tasks (for example, module creation, addition of external CSS or JavaScript file, ...), so you can focus on what matters: building the application. And once your application is ready to be deployed, 'golem' guides you through testing, and brings you tools for deploying to common platforms. In this talk, Colin and Vincent will present the 'golem' package, first talking about the \"why 'golem'?\", then presenting the general philosophy behind this framework, and help you get started building your first Shiny App with 'golem'.</span></p>\r\n</div></div>","id":"4723a69d-7a95-4e44-94bf-964972e221cf","capacityId":"4723a69d-7a95-4e44-94bf-964972e221cf","name":"Production-grade Shiny Apps with golem","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"facdb7b2-d84f-4db6-ba51-9bb39daef896":{"categoryId":"6d12298b-53af-4b4d-88b6-bb95130cbcb2","waitlistCapacityId":"facdb7b2-d84f-4db6-ba51-9bb39daef896_waitlist","startTime":"2020-01-29T22:38:00.000Z","endTime":"2020-01-29T23:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"al4dp\",\"text\":\"Geospatial analysts work in a wide range of positions within almost every industry. They work in government, non-profit, academic, and private institutions using geospatial data and technology to answer questions about the environment, agriculture, climate, urban planning and design, marketing, public health, transportation, and myriad other topics. A typical day may include data prep/cleaning, field work, cartography, image analysis, vector analysis, feature engineering, modeling, or database management. This diverse group necessarily uses a diverse set of tools. In this talk, we will explore how R fits into the spatial analyst’s toolkit. What does the geo community think of R? Who uses it? What groups avoid it? What geo-packages are used most? How can we, as a community, make R more appealing for geospatial scientists?\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":832,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d1cde307-d6f7-43c4-9a0b-1853acb7ebef":{"speakerId":"d1cde307-d6f7-43c4-9a0b-1853acb7ebef","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"facdb7b2-d84f-4db6-ba51-9bb39daef896"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Geospatial analysts work in a wide range of positions within almost every industry. They work in government, non-profit, academic, and private institutions using geospatial data and technology to answer questions about the environment, agriculture, climate, urban planning and design, marketing, public health, transportation, and myriad other topics. A typical day may include data prep/cleaning, field work, cartography, image analysis, vector analysis, feature engineering, modeling, or database management. This diverse group necessarily uses a diverse set of tools. In this talk, we will explore how R fits into the spatial analyst’s toolkit. What does the geo community think of R? Who uses it? What groups avoid it? What geo-packages are used most? How can we, as a community, make R more appealing for geospatial scientists?</span></p>\r\n</div></div>","id":"facdb7b2-d84f-4db6-ba51-9bb39daef896","capacityId":"facdb7b2-d84f-4db6-ba51-9bb39daef896","name":"Embracing R in the Geospatial Community","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"3b1ed201-fae3-4986-b31b-3bc0b855a881":{"categoryId":"ee69d256-3431-4764-9a02-05542b84f62c","waitlistCapacityId":"3b1ed201-fae3-4986-b31b-3bc0b855a881_waitlist","startTime":"2020-01-29T22:38:00.000Z","endTime":"2020-01-29T23:00:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8cdfu\",\"text\":\"China has been experiencing rapid growth over the last decade due to economically friendly reforms and a growing skilled and young population. With this increasing growth, China’s interconnectedness with the global economy has increased significantly. In parallel to this economic evolution, technology has experienced rapid acceleration, which has enabled firms and governments to track and record vast amounts of data. The side effect of this unstructured big data growth is that datasets may be polluted, meaning information can be conflicting, missing, and/or unreliable. This creates a gap in the ability to provide transparency to the exposed firms importing from China: both timely early warning signals and wide coverage of small- and medium-sized enterprises (SMEs). We have been able to address this problem for our end-users by using deep learning to extract information value and opinion from a public corpus to create the needed transparency. Our data science & machine learning stack uses connect, shiny, reticulate, tensorflow and scikit-learn to build the interactive solution to our clients and deploy it using spark and airflow.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1146,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"6c548ae8-dc0f-45bb-afae-38204bcaac24":{"speakerId":"6c548ae8-dc0f-45bb-afae-38204bcaac24","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"3b1ed201-fae3-4986-b31b-3bc0b855a881"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">China has been experiencing rapid growth over the last decade due to economically friendly reforms and a growing skilled and young population. With this increasing growth, China’s interconnectedness with the global economy has increased significantly. In parallel to this economic evolution, technology has experienced rapid acceleration, which has enabled firms and governments to track and record vast amounts of data. The side effect of this unstructured big data growth is that datasets may be polluted, meaning information can be conflicting, missing, and/or unreliable. This creates a gap in the ability to provide transparency to the exposed firms importing from China: both timely early warning signals and wide coverage of small- and medium-sized enterprises (SMEs). We have been able to address this problem for our end-users by using deep learning to extract information value and opinion from a public corpus to create the needed transparency. Our data science &amp; machine learning stack uses connect, shiny, reticulate, tensorflow and scikit-learn to build the interactive solution to our clients and deploy it using spark and airflow.</span></p>\r\n</div></div>","id":"3b1ed201-fae3-4986-b31b-3bc0b855a881","capacityId":"3b1ed201-fae3-4986-b31b-3bc0b855a881","name":"Deep Learning Extraction for Counterparty Risk Signals from a Corpus of Millions of Documents","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"7ae003b1-016e-4706-9dd0-60bec53ab0b4":{"categoryId":"7e8567f3-f428-4618-8b11-80600b5a4fc1","waitlistCapacityId":"7ae003b1-016e-4706-9dd0-60bec53ab0b4_waitlist","startTime":"2020-01-29T22:38:00.000Z","endTime":"2020-01-29T23:00:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"2d5709df-4584-46f9-9e14-aefce656db42":{"speakerId":"2d5709df-4584-46f9-9e14-aefce656db42","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"7ae003b1-016e-4706-9dd0-60bec53ab0b4"}},"code":"","description":"","id":"7ae003b1-016e-4706-9dd0-60bec53ab0b4","capacityId":"7ae003b1-016e-4706-9dd0-60bec53ab0b4","name":"Updates on Spark, MLflow, and the broader ML ecosystem","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"5ac2387d-4ea5-48ac-90a1-8b9333eb7592":{"categoryId":"ca4b6aec-4d63-4c6e-b368-d553e77a6497","waitlistCapacityId":"5ac2387d-4ea5-48ac-90a1-8b9333eb7592_waitlist","startTime":"2020-01-29T22:38:00.000Z","endTime":"2020-01-29T23:00:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ashvr\",\"text\":\"In January 2019 RStudio launched the first-ever Shiny contest to recognize outstanding Shiny applications and to share them with the community. We received 136 submissions for the contest and reviewing them was incredibly inspiring and humbling. In this talk, we shine a spotlight on the backstage: the inspiration behind the contest, the process of evaluation, what we learned about Shiny developers and how we can better support them, and what we learned about running contests and how we hope to improve the Shiny Contest experience. We also highlight some of the winning apps as well as the newly revamped Shiny Gallery, which features many noteworthy contest submissions. Finally, we introduce the new process for submitting your apps to the Shiny Gallery and, of course, to Shiny Contest 2020!\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":799,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"199e49f7-dbc2-4165-b700-4a47dc09bba2":{"speakerId":"199e49f7-dbc2-4165-b700-4a47dc09bba2","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5ac2387d-4ea5-48ac-90a1-8b9333eb7592"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In January 2019 RStudio launched the first-ever Shiny contest to recognize outstanding Shiny applications and to share them with the community. We received 136 submissions for the contest and reviewing them was incredibly inspiring and humbling. In this talk, we shine a spotlight on the backstage: the inspiration behind the contest, the process of evaluation, what we learned about Shiny developers and how we can better support them, and what we learned about running contests and how we hope to improve the Shiny Contest experience. We also highlight some of the winning apps as well as the newly revamped Shiny Gallery, which features many noteworthy contest submissions. Finally, we introduce the new process for submitting your apps to the Shiny Gallery and, of course, to Shiny Contest 2020!</span></p>\r\n</div></div>","id":"5ac2387d-4ea5-48ac-90a1-8b9333eb7592","capacityId":"5ac2387d-4ea5-48ac-90a1-8b9333eb7592","name":"Making the Shiny Contest","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"0455609a-cf61-44d1-a95b-3b97080c32a4":{"categoryId":"6d12298b-53af-4b4d-88b6-bb95130cbcb2","waitlistCapacityId":"0455609a-cf61-44d1-a95b-3b97080c32a4_waitlist","startTime":"2020-01-29T23:01:00.000Z","endTime":"2020-01-29T23:23:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"5a4de23e-972c-40d3-9687-f3a933398f2e":{"speakerId":"5a4de23e-972c-40d3-9687-f3a933398f2e","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"0455609a-cf61-44d1-a95b-3b97080c32a4"}},"code":"","description":"","id":"0455609a-cf61-44d1-a95b-3b97080c32a4","capacityId":"0455609a-cf61-44d1-a95b-3b97080c32a4","name":"The development of \"datos\" package for the R4DS Spanish translation","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2":{"categoryId":"ee69d256-3431-4764-9a02-05542b84f62c","waitlistCapacityId":"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2_waitlist","startTime":"2020-01-29T23:01:00.000Z","endTime":"2020-01-29T23:23:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"e2s7v\",\"text\":\"The idea of rpanda commodities trading simulation was many years in the making. As energy trading professionals working in the industry, we had developed insights around how to make risk/reward market calls, and what skills make someone an exceptional commodities trader. Traders are one of the most expensive seats in terms of monetizing value from the assets. We developed rpanda as a simulated environment which replicates closely how real-life physical commodities trading works in order to assist talent development and selection, both in academics and enterprise. My co-founder and I did not know how to design production-ready software, but we always had used R/Shiny for market analysis in our corporate jobs. Rather than hiring expensive app developers, we decided to do it ourselves. We used Rstudio development stack such as Rstudio Connect and open source tools, like plumber to turn our idea into a production-ready app that is used by University of Alberta classes. In this presentation, we share our journey, technical challenges, and how we overcame them.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1071,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"b2a4577f-0faa-434c-9a1b-5c3c52416f57":{"speakerId":"b2a4577f-0faa-434c-9a1b-5c3c52416f57","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The idea of rpanda commodities trading simulation was many years in the making. As energy trading professionals working in the industry, we had developed insights around how to make risk/reward market calls, and what skills make someone an exceptional commodities trader. Traders are one of the most expensive seats in terms of monetizing value from the assets. We developed rpanda as a simulated environment which replicates closely how real-life physical commodities trading works in order to assist talent development and selection, both in academics and enterprise. My co-founder and I did not know how to design production-ready software, but we always had used R/Shiny for market analysis in our corporate jobs. Rather than hiring expensive app developers, we decided to do it ourselves. We used Rstudio development stack such as Rstudio Connect and open source tools, like plumber to turn our idea into a production-ready app that is used by University of Alberta classes. In this presentation, we share our journey, technical challenges, and how we overcame them.</span></p>\r\n</div></div>","id":"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2","capacityId":"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2","name":"Rpanda trading simulation - from an idea to a multi-user shiny app","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"23235ff7-392d-430f-802c-4b4c849c8d0f":{"categoryId":"7e8567f3-f428-4618-8b11-80600b5a4fc1","waitlistCapacityId":"23235ff7-392d-430f-802c-4b4c849c8d0f_waitlist","startTime":"2020-01-29T23:01:00.000Z","endTime":"2020-01-29T23:23:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"576sl\",\"text\":\"TensorFlow is the most popular open-source platform for machine learning and it's ecosystem is evolving incredibly fast. In this talk we will explore what's new in TensorFlow 2.0 as well as how to build data pre-processing pipelines using the tfdatasets package and how to use pre-trained models with tfhub.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":307,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d384be03-51c1-4c0b-986f-dbd272c041a4":{"speakerId":"d384be03-51c1-4c0b-986f-dbd272c041a4","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"23235ff7-392d-430f-802c-4b4c849c8d0f"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">TensorFlow is the most popular open-source platform for machine learning and it's ecosystem is evolving incredibly fast. In this talk we will explore what's new in TensorFlow 2.0 as well as how to build data pre-processing pipelines using the tfdatasets package and how to use pre-trained models with tfhub.</span></p>\r\n</div></div>","id":"23235ff7-392d-430f-802c-4b4c849c8d0f","capacityId":"23235ff7-392d-430f-802c-4b4c849c8d0f","name":"What's new in TensorFlow for R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"b8e20e44-a193-494a-9ee7-4183d4bfa583":{"categoryId":"ca4b6aec-4d63-4c6e-b368-d553e77a6497","waitlistCapacityId":"b8e20e44-a193-494a-9ee7-4183d4bfa583_waitlist","startTime":"2020-01-29T23:01:00.000Z","endTime":"2020-01-29T23:23:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"5hq0g\",\"text\":\"Customizing the style--fonts, colors, margins, spacing--of Shiny apps has always been possible, but never as easy as we’d like it to be. Canned themes like those in the shinythemes package can easily make apps look slightly less generic, but that’s small consolation if your goal is to match the visual style of your university, corporation, or client.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":352,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6kabl\",\"text\":\"In theory, one can \\\"just\\\" use CSS to customize the appearance of your Shiny app, the same as any other web application. But in practice, the use of large CSS frameworks like Bootstrap means significant CSS expertise is required to comprehensively change the look of an app.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":273,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8o26v\",\"text\":\"Relief is on the way. As part of a round of upgrades to Shiny’s UI, we’ve made fundamental changes to the way R users can interact with CSS, using new R packages we’ve created around Sass and Bootstrap 4. In this talk, we’ll show some of the features of these packages and tell you how you can take advantage of them in your apps.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":330,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"38f60138-f7e7-49fd-ae5c-e606279ebf4a":{"speakerId":"38f60138-f7e7-49fd-ae5c-e606279ebf4a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b8e20e44-a193-494a-9ee7-4183d4bfa583"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Customizing the style--fonts, colors, margins, spacing--of Shiny apps has always been possible, but never as easy as we’d like it to be. Canned themes like those in the shinythemes package can easily make apps look slightly less generic, but that’s small consolation if your goal is to match the visual style of your university, corporation, or client.</span></p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In theory, one can \"just\" use CSS to customize the appearance of your Shiny app, the same as any other web application. But in practice, the use of large CSS frameworks like Bootstrap means significant CSS expertise is required to comprehensively change the look of an app.</span></p>\r\n<p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Relief is on the way. As part of a round of upgrades to Shiny’s UI, we’ve made fundamental changes to the way R users can interact with CSS, using new R packages we’ve created around Sass and Bootstrap 4. In this talk, we’ll show some of the features of these packages and tell you how you can take advantage of them in your apps.</span></p>\r\n</div></div>","id":"b8e20e44-a193-494a-9ee7-4183d4bfa583","capacityId":"b8e20e44-a193-494a-9ee7-4183d4bfa583","name":"Styling Shiny apps with Sass and Bootstrap 4","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d":{"categoryId":"6d12298b-53af-4b4d-88b6-bb95130cbcb2","waitlistCapacityId":"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d_waitlist","startTime":"2020-01-29T23:24:00.000Z","endTime":"2020-01-29T23:44:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dhrbn\",\"text\":\"R has changed a lot since the meetup was founded 10 years ago. Back then we were using base graphics (or lattice) and the apply family of functions and we didn't have pipes. At the time there was an impressive 1800 packages on CRAN, now there are over 15,000 extending R's reach far beyond its traditional domain of statistics and machine learning into publishing, website building and video generation. The community has grown and changed dramatically during that time, with the New York meetup alone going from 25 to over 10,000 members. During this talk we go through a then-and-now of R code and community to palpably see how everything has changed.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":653,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"0b47a32e-40b7-4ce9-90e3-8048e7beab3f":{"speakerId":"0b47a32e-40b7-4ce9-90e3-8048e7beab3f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">R has changed a lot since the meetup was founded 10 years ago. Back then we were using base graphics (or lattice) and the apply family of functions and we didn't have pipes. At the time there was an impressive 1800 packages on CRAN, now there are over 15,000 extending R's reach far beyond its traditional domain of statistics and machine learning into publishing, website building and video generation. The community has grown and changed dramatically during that time, with the New York meetup alone going from 25 to over 10,000 members. During this talk we go through a then-and-now of R code and community to palpably see how everything has changed.</span></p>\r\n</div></div>","id":"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d","capacityId":"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d","name":"R: Then and Now","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"dde422a6-90a4-4afa-af7a-035a7f876737":{"categoryId":"ee69d256-3431-4764-9a02-05542b84f62c","waitlistCapacityId":"dde422a6-90a4-4afa-af7a-035a7f876737_waitlist","startTime":"2020-01-29T23:24:00.000Z","endTime":"2020-01-29T23:44:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"j30o\",\"text\":\"A collection of data science stories about current problems that data scientists might face while working in academia, industry, and government. Some lessons learned, some situations avoided, what I learned, and how I survived my journey. First, I discuss the struggle of advocating for R when senior leaders decide Python is the only appropriate product. Then, I describe why donut charts are superior to pie charts, and why we should all be using them. Finally, the case of the uncatchable “drive-by” stakeholder and where to find them. The fight is real, and the path is long for the evangelical data scientist.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":614,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"305f12c6-3857-4e4c-805d-f943b568fc65":{"speakerId":"305f12c6-3857-4e4c-805d-f943b568fc65","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"dde422a6-90a4-4afa-af7a-035a7f876737"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">A collection of data science stories about current problems that data scientists might face while working in academia, industry, and government. Some lessons learned, some situations avoided, what I learned, and how I survived my journey. First, I discuss the struggle of advocating for R when senior leaders decide Python is the only appropriate product. Then, I describe why donut charts are superior to pie charts, and why we should all be using them. Finally, the case of the uncatchable “drive-by” stakeholder and where to find them. The fight is real, and the path is long for the evangelical data scientist.</span></p>\r\n</div></div>","id":"dde422a6-90a4-4afa-af7a-035a7f876737","capacityId":"dde422a6-90a4-4afa-af7a-035a7f876737","name":"The good, the bad and the ugly: What I learned while consulting across the business as a data scient","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"2a03d211-bb38-4617-a4c9-48ff1e9ab273":{"categoryId":"7e8567f3-f428-4618-8b11-80600b5a4fc1","waitlistCapacityId":"2a03d211-bb38-4617-a4c9-48ff1e9ab273_waitlist","startTime":"2020-01-29T23:24:00.000Z","endTime":"2020-01-29T23:44:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"ace50785-992b-46f2-be1b-0c64793be1d3":{"speakerId":"ace50785-992b-46f2-be1b-0c64793be1d3","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"2a03d211-bb38-4617-a4c9-48ff1e9ab273"}},"code":"","description":"","id":"2a03d211-bb38-4617-a4c9-48ff1e9ab273","capacityId":"2a03d211-bb38-4617-a4c9-48ff1e9ab273","name":"Deep Learning with R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"0bc552f1-b70a-439c-90cc-4f3c83b45b10":{"categoryId":"ca4b6aec-4d63-4c6e-b368-d553e77a6497","waitlistCapacityId":"0bc552f1-b70a-439c-90cc-4f3c83b45b10_waitlist","startTime":"2020-01-29T23:24:00.000Z","endTime":"2020-01-29T23:44:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"b8vc0\",\"text\":\"Shiny makes it easy to take domain logic from an existing R script and wrap some reactive logic around it to produce an interactive webpage where others can quickly explore different variables, parameter values, models/algorithms, etc. Although the interactivity is great for many reasons, once an interesting result is found, it’s more difficult to prove the correctness of the result since: (1) the result can only be (easily) reproduced via the Shiny app and (2) the relevant domain logic which produced the result is obscured by Shiny’s reactive logic. The R package shinymeta provides tools for capturing and exporting domain logic for execution outside of a Shiny runtime (so that others can reproduce Shiny-based result(s) from a new R session).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"84e9776e-dce6-4bb8-a8dc-5a4781426409":{"speakerId":"84e9776e-dce6-4bb8-a8dc-5a4781426409","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"0bc552f1-b70a-439c-90cc-4f3c83b45b10"}},"code":"","description":"Shiny makes it easy to take domain logic from an existing R script and wrap some reactive logic around it to produce an interactive webpage where others can quickly explore different variables, parameter values, models/algorithms, etc. Although the interactivity is great for many reasons, once an interesting result is found, it’s more difficult to prove the correctness of the result since: (1) the result can only be (easily) reproduced via the Shiny app and (2) the relevant domain logic which produced the result is obscured by Shiny’s reactive logic. The R package shinymeta provides tools for capturing and exporting domain logic for execution outside of a Shiny runtime (so that others can reproduce Shiny-based result(s) from a new R session).","id":"0bc552f1-b70a-439c-90cc-4f3c83b45b10","capacityId":"0bc552f1-b70a-439c-90cc-4f3c83b45b10","name":"Reproducible Shiny apps with shinymeta","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"914fa687-23c1-45ae-8a2f-fa5889cc9f20":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"914fa687-23c1-45ae-8a2f-fa5889cc9f20_waitlist","startTime":"2020-01-30T00:00:00.000Z","endTime":"2020-01-30T00:23:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"aajch\",\"text\":\"The Associated Press data team primarily uses R and the tidyverse as the main tool for doing data processing and analysis. In this talk, some of the technology behind the published stories will be showcased: - Using dbplyr to work off a hosted database containing 380 million opioid records to identify \\\"pill mills\\\". - Using open-sourced AP style templates for R Markdown and ggplot to quickly produce graphics and reports off breaking news. - Using R Markdown and htmlwidgets to give reporters and editors interactive reports to identify reporting leads.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":555,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9a0c0ac7-f3a5-4aa1-bce7-41aa5db40b09":{"speakerId":"9a0c0ac7-f3a5-4aa1-bce7-41aa5db40b09","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"914fa687-23c1-45ae-8a2f-fa5889cc9f20"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The Associated Press data team primarily uses R and the tidyverse as the main tool for doing data processing and analysis. In this talk, some of the technology behind the published stories will be showcased: - Using dbplyr to work off a hosted database containing 380 million opioid records to identify \"pill mills\". - Using open-sourced AP style templates for R Markdown and ggplot to quickly produce graphics and reports off breaking news. - Using R Markdown and htmlwidgets to give reporters and editors interactive reports to identify reporting leads.</span></p>\r\n</div></div>","id":"914fa687-23c1-45ae-8a2f-fa5889cc9f20","capacityId":"914fa687-23c1-45ae-8a2f-fa5889cc9f20","name":"Journalism with RStudio, R, and the tidyverse","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"b023451f-66c2-42c2-be21-18cd10ba3ef8":{"categoryId":"9541ec43-0d38-4c2a-a1d3-765a3e1d1e01","waitlistCapacityId":"b023451f-66c2-42c2-be21-18cd10ba3ef8_waitlist","startTime":"2020-01-30T00:00:00.000Z","endTime":"2020-01-30T00:22:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cu0u2\",\"text\":\"Good examples facilitate accomplishing new or unpracticed tasks in a programmatic workflow. Tools for communicating examples have improved in recent years. Especially embraced are tools that show code and its resultant output immediately thereafter --- the case of `Jupytr` notebooks and `Rmarkdown` documents. But creators using these tools often must choose between big-picture or narrow-focus demonstration; creators tend to either demo a complete code pipeline that accomplishes a realistic task or instead demonstrate a minimal example which makes clear the behavior of a particular function, but how it might be used in a larger project isn't clear. Flipbooks help address this problem, allowing the creator to present a full demonstration which accomplishes a real task, and gives the viewer the opportunity to focus on unfamiliar steps. A set of flipbook building functions parse code in a data manipulation or visualization pipeline and then build it back up incrementally. Aligned superimposition of new code and output atop previous code and output makes it easy to identify how each code change triggers changes in output. The presentation will guide attendees in creating their own Flipbooks (with Xaringan slides) or mini Flipbooks (gif output).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1259,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"563c4d6b-fc98-4f4f-8e18-44178550310d":{"speakerId":"563c4d6b-fc98-4f4f-8e18-44178550310d","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b023451f-66c2-42c2-be21-18cd10ba3ef8"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Good examples facilitate accomplishing new or unpracticed tasks in a programmatic workflow. Tools for communicating examples have improved in recent years. Especially embraced are tools that show code and its resultant output immediately thereafter --- the case of `Jupytr` notebooks and `Rmarkdown` documents. But creators using these tools often must choose between big-picture or narrow-focus demonstration; creators tend to either demo a complete code pipeline that accomplishes a realistic task or instead demonstrate a minimal example which makes clear the behavior of a particular function, but how it might be used in a larger project isn't clear. Flipbooks help address this problem, allowing the creator to present a full demonstration which accomplishes a real task, and gives the viewer the opportunity to focus on unfamiliar steps. A set of flipbook building functions parse code in a data manipulation or visualization pipeline and then build it back up incrementally. Aligned superimposition of new code and output atop previous code and output makes it easy to identify how each code change triggers changes in output. The presentation will guide attendees in creating their own Flipbooks (with Xaringan slides) or mini Flipbooks (gif output).</span></p>\r\n</div></div>","id":"b023451f-66c2-42c2-be21-18cd10ba3ef8","capacityId":"b023451f-66c2-42c2-be21-18cd10ba3ef8","name":"Flipbooks","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"89a098cc-e64c-478d-815f-77acab171676":{"categoryId":"7662541c-fece-41e8-9d2a-d2364454886c","waitlistCapacityId":"89a098cc-e64c-478d-815f-77acab171676_waitlist","startTime":"2020-01-30T00:00:00.000Z","endTime":"2020-01-30T00:22:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8cc2e\",\"text\":\"In this talk I will discuss the steps that have been created for validating internally generated R packages at SCHARP (Statistical Center for HIV/AIDS Research and Prevention) and the lessons learned while creating packages as a team. Housed within Fred Hutch, SCHARP is an instrumental partner in the research and clinical trials surrounding HIV prevention and vaccine development. Part of SCHARP’s work involves analyzing experimental biomarkers and endpoints which change as the experimental question, analysis methods, antigens measured, and assays evolve. Maintaining a validated code base that is rigid in its output format, but flexible enough to cater a variety of inputs with minimal custom coding has proven to be important for reproducibility and scalability. SCHARP has developed several key steps in the creation, validation, and documentation of R packages that take advantage of R’s packaging functionality. First, the programming team works with leadership to define specifications and lay out a roadmap of the package at the functional level. Next, statistical programmers work together to develop the package, taking advantage of the rich R ecosystem of packages for development such as roxygen2, devtools, usethis, and testthat. Once the code has been developed, the package is validated to ensure it passes all specifications using a combination of testthat and rmarkdown. Finally, the package is made available for use across the team on live data. These procedures set up a framework for validating assay processing packages that furthers the ability of Fred Hutch to provide world-class support for our clinical trials.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1642,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ba3190cf-bbed-4201-b023-bac630dbbdfd":{"speakerId":"ba3190cf-bbed-4201-b023-bac630dbbdfd","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"89a098cc-e64c-478d-815f-77acab171676"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In this talk I will discuss the steps that have been created for validating internally generated R packages at SCHARP (Statistical Center for HIV/AIDS Research and Prevention) and the lessons learned while creating packages as a team. Housed within Fred Hutch, SCHARP is an instrumental partner in the research and clinical trials surrounding HIV prevention and vaccine development. Part of SCHARP’s work involves analyzing experimental biomarkers and endpoints which change as the experimental question, analysis methods, antigens measured, and assays evolve. Maintaining a validated code base that is rigid in its output format, but flexible enough to cater a variety of inputs with minimal custom coding has proven to be important for reproducibility and scalability. SCHARP has developed several key steps in the creation, validation, and documentation of R packages that take advantage of R’s packaging functionality. First, the programming team works with leadership to define specifications and lay out a roadmap of the package at the functional level. Next, statistical programmers work together to develop the package, taking advantage of the rich R ecosystem of packages for development such as roxygen2, devtools, usethis, and testthat. Once the code has been developed, the package is validated to ensure it passes all specifications using a combination of testthat and rmarkdown. Finally, the package is made available for use across the team on live data. These procedures set up a framework for validating assay processing packages that furthers the ability of Fred Hutch to provide world-class support for our clinical trials.</span></p>\r\n</div></div>","id":"89a098cc-e64c-478d-815f-77acab171676","capacityId":"89a098cc-e64c-478d-815f-77acab171676","name":"Approaches to Assay Processing Package Validation","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"8e583082-de3d-4ba0-90c7-5b0a42c0b28e":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"8e583082-de3d-4ba0-90c7-5b0a42c0b28e_waitlist","startTime":"2020-01-30T00:00:00.000Z","endTime":"2020-01-30T00:22:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"avi2f\",\"text\":\"One of the greatest strength of R is the ease and speed of developing a prototype (let it be a report or dashboard, a statistical model or rule-based automation to solve a business problem etc), but deploying to production is not a broadly discussed topic despite its importance. This hands-on talk focuses on best practices and actual R packages to help transforming the prototypes developed by business analysts and data scientist into production jobs running in a secured and monitored environment that is easy to maintain -- discussing the importance of logging, securing credentials, effective helper functions to connect to database, open-source and SaaS job schedulers, dockerizing the run environment and scaling infrastructure.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":736,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ad82990a-8836-47a2-9de0-b27fe3f8811f":{"speakerId":"ad82990a-8836-47a2-9de0-b27fe3f8811f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"8e583082-de3d-4ba0-90c7-5b0a42c0b28e"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">One of the greatest strength of R is the ease and speed of developing a prototype (let it be a report or dashboard, a statistical model or rule-based automation to solve a business problem etc), but deploying to production is not a broadly discussed topic despite its importance. This hands-on talk focuses on best practices and actual R packages to help transforming the prototypes developed by business analysts and data scientist into production jobs running in a secured and monitored environment that is easy to maintain -- discussing the importance of logging, securing credentials, effective helper functions to connect to database, open-source and SaaS job schedulers, dockerizing the run environment and scaling infrastructure.</span></p>\r\n</div></div>","id":"8e583082-de3d-4ba0-90c7-5b0a42c0b28e","capacityId":"8e583082-de3d-4ba0-90c7-5b0a42c0b28e","name":"Getting things logged","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"ccae356c-f8ba-4549-ad55-5a1993a446b0":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"ccae356c-f8ba-4549-ad55-5a1993a446b0_waitlist","startTime":"2020-01-30T00:23:00.000Z","endTime":"2020-01-30T00:45:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"813md\",\"text\":\"Currently in football many hours are spent watching game film to manually label the routes run on passing plays. Using tracking data, each route can be described as a sequence of spatial-temporal measurements that varies in length depending on the duration of the play. This data can be conveniently analyzed using nested columns in tidyr and purrr. We demonstrate how model-based curve clustering using Bernstein polynomial basis functions (i.e. Bézier curves) fit using the Expectation Maximization algorithm can cluster route trajectories. Each cluster can then be labelled to obtain route names for each route and create route trees for all receivers. The clusters and routes can be visualized nicely using ggplot and seen developing over time using gganimate.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":764,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"f8e500bd-d563-43b7-ab66-b4fee19a5096":{"speakerId":"f8e500bd-d563-43b7-ab66-b4fee19a5096","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"ccae356c-f8ba-4549-ad55-5a1993a446b0"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Currently in football many hours are spent watching game film to manually label the routes run on passing plays. Using tracking data, each route can be described as a sequence of spatial-temporal measurements that varies in length depending on the duration of the play. This data can be conveniently analyzed using nested columns in tidyr and purrr. We demonstrate how model-based curve clustering using Bernstein polynomial basis functions (i.e. Bézier curves) fit using the Expectation Maximization algorithm can cluster route trajectories. Each cluster can then be labelled to obtain route names for each route and create route trees for all receivers. The clusters and routes can be visualized nicely using ggplot and seen developing over time using gganimate.</span></p>\r\n</div></div>","id":"ccae356c-f8ba-4549-ad55-5a1993a446b0","capacityId":"ccae356c-f8ba-4549-ad55-5a1993a446b0","name":"Putting the Fun in Functional Data: A tidy pipeline to identify routes in NFL tracking data","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d":{"categoryId":"9541ec43-0d38-4c2a-a1d3-765a3e1d1e01","waitlistCapacityId":"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d_waitlist","startTime":"2020-01-30T00:23:00.000Z","endTime":"2020-01-30T00:45:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"18qd8\",\"text\":\"What should you name a new dinosaur discovery, according to neural networks? Which season of The Golden Girls should you watch when playing a drinking game? How can you build a LEGO set for the lowest price? R is constantly evolving, so as users, we’re constantly learning. Over the past few years, I’ve found that working on side projects is great for hands-on learning - and for me, the more absurd the project, the better. Side projects provide a safe, low-stakes environment to learn new packages and methodologies before using them in work or in production. Sharing those projects can help publicize the package and increase its accessibility, benefiting both the original author and future users. In this talk, I’ll share my experiences with side projects for learning state-of-the-art data science tools and growing as an R user, including how one project helped me land my dream job.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":891,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{\"text-align\":\"left\"}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ebc06011-c15c-4e2a-a95b-b9faf8e02d42":{"speakerId":"ebc06011-c15c-4e2a-a95b-b9faf8e02d42","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p style=\"text-align:left;\" class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">What should you name a new dinosaur discovery, according to neural networks? Which season of The Golden Girls should you watch when playing a drinking game? How can you build a LEGO set for the lowest price? R is constantly evolving, so as users, we’re constantly learning. Over the past few years, I’ve found that working on side projects is great for hands-on learning - and for me, the more absurd the project, the better. Side projects provide a safe, low-stakes environment to learn new packages and methodologies before using them in work or in production. Sharing those projects can help publicize the package and increase its accessibility, benefiting both the original author and future users. In this talk, I’ll share my experiences with side projects for learning state-of-the-art data science tools and growing as an R user, including how one project helped me land my dream job.</span></p>\r\n</div></div>","id":"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d","capacityId":"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d","name":"Learning R with humorous side projects","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"5c780b5f-34ed-44c3-9c96-9e64637f8703":{"categoryId":"7662541c-fece-41e8-9d2a-d2364454886c","waitlistCapacityId":"5c780b5f-34ed-44c3-9c96-9e64637f8703_waitlist","startTime":"2020-01-30T00:23:00.000Z","endTime":"2020-01-30T00:45:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7lq8u\",\"text\":\"As companies are becoming aware of the need to embrace data-driven solutions, R has gained a huge momentum over recent years. Getting the insights to users has become a very important factor of Data Scientist work. While our world has advanced there is a need to build not only web applications, but also applications on mobile that are available offline. We would like to share with you how within months we have gone from nothing to a production-ready application that handles 500 concurrent users in healthcare. There are plenty of challenges to solve including restricted environments, internal processes and users availability. We will show you how to overcome them and iterate fast, navigating through complex infrastructure and integrating with proxy architecture to serve applications to end users in compliant manner. With RStudio Connect and Plumber you can deploy a scalable REST API that can feed insights to your users. This allows you to go one step further and implement native applications for tablets and smartphones. With the right tools, mindset and priorities you can achieve personal success by introducing a digital transformation within your organization, starting with something as small as converting a business critical Excel file that is slow, difficult to edit and maintain, to a robust application. Step by step your organization will evolve and become empowered by your insights uncovering even more untapped potential.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1449,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"b6213ab2-fbea-4172-b95f-df90676c07fe":{"speakerId":"b6213ab2-fbea-4172-b95f-df90676c07fe","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5c780b5f-34ed-44c3-9c96-9e64637f8703"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">As companies are becoming aware of the need to embrace data-driven solutions, R has gained a huge momentum over recent years. Getting the insights to users has become a very important factor of Data Scientist work. While our world has advanced there is a need to build not only web applications, but also applications on mobile that are available offline. We would like to share with you how within months we have gone from nothing to a production-ready application that handles 500 concurrent users in healthcare. There are plenty of challenges to solve including restricted environments, internal processes and users availability. We will show you how to overcome them and iterate fast, navigating through complex infrastructure and integrating with proxy architecture to serve applications to end users in compliant manner. With RStudio Connect and Plumber you can deploy a scalable REST API that can feed insights to your users. This allows you to go one step further and implement native applications for tablets and smartphones. With the right tools, mindset and priorities you can achieve personal success by introducing a digital transformation within your organization, starting with something as small as converting a business critical Excel file that is slow, difficult to edit and maintain, to a robust application. Step by step your organization will evolve and become empowered by your insights uncovering even more untapped potential.</span></p>\r\n</div></div>","id":"5c780b5f-34ed-44c3-9c96-9e64637f8703","capacityId":"5c780b5f-34ed-44c3-9c96-9e64637f8703","name":"Building a native iPad dashboard using plumber and RStudio Connect in Pharma","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"09d8197b-cb6a-4b38-a345-3bb8231d3d9f":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"09d8197b-cb6a-4b38-a345-3bb8231d3d9f_waitlist","startTime":"2020-01-30T00:23:00.000Z","endTime":"2020-01-30T00:45:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2b984\",\"text\":\"Technical debt is a big problem for the R community. Even though R has excellent support for testing, documentation and packaging code it has the reputation that it is not suitable for production applications because data scientists don’t pay enough attention to technical debt within their codebases. Most people think of technical debt as an engineering problem. We choose to make our current work cheaper at the expense of needing to do more work down the road. But when you look closely at the root causes of technical debt they are almost always about interpersonal relationships. Developers have trouble empathizing with other users of their code and so don’t spend the time to make that code easy for future developers to use and understand. In this talk I argue that we should think about technical debt as a social problem because it gives us insight into why it’s so hard to pay back. I then provide a practical roadmap of how to introduce best practices into your data science team.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":993,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"75c0de49-1d22-466f-9a80-0d9993af6ad6":{"speakerId":"75c0de49-1d22-466f-9a80-0d9993af6ad6","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"09d8197b-cb6a-4b38-a345-3bb8231d3d9f"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Technical debt is a big problem for the R community. Even though R has excellent support for testing, documentation and packaging code it has the reputation that it is not suitable for production applications because data scientists don’t pay enough attention to technical debt within their codebases. Most people think of technical debt as an engineering problem. We choose to make our current work cheaper at the expense of needing to do more work down the road. But when you look closely at the root causes of technical debt they are almost always about interpersonal relationships. Developers have trouble empathizing with other users of their code and so don’t spend the time to make that code easy for future developers to use and understand. In this talk I argue that we should think about technical debt as a social problem because it gives us insight into why it’s so hard to pay back. I then provide a practical roadmap of how to introduce best practices into your data science team.</span></p>\r\n</div></div>","id":"09d8197b-cb6a-4b38-a345-3bb8231d3d9f","capacityId":"09d8197b-cb6a-4b38-a345-3bb8231d3d9f","name":"Technical debt is a social problem","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"ad69c123-b268-4016-b58a-57f1901bb1ab":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"ad69c123-b268-4016-b58a-57f1901bb1ab_waitlist","startTime":"2020-01-30T00:46:00.000Z","endTime":"2020-01-30T01:08:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"99s5b\",\"text\":\"This talk will use a case study, most likely in hockey, to showcase the many ways in which R and the tidyverse can be used to analyze sports data as well as the unique priorities and considerations that are involved in applying statistical tools to sports problems.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":265,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d4ae5183-6bb6-452b-a85b-8a5da1af15c9":{"speakerId":"d4ae5183-6bb6-452b-a85b-8a5da1af15c9","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"ad69c123-b268-4016-b58a-57f1901bb1ab"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This talk will use a case study, most likely in hockey, to showcase the many ways in which R and the tidyverse can be used to analyze sports data as well as the unique priorities and considerations that are involved in applying statistical tools to sports problems.</span></p>\r\n</div></div>","id":"ad69c123-b268-4016-b58a-57f1901bb1ab","capacityId":"ad69c123-b268-4016-b58a-57f1901bb1ab","name":"R + Tidyverse in Sports","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"c3b70a5f-07f8-4762-a830-3e8f9e32831a":{"categoryId":"9541ec43-0d38-4c2a-a1d3-765a3e1d1e01","waitlistCapacityId":"c3b70a5f-07f8-4762-a830-3e8f9e32831a_waitlist","startTime":"2020-01-30T00:46:00.000Z","endTime":"2020-01-30T01:08:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"66gm7\",\"text\":\"Why does a psychological scientist learn a programming language? While motivations are many and varied the two most prominent are data analysis and data collection. The R programming language is well placed to address the first need, but there are fewer options for programming behavioural experiments within the R ecosystem. The simplest experimental designs can be recast as surveys, for which there are many options, but studies in cognitive psychology, psychophysics or developmental psychology typically require more flexibility. In this talk I outline the design principles behind xprmntr, an R package that provides wrappers to the a javascript library (jsPsych) for constructing web based psychology experiments and uses the plumber package to call server side R code as needed. In doing so, I discuss limitations to the current implementation and what a \\\"grammar of experiments\\\" might look like.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":904,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"94226be9-dedb-4182-afe2-df07aea93f43":{"speakerId":"94226be9-dedb-4182-afe2-df07aea93f43","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c3b70a5f-07f8-4762-a830-3e8f9e32831a"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Why does a psychological scientist learn a programming language? While motivations are many and varied the two most prominent are data analysis and data collection. The R programming language is well placed to address the first need, but there are fewer options for programming behavioural experiments within the R ecosystem. The simplest experimental designs can be recast as surveys, for which there are many options, but studies in cognitive psychology, psychophysics or developmental psychology typically require more flexibility. In this talk I outline the design principles behind xprmntr, an R package that provides wrappers to the a javascript library (jsPsych) for constructing web based psychology experiments and uses the plumber package to call server side R code as needed. In doing so, I discuss limitations to the current implementation and what a \"grammar of experiments\" might look like.</span></p>\r\n</div></div>","id":"c3b70a5f-07f8-4762-a830-3e8f9e32831a","capacityId":"c3b70a5f-07f8-4762-a830-3e8f9e32831a","name":"Toward a grammar of psychological experiments","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"f8673901-97c6-4edf-9cf7-e93d77da8fa8":{"categoryId":"7662541c-fece-41e8-9d2a-d2364454886c","waitlistCapacityId":"f8673901-97c6-4edf-9cf7-e93d77da8fa8_waitlist","startTime":"2020-01-30T00:46:00.000Z","endTime":"2020-01-30T01:08:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"95lr9\",\"text\":\"FlatironKitchen: How we overhauled a Frankensteinian SQL workflow with the tidyverse to enable fast, reproducible, elegant analyses of electronic health records.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{\"text-align\":\"start\"}},{\"key\":\"4n548\",\"text\":\"The increasing availability of real-world electronic health record (EHR) data is revolutionising how pharma companies are developing Personalized Healthcare (PHC) solutions. However, the scale and complexity of EHR data pose major challenges in deriving fit-for-purpose insights systematically and efficiently. The conventional approach, where siloed programmers write (or copy and paste) thousands of lines of undocumented, untested, unconnected SAS and SQL code for every research project is bad for business and ultimately for patients. Our team threw out the conventional approach and turned to R and the tidyverse. The result is FlatironKitchen, a modern R package enabling end-to-end EHR analyses in a cohesive, user-centric platform. FlatironKitchen allows users to “pipe their way” from database connections, to calculating derived variables, to running statistical analyses, to creating stunning visualisations. All of the technical details are both fully documented and seamlessly automised allowing users to focus on only meaningful functions that are fit-for-purpose to EHR analyses. The result: FlatironKitchen code is so simple it actually tells a step-by-step, human readable story about what the data scientist is doing-- a far cry from the Frankensteinian SQL/SAS code from the past. FlatironKitchen represents the best of both worlds in pharmaceutical data science. It gives expert data scientists a library of unit-tested, customisable functions for implementing existing procedures and designing new ones. Simultaneously, it enables those who are ‘coding insecure’ to -- finally -- work directly with data by reducing barriers. FlatironKitchen’s simple, easy-to-use syntax, combined with its training library of tutorials, vignettes and lessons made possible through RMarkdown has shown itself to be truly empowering. In addition to showcasing FlatironKitchen, we share lessons learned, and give a call to action for other pharma companies to embrace R.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{\"text-align\":\"start\"}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"a87ba546-6450-46f5-8562-3cc2d086f1ff":{"speakerId":"a87ba546-6450-46f5-8562-3cc2d086f1ff","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"f8673901-97c6-4edf-9cf7-e93d77da8fa8"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p style=\"text-align:start;\" class=\"carina-rte-public-DraftStyleDefault-block\">FlatironKitchen: How we overhauled a Frankensteinian SQL workflow with the tidyverse to enable fast, reproducible, elegant analyses of electronic health records.</p>\r\n<p style=\"text-align:start;\" class=\"carina-rte-public-DraftStyleDefault-block\">The increasing availability of real-world electronic health record (EHR) data is revolutionising how pharma companies are developing Personalized Healthcare (PHC) solutions. However, the scale and complexity of EHR data pose major challenges in deriving fit-for-purpose insights systematically and efficiently. The conventional approach, where siloed programmers write (or copy and paste) thousands of lines of undocumented, untested, unconnected SAS and SQL code for every research project is bad for business and ultimately for patients. Our team threw out the conventional approach and turned to R and the tidyverse. The result is FlatironKitchen, a modern R package enabling end-to-end EHR analyses in a cohesive, user-centric platform. FlatironKitchen allows users to “pipe their way” from database connections, to calculating derived variables, to running statistical analyses, to creating stunning visualisations. All of the technical details are both fully documented and seamlessly automised allowing users to focus on only meaningful functions that are fit-for-purpose to EHR analyses. The result: FlatironKitchen code is so simple it actually tells a step-by-step, human readable story about what the data scientist is doing-- a far cry from the Frankensteinian SQL/SAS code from the past. FlatironKitchen represents the best of both worlds in pharmaceutical data science. It gives expert data scientists a library of unit-tested, customisable functions for implementing existing procedures and designing new ones. Simultaneously, it enables those who are ‘coding insecure’ to -- finally -- work directly with data by reducing barriers. FlatironKitchen’s simple, easy-to-use syntax, combined with its training library of tutorials, vignettes and lessons made possible through RMarkdown has shown itself to be truly empowering. In addition to showcasing FlatironKitchen, we share lessons learned, and give a call to action for other pharma companies to embrace R.</p>\r\n</div></div>","id":"f8673901-97c6-4edf-9cf7-e93d77da8fa8","capacityId":"f8673901-97c6-4edf-9cf7-e93d77da8fa8","name":"FlatironKitchen: How we overhauled a Frankensteinian SQL workflow with the tidyverse","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"5b009813-1888-4c1c-bbfc-8e9b91262b25":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"5b009813-1888-4c1c-bbfc-8e9b91262b25_waitlist","startTime":"2020-01-30T00:46:00.000Z","endTime":"2020-01-30T01:08:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"abci7\",\"text\":\"Steve Weston's foreach package defines a simple but powerful framework for map/reduce and list-comprehension-style parallel computation in R. One of its great innovations is the ability to support many interchangeable back-end computing systems so that *the same R code* can run sequentially, in parallel on your laptop, or across a supercomputer. Recent new packages like future package define elegant new programming approaches that can use the foreach framework to run across a wide variety of parallel computing systems. This talk introduces the basics of foreach and future packages with examples using a variety of back-end systems including MPI, Redis and R's default parallel package clusters.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":701,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"b2a60c33-97d7-49a2-88d2-3d010e88b2a8":{"speakerId":"b2a60c33-97d7-49a2-88d2-3d010e88b2a8","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5b009813-1888-4c1c-bbfc-8e9b91262b25"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Steve Weston's foreach package defines a simple but powerful framework for map/reduce and list-comprehension-style parallel computation in R. One of its great innovations is the ability to support many interchangeable back-end computing systems so that *the same R code* can run sequentially, in parallel on your laptop, or across a supercomputer. Recent new packages like future package define elegant new programming approaches that can use the foreach framework to run across a wide variety of parallel computing systems. This talk introduces the basics of foreach and future packages with examples using a variety of back-end systems including MPI, Redis and R's default parallel package clusters.</span></p></div></div>","id":"5b009813-1888-4c1c-bbfc-8e9b91262b25","capacityId":"5b009813-1888-4c1c-bbfc-8e9b91262b25","name":"Parallel computing with R using foreach, future, and other packages","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"c003961a-ff90-4665-9abb-e663485b7826":{"categoryId":"c192b66d-c686-4874-b7d6-3e89bab649f1","waitlistCapacityId":"c003961a-ff90-4665-9abb-e663485b7826_waitlist","startTime":"2020-01-30T01:09:00.000Z","endTime":"2020-01-30T01:29:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8p394\",\"text\":\"There are two main challenges of working with longitudinal (panel) data: 1) Visualising the data, and 2) Understanding the model. Visualising longitudinal data is challenging as you often get a \\\"spaghetti plot”, where a line is drawn for each individual. When overlaid in one plot, it can have the appearance of a bowl of spaghetti. With even a small number of subjects, these plots are too overloaded to be read easily. For similar reasons, it is difficult to relate the model predictions back to the individual and keep the context of what the model means for the individual. For both visualisation, and modelling, it is challenging to capture interesting or unusual individuals, which are often lost in the noise. Better tools, and a more diverse set of grammar and verbs are needed to visualise and understand longitudinal data and models, to capture the individual experiences. In this talk, I introduce the R package, **brolgar** (BRowse over Longitudinal data Graphically and Analytically in R), which provides new tools, verbs, and grammar to identify and summarise interesting individual patterns in longitudinal data. This package extends upon ggplot2 with custom facets, and the new tidyverts time series packages to efficiently explore longitudinal data.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1266,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"50709a0b-7f20-44f0-bcf5-691c373f23b1":{"speakerId":"50709a0b-7f20-44f0-bcf5-691c373f23b1","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c003961a-ff90-4665-9abb-e663485b7826"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">There are two main challenges of working with longitudinal (panel) data: 1) Visualising the data, and 2) Understanding the model. Visualising longitudinal data is challenging as you often get a \"spaghetti plot”, where a line is drawn for each individual. When overlaid in one plot, it can have the appearance of a bowl of spaghetti. With even a small number of subjects, these plots are too overloaded to be read easily. For similar reasons, it is difficult to relate the model predictions back to the individual and keep the context of what the model means for the individual. For both visualisation, and modelling, it is challenging to capture interesting or unusual individuals, which are often lost in the noise. Better tools, and a more diverse set of grammar and verbs are needed to visualise and understand longitudinal data and models, to capture the individual experiences. In this talk, I introduce the R package, **brolgar** (BRowse over Longitudinal data Graphically and Analytically in R), which provides new tools, verbs, and grammar to identify and summarise interesting individual patterns in longitudinal data. This package extends upon ggplot2 with custom facets, and the new tidyverts time series packages to efficiently explore longitudinal data.</span></p>\r\n</div></div>","id":"c003961a-ff90-4665-9abb-e663485b7826","capacityId":"c003961a-ff90-4665-9abb-e663485b7826","name":"Making better spaghetti (plots): Exploring the individuals in longitudinal data with the brolgar pac","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9":{"categoryId":"9541ec43-0d38-4c2a-a1d3-765a3e1d1e01","waitlistCapacityId":"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9_waitlist","startTime":"2020-01-30T01:09:00.000Z","endTime":"2020-01-30T01:29:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cc5k8\",\"text\":\"For clinical trials a good deal of effort goes into producing both final trial reports and interim reports for data monitoring committees, and experience has shown that reviewers much prefer graphical to tabular reports. Interactive graphical reports go a step further and allow the most important information to be presented by default, while inviting the reviewer to drill down to see other details. The drill-down capability, implemented by hover text using the R plotly package, allows one to almost entirely dispense with tables because the hover text can contain the part of a table that pertains to the reviewer's current focal point in the graphical display, among other things. Also, there are major efficiency gains by having a high-level language for producing common elements of reports related to accrual, exclusions, descriptive statistics, adverse events, time to event, and longitudinal data. This talk will overview the hreport package, which relies on R, RMarkdown, knitr, plotly, Hmisc, and HTML5.  RStudio is an ideal report development environment for using these tools.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9e53364e-5406-4582-b036-8c0f345aa073":{"speakerId":"9e53364e-5406-4582-b036-8c0f345aa073","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9"}},"code":"","description":"For clinical trials a good deal of effort goes into producing both final trial reports and interim reports for data monitoring committees, and experience has shown that reviewers much prefer graphical to tabular reports. Interactive graphical reports go a step further and allow the most important information to be presented by default, while inviting the reviewer to drill down to see other details. The drill-down capability, implemented by hover text using the R plotly package, allows one to almost entirely dispense with tables because the hover text can contain the part of a table that pertains to the reviewer's current focal point in the graphical display, among other things. Also, there are major efficiency gains by having a high-level language for producing common elements of reports related to accrual, exclusions, descriptive statistics, adverse events, time to event, and longitudinal data. This talk will overview the hreport package, which relies on R, RMarkdown, knitr, plotly, Hmisc, and HTML5.  RStudio is an ideal report development environment for using these tools.","id":"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9","capacityId":"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9","name":"R for Graphical Clinical Trial Reporting","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"38bfec49-eddf-47aa-8d13-659296f7d8b4":{"categoryId":"7662541c-fece-41e8-9d2a-d2364454886c","waitlistCapacityId":"38bfec49-eddf-47aa-8d13-659296f7d8b4_waitlist","startTime":"2020-01-30T01:09:00.000Z","endTime":"2020-01-30T01:29:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"6dhq4\",\"text\":\"Engineers at Biosense Webster, a Johnson and Johnson medical device company that specializes in diagnosing and treating cardiac arrhythmias, write multiple test reports to comply with FDA regulatory standards. These intricate reports require 36 hours of an engineer’s time on average, constraining the engineers from completing investigations and studies in a timely matter. Writing scripts in R that create reproducible reports can significantly reduce the time spent by an engineer creating these reports allowing them to do a much thorough investigation with a larger scope. Through Shiny, engineers could conveniently have their parameters and recorded data processed and stored in a database by accessing a web link and filling out the required information within a user-friendly interface. Upon the generation of the report, accurate and properly formatted test reports, compliant to both the company and FDA regulatory standards, are produced through Rmarkdown and knitr knitting all the outputs with complete data analysis tools such as normality plots and process capability measurements to a word document that follows company required headers, footers, and headings. The reproducible report creation shown in this report can be extended to other types of test reports and protocols. The pilot phase that has been conducted has shown that complete report production has been decreased from 36 hours to an hour.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1420,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"7ee3848d-2095-40b5-ab05-eabfbe2c9aed":{"speakerId":"7ee3848d-2095-40b5-ab05-eabfbe2c9aed","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"38bfec49-eddf-47aa-8d13-659296f7d8b4"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Engineers at Biosense Webster, a Johnson and Johnson medical device company that specializes in diagnosing and treating cardiac arrhythmias, write multiple test reports to comply with FDA regulatory standards. These intricate reports require 36 hours of an engineer’s time on average, constraining the engineers from completing investigations and studies in a timely matter. Writing scripts in R that create reproducible reports can significantly reduce the time spent by an engineer creating these reports allowing them to do a much thorough investigation with a larger scope. Through Shiny, engineers could conveniently have their parameters and recorded data processed and stored in a database by accessing a web link and filling out the required information within a user-friendly interface. Upon the generation of the report, accurate and properly formatted test reports, compliant to both the company and FDA regulatory standards, are produced through Rmarkdown and knitr knitting all the outputs with complete data analysis tools such as normality plots and process capability measurements to a word document that follows company required headers, footers, and headings. The reproducible report creation shown in this report can be extended to other types of test reports and protocols. The pilot phase that has been conducted has shown that complete report production has been decreased from 36 hours to an hour.</span></p>\r\n</div></div>","id":"38bfec49-eddf-47aa-8d13-659296f7d8b4","capacityId":"38bfec49-eddf-47aa-8d13-659296f7d8b4","name":"Using R to Create Reproducible Engineering Test Reports","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a63f3f87-a6e1-4f63-bc0a-adb664886871":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"a63f3f87-a6e1-4f63-bc0a-adb664886871_waitlist","startTime":"2020-01-30T01:09:00.000Z","endTime":"2020-01-30T01:29:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2h0tr\",\"text\":\"Future is a minimal and unifying framework for asynchronous, parallel, and distributed computing in R. It is designed for robustness, consistency, scalability, extendability, and adoptability - all in the spirit of \\\"developer writes code once, user runs it anywhere\\\". It is being used in production for high-performance computing and asynchronous UX, among other things. In this talk, I will discuss common feature requests, recent progress we have made, and what is the pipeline.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":480,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"b95246b3-72d4-41e6-a44e-ac65beeee92e":{"speakerId":"b95246b3-72d4-41e6-a44e-ac65beeee92e","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a63f3f87-a6e1-4f63-bc0a-adb664886871"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Future is a minimal and unifying framework for asynchronous, parallel, and distributed computing in R. It is designed for robustness, consistency, scalability, extendability, and adoptability - all in the spirit of \"developer writes code once, user runs it anywhere\". It is being used in production for high-performance computing and asynchronous UX, among other things. In this talk, I will discuss common feature requests, recent progress we have made, and what is the pipeline.</span></p></div></div>","id":"a63f3f87-a6e1-4f63-bc0a-adb664886871","capacityId":"a63f3f87-a6e1-4f63-bc0a-adb664886871","name":"Future: Simple Async, Parallel & Distributed Processing in R - What's Next?","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"f84a21b9-ab4f-4886-90f4-42a6f5990f31":{"categoryId":"c32f17f6-2464-476b-859b-d8ab4d26556b","waitlistCapacityId":"f84a21b9-ab4f-4886-90f4-42a6f5990f31_waitlist","startTime":"2020-01-30T17:00:00.000Z","endTime":"2020-01-30T18:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"a5qe\",\"text\":\"Your first “object of type ‘closure’ is not subsettable” error message is a big milestone for an R user. Congratulations, if there was any lingering doubt, you now know that you are officially programming! Programming involves considerably more troubleshooting and debugging than many of us expected (or signed up for). The ability to solve your own problems is an incredibly powerful stealth skill that is worth cultivating with intention. This talk will help you nurture your inner problem solver, covering both general debugging methods and specific ways to implement them in the R ecosystem.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":595,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"265ea300-54f6-46e6-a6a4-ce00d292a372":{"speakerId":"265ea300-54f6-46e6-a6a4-ce00d292a372","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"f84a21b9-ab4f-4886-90f4-42a6f5990f31"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Your first “object of type ‘closure’ is not subsettable” error message is a big milestone for an R user. Congratulations, if there was any lingering doubt, you now know that you are officially programming! Programming involves considerably more troubleshooting and debugging than many of us expected (or signed up for). The ability to solve your own problems is an incredibly powerful stealth skill that is worth cultivating with intention. This talk will help you nurture your inner problem solver, covering both general debugging methods and specific ways to implement them in the R ecosystem.</span></p>\r\n</div></div>","id":"f84a21b9-ab4f-4886-90f4-42a6f5990f31","capacityId":"f84a21b9-ab4f-4886-90f4-42a6f5990f31","name":"Object of type ‘closure’ is not subsettable","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9ba940f7-ec0d-432f-8357-73ec0f0a31de":{"categoryId":"14e61c08-6228-4653-9d0d-93942e44ff9d","waitlistCapacityId":"9ba940f7-ec0d-432f-8357-73ec0f0a31de_waitlist","startTime":"2020-01-30T18:30:00.000Z","endTime":"2020-01-30T18:52:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dlb3i\",\"text\":\"The creation of research reports and manuscripts is a critical aspect of the work conducted by organizations and individual researchers. Most often, this process involves copying and pasting output from many different analyses into a separate document. Especially in organizations that produce annual reports for repeated analyses, this process can also involve applying incremental updates to annual reports. It is important to ensure that all relevant tables, figures, and numbers within the text are updated appropriately. Done manually, these processes are often error prone and inefficient. R Markdown is ideally suited to support these tasks. With R Markdown, users are able to conduct analyses directly in the document or read in output from a separate analyses pipeline. Tables, figures, and in-line results can then be dynamically populated and automatically numbered to ensure that everything is correctly updated when new data is provided. Additionally, the appearance of documents rendered with R Markdown can be customized to meet specific branding and formatting requirements of organizations and journals. In this presentation, we will present one implementation of customized R Markdown reports used for Accessible Teaching, Learning, and Assessment Systems (ATLAS) at the University of Kansas. A publicly available R package, ratlas, provides both Microsoft Word and LaTeX templates for different types of projects at ATLAS with their own unique formatting requirements. We will discuss how to create brand-specific templates, as well as how to incorporate the templates into an R package that can be used to unify report creation across an organization. We will also describe other components of branding reports beyond R Markdown templates, including customized ggplot2 themes, which can also be wrapped into the R package. Finally, we will share lessons learned from incorporating the R package workflow into an existing reporting pipeline.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1960,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ec5226fe-95b5-463f-a1a8-5cdb6e79e1ba":{"speakerId":"ec5226fe-95b5-463f-a1a8-5cdb6e79e1ba","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9ba940f7-ec0d-432f-8357-73ec0f0a31de"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The creation of research reports and manuscripts is a critical aspect of the work conducted by organizations and individual researchers. Most often, this process involves copying and pasting output from many different analyses into a separate document. Especially in organizations that produce annual reports for repeated analyses, this process can also involve applying incremental updates to annual reports. It is important to ensure that all relevant tables, figures, and numbers within the text are updated appropriately. Done manually, these processes are often error prone and inefficient. R Markdown is ideally suited to support these tasks. With R Markdown, users are able to conduct analyses directly in the document or read in output from a separate analyses pipeline. Tables, figures, and in-line results can then be dynamically populated and automatically numbered to ensure that everything is correctly updated when new data is provided. Additionally, the appearance of documents rendered with R Markdown can be customized to meet specific branding and formatting requirements of organizations and journals. In this presentation, we will present one implementation of customized R Markdown reports used for Accessible Teaching, Learning, and Assessment Systems (ATLAS) at the University of Kansas. A publicly available R package, ratlas, provides both Microsoft Word and LaTeX templates for different types of projects at ATLAS with their own unique formatting requirements. We will discuss how to create brand-specific templates, as well as how to incorporate the templates into an R package that can be used to unify report creation across an organization. We will also describe other components of branding reports beyond R Markdown templates, including customized ggplot2 themes, which can also be wrapped into the R package. Finally, we will share lessons learned from incorporating the R package workflow into an existing reporting pipeline.</span></p>\r\n</div></div>","id":"9ba940f7-ec0d-432f-8357-73ec0f0a31de","capacityId":"9ba940f7-ec0d-432f-8357-73ec0f0a31de","name":"Branding and Packaging Reports with R Markdown","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"82240a2e-0cd3-48c0-b643-6358ac8bd4f5":{"categoryId":"5b7895f7-b865-4880-8c38-3efe99272d3b","waitlistCapacityId":"82240a2e-0cd3-48c0-b643-6358ac8bd4f5_waitlist","startTime":"2020-01-30T18:30:00.000Z","endTime":"2020-01-30T18:52:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dh86o\",\"text\":\"The InsightRX precision dosing platform tailors in-patient drug doses to individual patients' characteristics and biomarkers, leveraging pharmacological models of drug metabolism and drug effects. These models are implemented in R, exposed through APIs, and called from a cloud-based web application. The core of our pharmacokinetic/pharmacodynamic simulation functionality is available open source at `github.com/InsightRX/PKPDsim` and `github.com/InsightRX/clinPK`. As a regulated device in Europe (and soon to be in the US) used in over 100 hospitals, the platform is necessarily developed under \\\"design control\\\", meaning that strict product planning and engineering practices are required. This has implications for how the application and APIs are developed and deployed, such as strict version control workflows and implementation of rigorous testing procedures. To meet the requirements for high availability and horizontal scaling, we use a combination of Plumber and OpenCPU, hosted on RStudio Connect and AWS Fargate/ECS, which cater to the various needs of the development and production environments.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1112,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"3224d2d6-d0f8-4267-a8cd-a072e98c0f10":{"speakerId":"3224d2d6-d0f8-4267-a8cd-a072e98c0f10","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"82240a2e-0cd3-48c0-b643-6358ac8bd4f5"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The InsightRX precision dosing platform tailors in-patient drug doses to individual patients' characteristics and biomarkers, leveraging pharmacological models of drug metabolism and drug effects. These models are implemented in R, exposed through APIs, and called from a cloud-based web application. The core of our pharmacokinetic/pharmacodynamic simulation functionality is available open source at `github.com/InsightRX/PKPDsim` and `github.com/InsightRX/clinPK`. As a regulated device in Europe (and soon to be in the US) used in over 100 hospitals, the platform is necessarily developed under \"design control\", meaning that strict product planning and engineering practices are required. This has implications for how the application and APIs are developed and deployed, such as strict version control workflows and implementation of rigorous testing procedures. To meet the requirements for high availability and horizontal scaling, we use a combination of Plumber and OpenCPU, hosted on RStudio Connect and AWS Fargate/ECS, which cater to the various needs of the development and production environments.</span></p>\r\n</div></div>","id":"82240a2e-0cd3-48c0-b643-6358ac8bd4f5","capacityId":"82240a2e-0cd3-48c0-b643-6358ac8bd4f5","name":"Building a Medical Device with R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"56b9aa0a-8bcc-4367-8300-1830fe7bc48e":{"categoryId":"e7813ace-5968-4b39-a41d-7dd97a1b17f9","waitlistCapacityId":"56b9aa0a-8bcc-4367-8300-1830fe7bc48e_waitlist","startTime":"2020-01-30T18:30:00.000Z","endTime":"2020-01-30T18:52:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"bmh4\",\"text\":\"I see a lot of ugly charts. This is to be expected as I work with a lot of academics and data scientists, neither of whom have been trained in how to design attractive charts. I myself produced many ugly charts during my years as a research scientist, when the design process basically came down to random tweaking until things \\\"looked good\\\". If only I could go back and tell young inexperienced me that there was a better way. In this talk, I will present that better way--a series of design principles that can take any chart from drab to fab. Rather than applying these techniques willy nilly, I will show how they form a layered \\\"Glamour of Graphics\\\" that is structured and can be easily applied to any chart. This Glamour of Graphics has some simple implementations in ggplot, where we will replace geoms, aesthetics, and scales with typography, color, and layout. Finally, I will discuss why looks matter when it comes to charts, and how by following the Glamour of Graphics you can design charts that are more persuasive and more accurately perceived.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1058,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"3c159f8d-889f-4bf9-9800-f1c06799bb71":{"speakerId":"3c159f8d-889f-4bf9-9800-f1c06799bb71","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"56b9aa0a-8bcc-4367-8300-1830fe7bc48e"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">I see a lot of ugly charts. This is to be expected as I work with a lot of academics and data scientists, neither of whom have been trained in how to design attractive charts. I myself produced many ugly charts during my years as a research scientist, when the design process basically came down to random tweaking until things \"looked good\". If only I could go back and tell young inexperienced me that there was a better way. In this talk, I will present that better way--a series of design principles that can take any chart from drab to fab. Rather than applying these techniques willy nilly, I will show how they form a layered \"Glamour of Graphics\" that is structured and can be easily applied to any chart. This Glamour of Graphics has some simple implementations in ggplot, where we will replace geoms, aesthetics, and scales with typography, color, and layout. Finally, I will discuss why looks matter when it comes to charts, and how by following the Glamour of Graphics you can design charts that are more persuasive and more accurately perceived.</span></p>\r\n</div></div>","id":"56b9aa0a-8bcc-4367-8300-1830fe7bc48e","capacityId":"56b9aa0a-8bcc-4367-8300-1830fe7bc48e","name":"The Glamour of Graphics","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"4821ea1e-a51e-47d1-b7b8-f34e50043f8c":{"categoryId":"416e941f-8c5e-45a7-a381-a3af761561a9","waitlistCapacityId":"4821ea1e-a51e-47d1-b7b8-f34e50043f8c_waitlist","startTime":"2020-01-30T18:30:00.000Z","endTime":"2020-01-30T18:52:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2ncm3\",\"text\":\"RMarkdown enables analysts to engage with code interactively, embrace literate programming, and rapidly produce a wide variety of high-quality data products such as documents, emails, dashboards, and websites. However, RMarkdown is less commonly explored and celebrated for the important role it can play in helping R users grow into developers. In this talk, I will provide an overview of RMarkdown Driven Development: a workflow for converting one-off analysis into a well-engineered and well-designed R package with deep empathy for user needs. We will explore how the methodical incorporation of good coding practices such as modularization and testing naturally evolves a single-file RMarkdown into an R project or package. Along the way, we will discuss big-picture questions like “optimal stopping” (why some data products are better left as single files or projects) and concrete details such as the {here} and {testthat} packages which can provide step-change improvements to project sustainability. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1009,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"3cc60f1a-838d-404f-96bd-c8185d1bf36c":{"speakerId":"3cc60f1a-838d-404f-96bd-c8185d1bf36c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4821ea1e-a51e-47d1-b7b8-f34e50043f8c"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">RMarkdown enables analysts to engage with code interactively, embrace literate programming, and rapidly produce a wide variety of high-quality data products such as documents, emails, dashboards, and websites. However, RMarkdown is less commonly explored and celebrated for the important role it can play in helping R users grow into developers. In this talk, I will provide an overview of RMarkdown Driven Development: a workflow for converting one-off analysis into a well-engineered and well-designed R package with deep empathy for user needs. We will explore how the methodical incorporation of good coding practices such as modularization and testing naturally evolves a single-file RMarkdown into an R project or package. Along the way, we will discuss big-picture questions like “optimal stopping” (why some data products are better left as single files or projects) and concrete details such as the {here} and {testthat} packages which can provide step-change improvements to project sustainability. </span></p>\r\n</div></div>","id":"4821ea1e-a51e-47d1-b7b8-f34e50043f8c","capacityId":"4821ea1e-a51e-47d1-b7b8-f34e50043f8c","name":"RMarkdown Driven Development","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"c152e08a-9995-4eab-b1f4-c139203af0ff":{"categoryId":"14e61c08-6228-4653-9d0d-93942e44ff9d","waitlistCapacityId":"c152e08a-9995-4eab-b1f4-c139203af0ff_waitlist","startTime":"2020-01-30T18:53:00.000Z","endTime":"2020-01-30T19:15:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"1mr1p\",\"text\":\"If you’re responsible for analyses that need updating or repeating on a semi-regular basis, you might find yourself doing the same work over and over again. The principle of \\\"don’t repeat yourself\\\" from software engineering motivates us to use functions and packages, the core of repetition in the R universe. For analyses, it can be difficult to know how to use this principle and move beyond \\\"copying and pasting scripts and changing the data file and the object names and updating the dates and results in RMarkdown\\\", especially when there’s some element of human intervention required, whether it be for validating assumptions or cleaning artisanal data.  This talk will focus on those next steps, showcasing opportunities to stop repeating yourself and instead anticipate the needs of and communicate effectively with your future self (or the next person with your job!) using project-oriented workflows, clever interactivity, templated analyses, functions, and yes, your own packages.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":990,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"4626deea-bcca-4718-9c57-f5c15fb4fed7":{"speakerId":"4626deea-bcca-4718-9c57-f5c15fb4fed7","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c152e08a-9995-4eab-b1f4-c139203af0ff"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">If you’re responsible for analyses that need updating or repeating on a semi-regular basis, you might find yourself doing the same work over and over again. The principle of \"don’t repeat yourself\" from software engineering motivates us to use functions and packages, the core of repetition in the R universe. For analyses, it can be difficult to know how to use this principle and move beyond \"copying and pasting scripts and changing the data file and the object names and updating the dates and results in RMarkdown\", especially when there’s some element of human intervention required, whether it be for validating assumptions or cleaning artisanal data.  This talk will focus on those next steps, showcasing opportunities to stop repeating yourself and instead anticipate the needs of and communicate effectively with your future self (or the next person with your job!) using project-oriented workflows, clever interactivity, templated analyses, functions, and yes, your own packages.</span></p>\r\n</div></div>","id":"c152e08a-9995-4eab-b1f4-c139203af0ff","capacityId":"c152e08a-9995-4eab-b1f4-c139203af0ff","name":"Don’t repeat yourself, talk to yourself! Repeated reporting in the R universe.","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"748ff65d-fbbb-45e0-833d-418169cddc58":{"categoryId":"5b7895f7-b865-4880-8c38-3efe99272d3b","waitlistCapacityId":"748ff65d-fbbb-45e0-833d-418169cddc58_waitlist","startTime":"2020-01-30T18:53:00.000Z","endTime":"2020-01-30T19:15:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cjunt\",\"text\":\"Development of a web-based clinical decision support application for platelet transfusion management using R and the Tidyverse\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{\"text-align\":\"start\"}},{\"key\":\"aldek\",\"text\":\"Blood product transfusion is a high risk and costly medical procedure. Platelets (blood cells that initiate clotting) are a rare and expensive blood product with a short shelf life. Proper management of platelet transfusions is essential to clinical care, particularly for patients who have developed antibodies against specific platelet types due to pregnancy or past transfusions. By providing platelets that avoid a patient’s known antibodies, improved patient outcomes and better inventory management of a rare blood product are achieved. To address this need, we used R, Tidyverse, and several key packages (Shiny, shinydashboard, dplyr, purrr, httr, officer, flextables, futures) to develop a web-based application (PLTVXM) to help guide platelet inventory selection. PLTVXM queries information on available/pending platelet inventory (and eligible donors) from reports that run in our institutional reporting tool Tableau® via a Tableau Server REST API. Patient antibody and blood type information is securely retrieved from a clinical data lake via an in-house R package (“dart”) and a custom institutional API. The retrieved data is processed by a published algorithm implemented in R and incorporates user input to present sortable tables of patient-specific compatible platelet inventory (and donors) for consideration. The requisite documentation for platelet product reservation or donor recruitment is then autogenerated using institutional form templates. PLTVXM is deployed on an RStudio Connect server which allows seamless integration with our institution’s Active Directory identity management infrastructure. The pilot version of PLTVXM was created by physicians without formal computer programming training in two weeks. After successful demonstration, PLTVXM was approved for clinical validation and future use in our practice. Our experience highlights how R can facilitate creation of dynamic web-based applications for a wide range of business (or clinical) needs.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{\"text-align\":\"start\"}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"6313be58-0709-4272-86b6-3d0ecd6c1510":{"speakerId":"6313be58-0709-4272-86b6-3d0ecd6c1510","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"748ff65d-fbbb-45e0-833d-418169cddc58"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p style=\"text-align:start;\" class=\"carina-rte-public-DraftStyleDefault-block\">Development of a web-based clinical decision support application for platelet transfusion management using R and the Tidyverse</p>\r\n<p style=\"text-align:start;\" class=\"carina-rte-public-DraftStyleDefault-block\">Blood product transfusion is a high risk and costly medical procedure. Platelets (blood cells that initiate clotting) are a rare and expensive blood product with a short shelf life. Proper management of platelet transfusions is essential to clinical care, particularly for patients who have developed antibodies against specific platelet types due to pregnancy or past transfusions. By providing platelets that avoid a patient’s known antibodies, improved patient outcomes and better inventory management of a rare blood product are achieved. To address this need, we used R, Tidyverse, and several key packages (Shiny, shinydashboard, dplyr, purrr, httr, officer, flextables, futures) to develop a web-based application (PLTVXM) to help guide platelet inventory selection. PLTVXM queries information on available/pending platelet inventory (and eligible donors) from reports that run in our institutional reporting tool Tableau® via a Tableau Server REST API. Patient antibody and blood type information is securely retrieved from a clinical data lake via an in-house R package (“dart”) and a custom institutional API. The retrieved data is processed by a published algorithm implemented in R and incorporates user input to present sortable tables of patient-specific compatible platelet inventory (and donors) for consideration. The requisite documentation for platelet product reservation or donor recruitment is then autogenerated using institutional form templates. PLTVXM is deployed on an RStudio Connect server which allows seamless integration with our institution’s Active Directory identity management infrastructure. The pilot version of PLTVXM was created by physicians without formal computer programming training in two weeks. After successful demonstration, PLTVXM was approved for clinical validation and future use in our practice. Our experience highlights how R can facilitate creation of dynamic web-based applications for a wide range of business (or clinical) needs.</p>\r\n</div></div>","id":"748ff65d-fbbb-45e0-833d-418169cddc58","capacityId":"748ff65d-fbbb-45e0-833d-418169cddc58","name":"Development of a web-based clinical decision support application for platelet transfusion management","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff":{"categoryId":"e7813ace-5968-4b39-a41d-7dd97a1b17f9","waitlistCapacityId":"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff_waitlist","startTime":"2020-01-30T18:53:00.000Z","endTime":"2020-01-30T19:15:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8rohe\",\"text\":\"Learn how a single line of code can transform your data visualizations into stunning 3D using the rayshader package. In this talk, I will show how you can use rayshader to create beautiful 3D figures and animations to help promote your research and analyses to the public. Find out how to use principles of cinematography to take users on a 3D tour of your data, scripted entirely within R. Leaving the 3D pie charts in the pantry at home, I will discuss how to build interpretable, engaging, and informative plots using all three dimensions.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":542,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"6ee23af8-7141-442e-b031-9c5e18002d9a":{"speakerId":"6ee23af8-7141-442e-b031-9c5e18002d9a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Learn how a single line of code can transform your data visualizations into stunning 3D using the rayshader package. In this talk, I will show how you can use rayshader to create beautiful 3D figures and animations to help promote your research and analyses to the public. Find out how to use principles of cinematography to take users on a 3D tour of your data, scripted entirely within R. Leaving the 3D pie charts in the pantry at home, I will discuss how to build interpretable, engaging, and informative plots using all three dimensions.</span></p>\r\n</div></div>","id":"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff","capacityId":"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff","name":"3D ggplots with rayshader","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"08421d97-b1e7-4db0-9de2-5701d84c9662":{"categoryId":"416e941f-8c5e-45a7-a381-a3af761561a9","waitlistCapacityId":"08421d97-b1e7-4db0-9de2-5701d84c9662_waitlist","startTime":"2020-01-30T18:53:00.000Z","endTime":"2020-01-30T19:15:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"2dik8\",\"text\":\"The renv package helps you create reproducible environments for your R projects. With renv, you can make your R projects more: Isolated: Installing a new or updated package for one project won’t break your other projects, and vice versa. Portable: Easily transport your projects from one computer to another, even across different platforms. renv makes it easy to install the packages your project depends on. Reproducible: renv records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go. In this presentation, I'll introduce renv and some of its main workflows.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":634,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9c6e5f7d-e4bb-4b0e-8900-bdc7789a0460":{"speakerId":"9c6e5f7d-e4bb-4b0e-8900-bdc7789a0460","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"08421d97-b1e7-4db0-9de2-5701d84c9662"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The renv package helps you create reproducible environments for your R projects. With renv, you can make your R projects more: Isolated: Installing a new or updated package for one project won’t break your other projects, and vice versa. Portable: Easily transport your projects from one computer to another, even across different platforms. renv makes it easy to install the packages your project depends on. Reproducible: renv records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go. In this presentation, I'll introduce renv and some of its main workflows.</span></p>\r\n</div></div>","id":"08421d97-b1e7-4db0-9de2-5701d84c9662","capacityId":"08421d97-b1e7-4db0-9de2-5701d84c9662","name":"renv: Project Environments to R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a42a7a38-4446-40ae-ac33-20f211442286":{"categoryId":"14e61c08-6228-4653-9d0d-93942e44ff9d","waitlistCapacityId":"a42a7a38-4446-40ae-ac33-20f211442286_waitlist","startTime":"2020-01-30T19:16:00.000Z","endTime":"2020-01-30T19:38:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"6r1c5\",\"text\":\"Over the last few years, Rmarkdown seems to have taken over my life, or at least my written communication. These days I use Rmarkdown to maintain my website, write my blog, write textbooks, write academic papers, prepare slides for talks, keep my CV up-to-date, help my students write theses, prepare university policy documents, write letters, prepare exams, write reports for clients, and more. I haven't quite got to the point of using it for shopping lists, but perhaps that's my next Rmarkdown template. I will reflect on the journey in getting to this point, what I've lost and what I've gained. I will also speculate on what might be next in the Rmarkdownification of my life.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":683,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d48fc2af-1487-4fae-900a-8d95513f1eb5":{"speakerId":"d48fc2af-1487-4fae-900a-8d95513f1eb5","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a42a7a38-4446-40ae-ac33-20f211442286"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Over the last few years, Rmarkdown seems to have taken over my life, or at least my written communication. These days I use Rmarkdown to maintain my website, write my blog, write textbooks, write academic papers, prepare slides for talks, keep my CV up-to-date, help my students write theses, prepare university policy documents, write letters, prepare exams, write reports for clients, and more. I haven't quite got to the point of using it for shopping lists, but perhaps that's my next Rmarkdown template. I will reflect on the journey in getting to this point, what I've lost and what I've gained. I will also speculate on what might be next in the Rmarkdownification of my life.</span></p>\r\n</div></div>","id":"a42a7a38-4446-40ae-ac33-20f211442286","capacityId":"a42a7a38-4446-40ae-ac33-20f211442286","name":"How Rmarkdown changed my life","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c":{"categoryId":"5b7895f7-b865-4880-8c38-3efe99272d3b","waitlistCapacityId":"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c_waitlist","startTime":"2020-01-30T19:16:00.000Z","endTime":"2020-01-30T19:38:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"9bqnr\",\"text\":\"The Stanford Blood Center collects and distributes blood products to Stanford Hospital. One of these is platelets, a vital clot-forming blood component with a limited shelf life of a few days. Previous work (Guan et al. , 2017) formulated an optimization problem using features aggregated from the available data to solve the problem of reducing waste. An R package was created for a three-day ordering strategy but has not been put into production due to lack of human trust in modelling accuracy. In summer 2019, the Stanford Data Science for Social Good team, decided to make use of additional patient-level data and models to predict platelet consumption rather than relying solely on aggregated data. Modeling the transfusion recipients into different subpopulations allows for finer-grained predictions on a patient level. We make extensive use of R packages, such as the tidyverse and R Shiny, to conduct exploratory data analysis, build models, and create a user-intuitive dashboard. The Shiny dashboard is designed to display consumption predictions aggregated across all models, consumption predictions for each subpopulation, and historical performance of the model, thereby serving as a valuable tool in building the trust necessary for adopting the algorithmic ordering strategies. Reference Guan, L., Tian, X., et al. (2017). “Big data modeling to predict platelet usage and minimize wastage in a tertiary care system.” PNAS (43) 114: 11368 - 11373. Retrieved from: www.pnas.org/cgi/doi/10.1073/pnas.1714097114\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1524,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"679fbfd0-e0ed-4664-8783-2f3cfa37d770":{"speakerId":"679fbfd0-e0ed-4664-8783-2f3cfa37d770","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The Stanford Blood Center collects and distributes blood products to Stanford Hospital. One of these is platelets, a vital clot-forming blood component with a limited shelf life of a few days. Previous work (Guan et al. , 2017) formulated an optimization problem using features aggregated from the available data to solve the problem of reducing waste. An R package was created for a three-day ordering strategy but has not been put into production due to lack of human trust in modelling accuracy. In summer 2019, the Stanford Data Science for Social Good team, decided to make use of additional patient-level data and models to predict platelet consumption rather than relying solely on aggregated data. Modeling the transfusion recipients into different subpopulations allows for finer-grained predictions on a patient level. We make extensive use of R packages, such as the tidyverse and R Shiny, to conduct exploratory data analysis, build models, and create a user-intuitive dashboard. The Shiny dashboard is designed to display consumption predictions aggregated across all models, consumption predictions for each subpopulation, and historical performance of the model, thereby serving as a valuable tool in building the trust necessary for adopting the algorithmic ordering strategies. Reference Guan, L., Tian, X., et al. (2017). “Big data modeling to predict platelet usage and minimize wastage in a tertiary care system.” PNAS (43) 114: 11368 - 11373. Retrieved from: www.pnas.org/cgi/doi/10.1073/pnas.1714097114</span></p>\r\n</div></div>","id":"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c","capacityId":"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c","name":"Forecasting Platelet Blood Bag Demand to Reduce Inventory Wastage at the Stanford Blood Center","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"1ba2254d-cfa9-403d-9e43-bd58014f9c9b":{"categoryId":"e7813ace-5968-4b39-a41d-7dd97a1b17f9","waitlistCapacityId":"1ba2254d-cfa9-403d-9e43-bd58014f9c9b_waitlist","startTime":"2020-01-30T19:16:00.000Z","endTime":"2020-01-30T19:38:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"2c7390ac-3e7a-4b03-86e4-25d3246cabdc":{"speakerId":"2c7390ac-3e7a-4b03-86e4-25d3246cabdc","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"1ba2254d-cfa9-403d-9e43-bd58014f9c9b"}},"code":"","description":"","id":"1ba2254d-cfa9-403d-9e43-bd58014f9c9b","capacityId":"1ba2254d-cfa9-403d-9e43-bd58014f9c9b","name":"Designing Effective Visualizations","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"e7677084-4afd-4f68-8ced-2b0a159f56a0":{"categoryId":"416e941f-8c5e-45a7-a381-a3af761561a9","waitlistCapacityId":"e7677084-4afd-4f68-8ced-2b0a159f56a0_waitlist","startTime":"2020-01-30T19:16:00.000Z","endTime":"2020-01-30T19:38:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8a73v\",\"text\":\"RStudio 1.3, currently available as a preview release, includes a number of new capabilities that will help you be more productive in R. It's also more configurable, accessible, and flexible. In this talk, you'll learn to take advantage of these new tools.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":256,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{\"text-align\":\"left\"}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"109cd1e3-4e45-4d06-8f18-6625a047e412":{"speakerId":"109cd1e3-4e45-4d06-8f18-6625a047e412","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"e7677084-4afd-4f68-8ced-2b0a159f56a0"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p style=\"text-align:left;\" class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">RStudio 1.3, currently available as a preview release, includes a number of new capabilities that will help you be more productive in R. It's also more configurable, accessible, and flexible. In this talk, you'll learn to take advantage of these new tools.</span></p>\r\n</div></div>","id":"e7677084-4afd-4f68-8ced-2b0a159f56a0","capacityId":"e7677084-4afd-4f68-8ced-2b0a159f56a0","name":"RStudio 1.3 Sneak Preview","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"adc756af-1e58-459f-8a95-9f06b3b341d0":{"categoryId":"14e61c08-6228-4653-9d0d-93942e44ff9d","waitlistCapacityId":"adc756af-1e58-459f-8a95-9f06b3b341d0_waitlist","startTime":"2020-01-30T19:39:00.000Z","endTime":"2020-01-30T19:59:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"bs28c\",\"text\":\"R Markdown is a document format based on the R language and Markdown to intermingle computing with narratives in the same document. With this simple format, you can actually do a lot of things. For example, you can generate reports dynamically (no need to cut-and-paste any results because all results can be dynamically generated from R), write papers and books, create websites, and make presentations. In this talk, I'll use a single R Markdown document to give demos of the R packages rmarkdown, bookdown for authoring books (https://bookdown.org), blogdown for creating websites (https://github.com/rstudio/blogdown), rticles for writing journal papers (https://github.com/rstudio/rticles), xaringan for making slides (https://github.com/yihui/xaringan), flexdashboard for generating dashboards (https://github.com/rstudio/flexdashboard), learnr for tutorials (https://github.com/rstudio/learnr), rolldown for storytelling (https://github.com/yihui/rolldown), and the integration between Shiny and R Markdown. To make the best use of your time during the presentation, I recommend you to take a look at the rmarkdown website in advance: https://rmarkdown.rstudio.com.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1172,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9e289142-3880-47a2-9515-3b02327bf77c":{"speakerId":"9e289142-3880-47a2-9515-3b02327bf77c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"adc756af-1e58-459f-8a95-9f06b3b341d0"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">R Markdown is a document format based on the R language and Markdown to intermingle computing with narratives in the same document. With this simple format, you can actually do a lot of things. For example, you can generate reports dynamically (no need to cut-and-paste any results because all results can be dynamically generated from R), write papers and books, create websites, and make presentations. In this talk, I'll use a single R Markdown document to give demos of the R packages rmarkdown, bookdown for authoring books (https://bookdown.org), blogdown for creating websites (https://github.com/rstudio/blogdown), rticles for writing journal papers (https://github.com/rstudio/rticles), xaringan for making slides (https://github.com/yihui/xaringan), flexdashboard for generating dashboards (https://github.com/rstudio/flexdashboard), learnr for tutorials (https://github.com/rstudio/learnr), rolldown for storytelling (https://github.com/yihui/rolldown), and the integration between Shiny and R Markdown. To make the best use of your time during the presentation, I recommend you to take a look at the rmarkdown website in advance: https://rmarkdown.rstudio.com.</span></p>\r\n</div></div>","id":"adc756af-1e58-459f-8a95-9f06b3b341d0","capacityId":"adc756af-1e58-459f-8a95-9f06b3b341d0","name":"One R Markdown Document, Fourteen Demos","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d8acadca-5e06-49b9-8372-ac0ef1c9a74e":{"categoryId":"5b7895f7-b865-4880-8c38-3efe99272d3b","waitlistCapacityId":"d8acadca-5e06-49b9-8372-ac0ef1c9a74e_waitlist","startTime":"2020-01-30T19:39:00.000Z","endTime":"2020-01-30T19:59:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"bsvvq\",\"text\":\"Electronic Medical Records (EMRs) are a treasure trove of information, but tend to fall disappointingly short when it comes to visualizing and reporting data in a user friendly and intuitive manner. Building reports in an EMR can be a frustrating experience; the developer is at the mercy of how the data is stored within the EMR and the available EMR reporting tools can be bland and uninspiring. But reporting on data in the EMR doesn't have to be this way! Combining the data-rich EMR with R's robust reporting capabilities benefits both developers and consumers of data. This talk will describe how a cross-departmental project team uses an internal R package, RMarkdown reports scheduled via R Studio Connect, and an interactive flexdashboard app to quickly implement solutions to gaps in the reporting capabilities of the EMR. The flexibility of R relative to EMR reporting tools facilitates a design thinking approach to reporting allowing for more user input, customization and quick iteration. Furthermore, the web-based app we developed is able to be embedded within the EMR itself allowing for a more streamlined workflow.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1133,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"7058fde0-ae75-416f-912e-6a89c3ac80e6":{"speakerId":"7058fde0-ae75-416f-912e-6a89c3ac80e6","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d8acadca-5e06-49b9-8372-ac0ef1c9a74e"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Electronic Medical Records (EMRs) are a treasure trove of information, but tend to fall disappointingly short when it comes to visualizing and reporting data in a user friendly and intuitive manner. Building reports in an EMR can be a frustrating experience; the developer is at the mercy of how the data is stored within the EMR and the available EMR reporting tools can be bland and uninspiring. But reporting on data in the EMR doesn't have to be this way! Combining the data-rich EMR with R's robust reporting capabilities benefits both developers and consumers of data. This talk will describe how a cross-departmental project team uses an internal R package, RMarkdown reports scheduled via R Studio Connect, and an interactive flexdashboard app to quickly implement solutions to gaps in the reporting capabilities of the EMR. The flexibility of R relative to EMR reporting tools facilitates a design thinking approach to reporting allowing for more user input, customization and quick iteration. Furthermore, the web-based app we developed is able to be embedded within the EMR itself allowing for a more streamlined workflow.</span></p>\r\n</div></div>","id":"d8acadca-5e06-49b9-8372-ac0ef1c9a74e","capacityId":"d8acadca-5e06-49b9-8372-ac0ef1c9a74e","name":"Shiny New Things: Using R to Bridge the Gap in EMR Reporting","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"422c5e4a-aff6-4277-bbff-71f9a34e804f":{"categoryId":"e7813ace-5968-4b39-a41d-7dd97a1b17f9","waitlistCapacityId":"422c5e4a-aff6-4277-bbff-71f9a34e804f_waitlist","startTime":"2020-01-30T19:39:00.000Z","endTime":"2020-01-30T19:59:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"94513fe9-5def-41c2-9cb0-022850f30285":{"speakerId":"94513fe9-5def-41c2-9cb0-022850f30285","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"422c5e4a-aff6-4277-bbff-71f9a34e804f"}},"code":"","description":"","id":"422c5e4a-aff6-4277-bbff-71f9a34e804f","capacityId":"422c5e4a-aff6-4277-bbff-71f9a34e804f","name":"Tidyverse 2019-2020","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"34e68e07-d564-4612-8025-bf112576d6a8":{"categoryId":"416e941f-8c5e-45a7-a381-a3af761561a9","waitlistCapacityId":"34e68e07-d564-4612-8025-bf112576d6a8_waitlist","startTime":"2020-01-30T19:39:00.000Z","endTime":"2020-01-30T19:59:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8iner\",\"text\":\"This talk is for R admins who want to learn how to set up Jupyter notebooks on RStudio Server Pro. We'll cover prerequisites, basic configuration, best practices for management, Jupyter Lab, and more.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":200,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"38d0e2ac-67a9-44af-bd2f-f29d9d26a0ae":{"speakerId":"38d0e2ac-67a9-44af-bd2f-f29d9d26a0ae","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"34e68e07-d564-4612-8025-bf112576d6a8"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">This talk is for R admins who want to learn how to set up Jupyter notebooks on RStudio Server Pro. We'll cover prerequisites, basic configuration, best practices for management, Jupyter Lab, and more.</span></p>\r\n</div></div>","id":"34e68e07-d564-4612-8025-bf112576d6a8","capacityId":"34e68e07-d564-4612-8025-bf112576d6a8","name":"Using Jupyter with RStudio Server Pro","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"df93fafe-1d66-46be-839b-aa653ff36d4f":{"categoryId":"cc6bd243-8042-4181-9f98-81f38044b7f0","waitlistCapacityId":"df93fafe-1d66-46be-839b-aa653ff36d4f_waitlist","startTime":"2020-01-30T21:00:00.000Z","endTime":"2020-01-30T21:22:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"eab5d\",\"text\":\"Azure Machine Learning service (Azure ML) is Microsoft’s cloud-based machine learning platform that enables data scientists and their teams to carry out end-to-end machine learning workflows at scale. With Azure ML's new open-source R SDK and R capabilities, you can take advantage of the platform’s enterprise-grade features to train, tune, manage and deploy R-based machine learning models and applications. In this talk, the attendees will learn how to: •Carry out ML workflows using the authoring experience of their choice, from no-code to code-first options that include Azure ML’s drag-and-drop visual interface for defining workflows and RStudio Server on the Data Science Instance, a hosted VM workstation, for using the Azure ML R SDK from the RStudio browser-based interface. •Use the Azure ML R SDK to manage cloud resources and train, hyperparameter tune, and log and visualize metrics for their models at scale on Azure compute. •Build ML Pipelines in R for defining and orchestrating reusable and reproducible ML workflows. •Deploy, manage, and monitor their R ML models and applications as web services on Azure Container Instance and Azure Kubernetes Service, with an emphasis on robust DevOps and CI/CD for orchestrating and streamlining their end-to-end data science development lifecycle.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1308,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"fb0a2103-5459-4838-85f7-1ff2c834e9fc":{"speakerId":"fb0a2103-5459-4838-85f7-1ff2c834e9fc","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"df93fafe-1d66-46be-839b-aa653ff36d4f"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Azure Machine Learning service (Azure ML) is Microsoft’s cloud-based machine learning platform that enables data scientists and their teams to carry out end-to-end machine learning workflows at scale. With Azure ML's new open-source R SDK and R capabilities, you can take advantage of the platform’s enterprise-grade features to train, tune, manage and deploy R-based machine learning models and applications. In this talk, the attendees will learn how to: •Carry out ML workflows using the authoring experience of their choice, from no-code to code-first options that include Azure ML’s drag-and-drop visual interface for defining workflows and RStudio Server on the Data Science Instance, a hosted VM workstation, for using the Azure ML R SDK from the RStudio browser-based interface. •Use the Azure ML R SDK to manage cloud resources and train, hyperparameter tune, and log and visualize metrics for their models at scale on Azure compute. •Build ML Pipelines in R for defining and orchestrating reusable and reproducible ML workflows. •Deploy, manage, and monitor their R ML models and applications as web services on Azure Container Instance and Azure Kubernetes Service, with an emphasis on robust DevOps and CI/CD for orchestrating and streamlining their end-to-end data science development lifecycle.</span></p>\r\n</div></div>","id":"df93fafe-1d66-46be-839b-aa653ff36d4f","capacityId":"df93fafe-1d66-46be-839b-aa653ff36d4f","name":"MLOps for R with Azure Machine Learning","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"31bb43be-554e-4488-81b3-8e07c7ba33c9":{"categoryId":"9f757023-00f9-48dc-8e36-57eef3be415d","waitlistCapacityId":"31bb43be-554e-4488-81b3-8e07c7ba33c9_waitlist","startTime":"2020-01-30T21:00:00.000Z","endTime":"2020-01-30T21:22:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"enr4u\",\"text\":\"Many R users can feel isolated due to the prevalence of Python or Tableau at their institutions. This talk will focus on how we use R to develop reference implementations of visualizations (using ggplot2), and to develop corporate-themed color maps (using the colorspace package) to bring value to the entire institution. Color maps can be translated into variety of formats, for Tableau, Qlik Sense, d3, etc., and deployed independently from R. For visualizations, our goal is to translate ggplot2 objects to Vega-Lite specifications, using a package we are developing: ggvega. Vega-Lite visualizations are web-native, and are rendered independently from R. Specifications can be designed to be extensible to new data, allowing them serve as templates, to be deployed and updated for use outside of R. Of course, despite isolation within an institution, our work with the larger R open-source communities provides a foundation on which to build; in fact, we have a lot of company and are having a lot of fun.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1009,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"78ff1c9c-02da-461b-a661-155b4ec3d15a":{"speakerId":"78ff1c9c-02da-461b-a661-155b4ec3d15a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"31bb43be-554e-4488-81b3-8e07c7ba33c9"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Many R users can feel isolated due to the prevalence of Python or Tableau at their institutions. This talk will focus on how we use R to develop reference implementations of visualizations (using ggplot2), and to develop corporate-themed color maps (using the colorspace package) to bring value to the entire institution. Color maps can be translated into variety of formats, for Tableau, Qlik Sense, d3, etc., and deployed independently from R. For visualizations, our goal is to translate ggplot2 objects to Vega-Lite specifications, using a package we are developing: ggvega. Vega-Lite visualizations are web-native, and are rendered independently from R. Specifications can be designed to be extensible to new data, allowing them serve as templates, to be deployed and updated for use outside of R. Of course, despite isolation within an institution, our work with the larger R open-source communities provides a foundation on which to build; in fact, we have a lot of company and are having a lot of fun.</span></p>\r\n</div></div>","id":"31bb43be-554e-4488-81b3-8e07c7ba33c9","capacityId":"31bb43be-554e-4488-81b3-8e07c7ba33c9","name":"Small Team, Big Value: Using R to Design Visualizations","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"f34b33b5-37c3-4873-8712-63a4c80e4a29":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"f34b33b5-37c3-4873-8712-63a4c80e4a29_waitlist","startTime":"2020-01-30T21:00:00.000Z","endTime":"2020-01-30T21:22:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cdq75\",\"text\":\"Vega-lite is a high-level grammar of interactive graphics implemented in Javascript; it renders interactive visualizations in the browser based on a JSON specification. In Python and Javascript, the Altair and vega-lite-api packages have demonstrated how the development of APIs to build Vega-Lite graphics can be partially automated based on the Vega-Lite JSON schema, which describes the required format for a Vega-Lite JSON specification. This talk will describe the development of the ‘vlbuildr’ package for building Vega-Lite specifications in R and the ‘vlmetabuildr’ package for building the ‘vlbuildr’ package. The ‘vlbuildr’ package seeks to provide a pipe-friendly, “R-like” functional interface for building up simple to complex specifications for Vega-Lite graphics, which can in turn be rendered as an HtmlWidget by the ‘vegawidget’ R package. Building such an API in a fully automated way from the Vega-Lite schema presents considerable challenges, so the approach taken here was to rely on partial automation. Human judgement dictates the basic contours of the API, such as what groups of functions to include and how various types of building blocks will go together. The part that is automated is filling in many details such as the different variants of a group of functions, the exact parameters needed for each function, and the documentation of those parameters -- the parts that would be extremely tedious to port over!\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1441,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"ab08004a-1661-4333-88f2-1edab293de77":{"speakerId":"ab08004a-1661-4333-88f2-1edab293de77","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"f34b33b5-37c3-4873-8712-63a4c80e4a29"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Vega-lite is a high-level grammar of interactive graphics implemented in Javascript; it renders interactive visualizations in the browser based on a JSON specification. In Python and Javascript, the Altair and vega-lite-api packages have demonstrated how the development of APIs to build Vega-Lite graphics can be partially automated based on the Vega-Lite JSON schema, which describes the required format for a Vega-Lite JSON specification. This talk will describe the development of the ‘vlbuildr’ package for building Vega-Lite specifications in R and the ‘vlmetabuildr’ package for building the ‘vlbuildr’ package. The ‘vlbuildr’ package seeks to provide a pipe-friendly, “R-like” functional interface for building up simple to complex specifications for Vega-Lite graphics, which can in turn be rendered as an HtmlWidget by the ‘vegawidget’ R package. Building such an API in a fully automated way from the Vega-Lite schema presents considerable challenges, so the approach taken here was to rely on partial automation. Human judgement dictates the basic contours of the API, such as what groups of functions to include and how various types of building blocks will go together. The part that is automated is filling in many details such as the different variants of a group of functions, the exact parameters needed for each function, and the documentation of those parameters -- the parts that would be extremely tedious to port over!</span></p>\r\n</div></div>","id":"f34b33b5-37c3-4873-8712-63a4c80e4a29","capacityId":"f34b33b5-37c3-4873-8712-63a4c80e4a29","name":"Auto-magic package development: Building an R API for building Vega-Lite Specs","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"135530e9-722e-4889-9b2f-30f09bbfbdfa":{"categoryId":"685cea12-cca3-47f5-9c7d-6e5ebbdfea31","waitlistCapacityId":"135530e9-722e-4889-9b2f-30f09bbfbdfa_waitlist","startTime":"2020-01-30T21:00:00.000Z","endTime":"2020-01-30T21:22:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"4pg02\",\"text\":\"The ggplot2 package is widely acknowledged as a powerful, dynamic, and easy-to-learn graphics framework when used in an interactive environment. Using ggplot2 in a package or Shiny app environment adds several constraints which are sometimes circumvented using ggplot2 behaviour that may change in the future. Some best practices include (1) using the `.data` pronoun to refer to the layer data within `aes()` and `vars()` instead of the original variable name, (2) ensuring that `plot()` methods that use ggplot2 explicitly `print()` one or more ggplot objects, (3) defining extension themes that modify a complete theme within ggplot2 (like `theme_gray()`), and (4) testing graphical output using the vdiffr package. Collectively, these practices result in better error messages with unexpected user input and ensure compatibility with most versions of ggplot2, including those to come in the future.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":902,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9edc4001-6d55-499d-b6de-334a47de9ba8":{"speakerId":"9edc4001-6d55-499d-b6de-334a47de9ba8","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"135530e9-722e-4889-9b2f-30f09bbfbdfa"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The ggplot2 package is widely acknowledged as a powerful, dynamic, and easy-to-learn graphics framework when used in an interactive environment. Using ggplot2 in a package or Shiny app environment adds several constraints which are sometimes circumvented using ggplot2 behaviour that may change in the future. Some best practices include (1) using the `.data` pronoun to refer to the layer data within `aes()` and `vars()` instead of the original variable name, (2) ensuring that `plot()` methods that use ggplot2 explicitly `print()` one or more ggplot objects, (3) defining extension themes that modify a complete theme within ggplot2 (like `theme_gray()`), and (4) testing graphical output using the vdiffr package. Collectively, these practices result in better error messages with unexpected user input and ensure compatibility with most versions of ggplot2, including those to come in the future.</span></p>\r\n</div></div>","id":"135530e9-722e-4889-9b2f-30f09bbfbdfa","capacityId":"135530e9-722e-4889-9b2f-30f09bbfbdfa","name":"Best practices for programming with ggplot2","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7":{"categoryId":"cc6bd243-8042-4181-9f98-81f38044b7f0","waitlistCapacityId":"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7_waitlist","startTime":"2020-01-30T21:23:00.000Z","endTime":"2020-01-30T21:45:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8qm3b\",\"text\":\"Many models have structural parameters that cannot be directly estimated from the data. These tuning parameters can have a significant effect on model performance and require some mechanism for finding reasonable values. The tune and workflow packages enable tidymodels users to optimize these parameters using a variety of efficient grid search methods as well as with iterative search techniques (such as Bayesian optimization).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":430,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"5e87d90e-8603-42d6-9699-1cc9ddda1a93":{"speakerId":"5e87d90e-8603-42d6-9699-1cc9ddda1a93","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Many models have structural parameters that cannot be directly estimated from the data. These tuning parameters can have a significant effect on model performance and require some mechanism for finding reasonable values. The tune and workflow packages enable tidymodels users to optimize these parameters using a variety of efficient grid search methods as well as with iterative search techniques (such as Bayesian optimization).</span></p>\r\n</div></div>","id":"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7","capacityId":"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7","name":"Totally Tidy Tuning Techniques","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be":{"categoryId":"9f757023-00f9-48dc-8e36-57eef3be415d","waitlistCapacityId":"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be_waitlist","startTime":"2020-01-30T21:23:00.000Z","endTime":"2020-01-30T21:45:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"18qj9\",\"text\":\"Common advice from experienced data scientists to job-seekers is to avoid job postings that describe a \\\"data science unicorn\\\": someone who has experience performing an unrealistically large array of technical and business-related job duties. Seeking a unicorn is viewed as a potential indicator that the company fails to understand their data science needs, and that new hires will not be poised for success due to lacking support and resources [Robinson & Nolis, 2019]. The R language, particularly when used with RStudio products, has evolved to enable production-level activities in the areas of data wrangling, reporting/dashboarding, database/software engineering, machine learning, and web application development. It is increasingly plausible that a data scientist will be able to efficiently perform a wide variety of job functions with experience only in a single language (R). Indeed, even entry level R users may tread into \\\"unicorn\\\" territory. Current standards for data scientist job descriptions and salaries do not accommodate this nuance, leaving both job-seekers and hiring managers unable to distinguish job requirements which should be read as warning signs from listings which are idyllic matches for the modern R unicorn. In this talk, we present data aggregated from several large compensation analytics companies which summarize current benchmarks for data science job descriptions and corresponding salary ranges. We then suggest job description language to target modern R users, considering both job duty compatibility and job post findability. These descriptions are presented with likely salary range pairings. Attention is given to deviations from traditional degree requirements, years of experience, and demands for multiple programming language literacy which may lack relevance for the R unicorn. Our overarching goal is to provide job description templates which encourage optimal matchmaking between R job seekers and organizations in need of their talents.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1992,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"fdada0d5-fccc-4c0d-a4bd-9e95ff2f9729":{"speakerId":"fdada0d5-fccc-4c0d-a4bd-9e95ff2f9729","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Common advice from experienced data scientists to job-seekers is to avoid job postings that describe a \"data science unicorn\": someone who has experience performing an unrealistically large array of technical and business-related job duties. Seeking a unicorn is viewed as a potential indicator that the company fails to understand their data science needs, and that new hires will not be poised for success due to lacking support and resources [Robinson &amp; Nolis, 2019]. The R language, particularly when used with RStudio products, has evolved to enable production-level activities in the areas of data wrangling, reporting/dashboarding, database/software engineering, machine learning, and web application development. It is increasingly plausible that a data scientist will be able to efficiently perform a wide variety of job functions with experience only in a single language (R). Indeed, even entry level R users may tread into \"unicorn\" territory. Current standards for data scientist job descriptions and salaries do not accommodate this nuance, leaving both job-seekers and hiring managers unable to distinguish job requirements which should be read as warning signs from listings which are idyllic matches for the modern R unicorn. In this talk, we present data aggregated from several large compensation analytics companies which summarize current benchmarks for data science job descriptions and corresponding salary ranges. We then suggest job description language to target modern R users, considering both job duty compatibility and job post findability. These descriptions are presented with likely salary range pairings. Attention is given to deviations from traditional degree requirements, years of experience, and demands for multiple programming language literacy which may lack relevance for the R unicorn. Our overarching goal is to provide job description templates which encourage optimal matchmaking between R job seekers and organizations in need of their talents.</span></p>\r\n</div></div>","id":"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be","capacityId":"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be","name":"UnicoRns are real","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"23129cb7-1186-49c3-9287-9bf9fd22b25f":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"23129cb7-1186-49c3-9287-9bf9fd22b25f_waitlist","startTime":"2020-01-30T21:23:00.000Z","endTime":"2020-01-30T21:45:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"98ip6\",\"text\":\"Like it or not, SQL is the closest thing we have to a universal language for working with structured data. Celebrating its 50th birthday in 2020, SQL today integrates with thousands of applications and has millions of users worldwide. Data analysts using SQL represent a large audience of potential R users motivated to expand their data science skills. But learning R can be frustrating for SQL users. One major frustration is the inability to directly query R data frames with SQL SELECT statements. Eager to use R for tasks that are not possible with SQL (like data visualization and machine learning), these users are dismayed to find that they must first learn an unfamiliar syntax for data manipulation. The popularity of the sqldf package (which automatically exports an R data frame into an embedded database, then runs a SQL query on it) demonstrates this frustration. But now there is a way to directly query an R data frame without moving the data out of R. In this talk, I introduce tidyquery, a new R package that runs SQL queries directly on R data frames. tidyquery is powered by dplyr and by queryparser, a new pure-R, no-dependency SQL query parser.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1166,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"e332b156-d576-4205-8995-25d35dcd4e6d":{"speakerId":"e332b156-d576-4205-8995-25d35dcd4e6d","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"23129cb7-1186-49c3-9287-9bf9fd22b25f"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Like it or not, SQL is the closest thing we have to a universal language for working with structured data. Celebrating its 50th birthday in 2020, SQL today integrates with thousands of applications and has millions of users worldwide. Data analysts using SQL represent a large audience of potential R users motivated to expand their data science skills. But learning R can be frustrating for SQL users. One major frustration is the inability to directly query R data frames with SQL SELECT statements. Eager to use R for tasks that are not possible with SQL (like data visualization and machine learning), these users are dismayed to find that they must first learn an unfamiliar syntax for data manipulation. The popularity of the sqldf package (which automatically exports an R data frame into an embedded database, then runs a SQL query on it) demonstrates this frustration. But now there is a way to directly query an R data frame without moving the data out of R. In this talk, I introduce tidyquery, a new R package that runs SQL queries directly on R data frames. tidyquery is powered by dplyr and by queryparser, a new pure-R, no-dependency SQL query parser.</span></p>\r\n</div></div>","id":"23129cb7-1186-49c3-9287-9bf9fd22b25f","capacityId":"23129cb7-1186-49c3-9287-9bf9fd22b25f","name":"Bridging the gap between SQL and R: Introducing queryparser and tidyquery","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d2148603-58e1-4d62-ae8a-cfc267028184":{"categoryId":"685cea12-cca3-47f5-9c7d-6e5ebbdfea31","waitlistCapacityId":"d2148603-58e1-4d62-ae8a-cfc267028184_waitlist","startTime":"2020-01-30T21:23:00.000Z","endTime":"2020-01-30T21:45:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ec9sv\",\"text\":\"The ggtext package provides various functions to add formatted text to ggplot2 figures, both in the form of plot or axis labels and in the form of text labels or text boxes inside the plot panel. Text formatting can be achieved through a small subset of markdown, HTML, and CSS directives. Features currently supported include italics, bold, super- and sub-script, as well as changing font size, font family, and color. Basic support for adding images to formatted text is also available.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":488,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"237d836b-fbec-4755-81fa-d1de005c766e":{"speakerId":"237d836b-fbec-4755-81fa-d1de005c766e","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d2148603-58e1-4d62-ae8a-cfc267028184"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The ggtext package provides various functions to add formatted text to ggplot2 figures, both in the form of plot or axis labels and in the form of text labels or text boxes inside the plot panel. Text formatting can be achieved through a small subset of markdown, HTML, and CSS directives. Features currently supported include italics, bold, super- and sub-script, as well as changing font size, font family, and color. Basic support for adding images to formatted text is also available.</span></p>\r\n</div></div>","id":"d2148603-58e1-4d62-ae8a-cfc267028184","capacityId":"d2148603-58e1-4d62-ae8a-cfc267028184","name":"Spruce up your ggplot2 visualizations with formatted text","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a401221d-297b-432f-b612-ed488632e150":{"categoryId":"cc6bd243-8042-4181-9f98-81f38044b7f0","waitlistCapacityId":"a401221d-297b-432f-b612-ed488632e150_waitlist","startTime":"2020-01-30T21:46:00.000Z","endTime":"2020-01-30T22:08:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"dmj9q\",\"text\":\"Longitudinal data (or panel data) arise when observations are recorded on the same individuals at multiple points in time. For example, a longitudinal baseball study might track individual player characteristics (team affiliation, age, height, weight, etc.) and outcomes (batting average, stolen bases, runs, strikeouts, etc.) over multiple seasons, where the number of seasons could vary across players. Neural network frameworks such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) can flexibly accommodate this data structure while preserving and exploiting temporal relationships. In this presentation, we highlight the use of neural networks for longitudinal data analysis with tensorflow and keras in R.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":727,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"d11a6d32-d39d-4db2-80cf-4ef534dc569e":{"speakerId":"d11a6d32-d39d-4db2-80cf-4ef534dc569e","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a401221d-297b-432f-b612-ed488632e150"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Longitudinal data (or panel data) arise when observations are recorded on the same individuals at multiple points in time. For example, a longitudinal baseball study might track individual player characteristics (team affiliation, age, height, weight, etc.) and outcomes (batting average, stolen bases, runs, strikeouts, etc.) over multiple seasons, where the number of seasons could vary across players. Neural network frameworks such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) can flexibly accommodate this data structure while preserving and exploiting temporal relationships. In this presentation, we highlight the use of neural networks for longitudinal data analysis with tensorflow and keras in R.</span></p>\r\n</div></div>","id":"a401221d-297b-432f-b612-ed488632e150","capacityId":"a401221d-297b-432f-b612-ed488632e150","name":"Neural Networks for Longitudinal Data Analysis","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"e12072bb-806d-4f62-92e1-fd1849191693":{"categoryId":"9f757023-00f9-48dc-8e36-57eef3be415d","waitlistCapacityId":"e12072bb-806d-4f62-92e1-fd1849191693_waitlist","startTime":"2020-01-30T21:46:00.000Z","endTime":"2020-01-30T22:08:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"3dlf6\",\"text\":\"The Data Science community is dominated by folks doing amazing work with data that starts in and never leaves **cyberspace**. This talk is about best paractices and playbooks for doing data science that involves **meatspace** (the opposite of cyberspace) and why R is such a great language for working with data that originated in the physical world. While the concrete examples in this talk will mostly come from the **manufacturing** space, where I have the most experience, I believe the themes are relevant to many meatspace workflows. We'll talk through effective playbooks that can help you navigate common tasks throughout the life-cycle of a project. We’ll also weave in how R’s glorious package ecosystem, including `tidyverse`, can be combined with other languages like `python`, and with enterprise products like **RStudio Connect** to great effect. Specifically, we'll discuss practices in these areas: * best practices for **data collection** in meatspace * the importance of quantifying **measurement system error** * collecting the correct data for training **computer vision** models * the rarely discussed cost of **maintaining models** in production\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1167,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"fb9a1c06-d4a9-4ea6-a36b-32e86922850b":{"speakerId":"fb9a1c06-d4a9-4ea6-a36b-32e86922850b","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"e12072bb-806d-4f62-92e1-fd1849191693"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The Data Science community is dominated by folks doing amazing work with data that starts in and never leaves **cyberspace**. This talk is about best paractices and playbooks for doing data science that involves **meatspace** (the opposite of cyberspace) and why R is such a great language for working with data that originated in the physical world. While the concrete examples in this talk will mostly come from the **manufacturing** space, where I have the most experience, I believe the themes are relevant to many meatspace workflows. We'll talk through effective playbooks that can help you navigate common tasks throughout the life-cycle of a project. We’ll also weave in how R’s glorious package ecosystem, including `tidyverse`, can be combined with other languages like `python`, and with enterprise products like **RStudio Connect** to great effect. Specifically, we'll discuss practices in these areas: * best practices for **data collection** in meatspace * the importance of quantifying **measurement system error** * collecting the correct data for training **computer vision** models * the rarely discussed cost of **maintaining models** in production</span></p>\r\n</div></div>","id":"e12072bb-806d-4f62-92e1-fd1849191693","capacityId":"e12072bb-806d-4f62-92e1-fd1849191693","name":"Data Science in Meatspace","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a01cabb8-3e45-451b-a13d-8904abede0c9":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"a01cabb8-3e45-451b-a13d-8904abede0c9_waitlist","startTime":"2020-01-30T21:46:00.000Z","endTime":"2020-01-30T22:08:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8tun7\",\"text\":\"The use of list-columns in data frames and tibbles is well documented (e.g. Bryan, 2018), providing a cognitively efficient way to organize results of complex data (e.g. several statistical models, groupings of text, data summaries, or even graphics) with corresponding data. For example, one can store student information within classrooms, player information within teams, or analyses within groups. This allows the data to be of variable sizes without overly complicating or adding redundancies to the structure of the data. In turn, this can improve the reliability to appropriately analyze the data. Because of its efficiency and speed, being able to use data.table to work with list-columns would be beneficial in many data contexts (e.g. to reduce memory usage in large data sets). Herein, I demonstrate how one can create list-columns in a data table using the by argument in data.table and purrr::map(). I compare the behavior of the data.table approaches to the dplyr::group_nest() function and tidyr::unnest(), two of the several powerful tidyverse nesting and unnesting functions. Results using bench::mark() show the speed and efficiency of using data.table to work with list-columns.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1197,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"fa3f398d-9a75-4e55-b00b-f1b416b1ec65":{"speakerId":"fa3f398d-9a75-4e55-b00b-f1b416b1ec65","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a01cabb8-3e45-451b-a13d-8904abede0c9"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The use of list-columns in data frames and tibbles is well documented (e.g. Bryan, 2018), providing a cognitively efficient way to organize results of complex data (e.g. several statistical models, groupings of text, data summaries, or even graphics) with corresponding data. For example, one can store student information within classrooms, player information within teams, or analyses within groups. This allows the data to be of variable sizes without overly complicating or adding redundancies to the structure of the data. In turn, this can improve the reliability to appropriately analyze the data. Because of its efficiency and speed, being able to use data.table to work with list-columns would be beneficial in many data contexts (e.g. to reduce memory usage in large data sets). Herein, I demonstrate how one can create list-columns in a data table using the by argument in data.table and purrr::map(). I compare the behavior of the data.table approaches to the dplyr::group_nest() function and tidyr::unnest(), two of the several powerful tidyverse nesting and unnesting functions. Results using bench::mark() show the speed and efficiency of using data.table to work with list-columns.</span></p>\r\n</div></div>","id":"a01cabb8-3e45-451b-a13d-8904abede0c9","capacityId":"a01cabb8-3e45-451b-a13d-8904abede0c9","name":"List-columns in data.table: Reducing the cognitive and computational burden when working with comple","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"66b0d4a2-35ec-44be-92f2-ab8272ee34cf":{"categoryId":"685cea12-cca3-47f5-9c7d-6e5ebbdfea31","waitlistCapacityId":"66b0d4a2-35ec-44be-92f2-ab8272ee34cf_waitlist","startTime":"2020-01-30T21:46:00.000Z","endTime":"2020-01-30T22:08:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8rf16\",\"text\":\"Precise axes, proper data transformation, and informative visual data mappings are critical components to any polished visualization. The scales package, the unsung hero behind ggplot2’s scale_* infrastructure, includes functions to help any R user manipulate and polish their visualizations. In this presentation, we will explore the functionality of this small but mighty package: demonstrating its functions for polishing guides, e.g. breaks and labels, managing data transformations, and for mapping aesthetic palettes to data.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":531,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"632b8eb1-14ee-4f30-ad00-4559cc915229":{"speakerId":"632b8eb1-14ee-4f30-ad00-4559cc915229","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"66b0d4a2-35ec-44be-92f2-ab8272ee34cf"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Precise axes, proper data transformation, and informative visual data mappings are critical components to any polished visualization. The scales package, the unsung hero behind ggplot2’s scale_* infrastructure, includes functions to help any R user manipulate and polish their visualizations. In this presentation, we will explore the functionality of this small but mighty package: demonstrating its functions for polishing guides, e.g. breaks and labels, managing data transformations, and for mapping aesthetic palettes to data.</span></p>\r\n</div></div>","id":"66b0d4a2-35ec-44be-92f2-ab8272ee34cf","capacityId":"66b0d4a2-35ec-44be-92f2-ab8272ee34cf","name":"The little package that could: taking visualizations to the next level with the scales package","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"a908e1ea-a021-4a4a-9144-539f8d21c5af":{"categoryId":"cc6bd243-8042-4181-9f98-81f38044b7f0","waitlistCapacityId":"a908e1ea-a021-4a4a-9144-539f8d21c5af_waitlist","startTime":"2020-01-30T22:09:00.000Z","endTime":"2020-01-30T22:29:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8lb9l\",\"text\":\"Often a machine learning research project starts with brainstorming, continues to one-off scripts while an idea forms, and finally, a package is written to disseminate the product. In this talk, I will share my experience rethinking this process by spreading the package writing across the whole process. While there are cognitive overheads involved with setting up a package framework, I will argue that these overheads can serve as a scaffolding for not only good code but robust research practices. The result of this experiment is the SBMR package: a native R package written to fit and investigate the results of Bipartite Stochastic Block Models that forms the backbone of my PhD dissertation. By going over the ups and downs of this process, I hope to leave the audience with inspiration for moving the package writing process closer to the start of their projects and melding research and code more closely to improve both.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":931,\"style\":\"ITALIC\"},{\"offset\":0,\"length\":931,\"style\":\"color-rgb(34,34,34)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"239403d5-1610-443f-a25a-e5409f3dd363":{"speakerId":"239403d5-1610-443f-a25a-e5409f3dd363","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"a908e1ea-a021-4a4a-9144-539f8d21c5af"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(34,34,34);\"><span style=\"font-style: italic;\">Often a machine learning research project starts with brainstorming, continues to one-off scripts while an idea forms, and finally, a package is written to disseminate the product. In this talk, I will share my experience rethinking this process by spreading the package writing across the whole process. While there are cognitive overheads involved with setting up a package framework, I will argue that these overheads can serve as a scaffolding for not only good code but robust research practices. The result of this experiment is the SBMR package: a native R package written to fit and investigate the results of Bipartite Stochastic Block Models that forms the backbone of my PhD dissertation. By going over the ups and downs of this process, I hope to leave the audience with inspiration for moving the package writing process closer to the start of their projects and melding research and code more closely to improve both.</span></span></p></div></div>","id":"a908e1ea-a021-4a4a-9144-539f8d21c5af","capacityId":"a908e1ea-a021-4a4a-9144-539f8d21c5af","name":"Stochastic Block Models with R: Statistically rigerous clusting with rigorous code","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67":{"categoryId":"9f757023-00f9-48dc-8e36-57eef3be415d","waitlistCapacityId":"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67_waitlist","startTime":"2020-01-30T22:09:00.000Z","endTime":"2020-01-30T22:29:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"5626a\",\"text\":\"ML in production is one of the most obvious ways that data science organizations create value in business. However, these models are at the very end of a long story of how quantitative research changes and enhances organizations. In this talk I will discuss how I have found DS organization to be truly transformative outside of ML in the loop. Bio: Eduardo Ariño de la Rubia is a DS manager and educator. He loves R and RStudio. He has a Masters in Negotiation, Conflict Resolution and Peacebuilding, which is probably the most useful training he could have received.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":568,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"e4f10720-96b3-4521-8e0a-aaa15be5f38b":{"speakerId":"e4f10720-96b3-4521-8e0a-aaa15be5f38b","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">ML in production is one of the most obvious ways that data science organizations create value in business. However, these models are at the very end of a long story of how quantitative research changes and enhances organizations. In this talk I will discuss how I have found DS organization to be truly transformative outside of ML in the loop. Bio: Eduardo Ariño de la Rubia is a DS manager and educator. He loves R and RStudio. He has a Masters in Negotiation, Conflict Resolution and Peacebuilding, which is probably the most useful training he could have received.</span></p>\r\n</div></div>","id":"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67","capacityId":"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67","name":"Value in Data Science Beyond Models in Production","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"6ad3db7d-89ab-4c72-aeac-e228ce58098e":{"categoryId":"86bdfdfa-e086-4ec9-9883-800820265d71","waitlistCapacityId":"6ad3db7d-89ab-4c72-aeac-e228ce58098e_waitlist","startTime":"2020-01-30T22:09:00.000Z","endTime":"2020-01-30T22:29:00.000Z","locationName":"Room 4","locationCode":"Room 41574889904972","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"anq81\",\"text\":\"In tidyverse grammars such as dplyr you can refer to the columns in your data frames as if they were objects in the workspace. This syntax is optimised for interactivity and is a great fit for data analysis, but it makes it harder to write functions and reuse code. In this talk we present some advances in the tidy eval framework that make it easier to program around tidyverse pipelines without having to learn a lot of theory.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":429,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"144613aa-b52a-46a2-bbc7-9056734523c6":{"speakerId":"144613aa-b52a-46a2-bbc7-9056734523c6","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"6ad3db7d-89ab-4c72-aeac-e228ce58098e"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In tidyverse grammars such as dplyr you can refer to the columns in your data frames as if they were objects in the workspace. This syntax is optimised for interactivity and is a great fit for data analysis, but it makes it harder to write functions and reuse code. In this talk we present some advances in the tidy eval framework that make it easier to program around tidyverse pipelines without having to learn a lot of theory.</span></p>\r\n</div></div>","id":"6ad3db7d-89ab-4c72-aeac-e228ce58098e","capacityId":"6ad3db7d-89ab-4c72-aeac-e228ce58098e","name":"Advances in tidyeval","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"4b9a8f5f-7916-4232-86ea-ba308cb61bbf":{"categoryId":"685cea12-cca3-47f5-9c7d-6e5ebbdfea31","waitlistCapacityId":"4b9a8f5f-7916-4232-86ea-ba308cb61bbf_waitlist","startTime":"2020-01-30T22:09:00.000Z","endTime":"2020-01-30T22:29:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"16avd\",\"text\":\"The ggplot2 package continue to be one of the most used frameworks for producing graphics in R. While being extremely flexible, the package itself can be constrained by the different types of graphic elements and statistic transformations available. Instead of continuing to add new features, the development in recent years have focused on making ggplot2 extensible by other packages, thus distributing development and maintenance. Despite the best of intentions, ggplot2 can feel daunting to extend, due unusual idiosyncrasies, a foreign object system, and a partly obscured rendering model. This talk intend to remove the mystery of extending ggplot2, by describing the basic ways that it can be extended and showcasing a couple of simple extensions that can be build with very little code. Lastly, it will include discussions of some best practices and gotchas that may come in handy when you start out.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":907,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"38322ddd-270a-477f-888d-8069bff36759":{"speakerId":"38322ddd-270a-477f-888d-8069bff36759","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"4b9a8f5f-7916-4232-86ea-ba308cb61bbf"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The ggplot2 package continue to be one of the most used frameworks for producing graphics in R. While being extremely flexible, the package itself can be constrained by the different types of graphic elements and statistic transformations available. Instead of continuing to add new features, the development in recent years have focused on making ggplot2 extensible by other packages, thus distributing development and maintenance. Despite the best of intentions, ggplot2 can feel daunting to extend, due unusual idiosyncrasies, a foreign object system, and a partly obscured rendering model. This talk intend to remove the mystery of extending ggplot2, by describing the basic ways that it can be extended and showcasing a couple of simple extensions that can be build with very little code. Lastly, it will include discussions of some best practices and gotchas that may come in handy when you start out.</span></p>\r\n</div></div>","id":"4b9a8f5f-7916-4232-86ea-ba308cb61bbf","capacityId":"4b9a8f5f-7916-4232-86ea-ba308cb61bbf","name":"Extending your ability to extend ggplot2","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"895592d5-b93e-487c-bcde-e033b9367411":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"895592d5-b93e-487c-bcde-e033b9367411_waitlist","startTime":"2020-01-30T22:45:00.000Z","endTime":"2020-01-30T22:50:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cqjj\",\"text\":\"After at least a year of dreaming about it, I finally produced the #rstats/#tidyverse dress of my dreams. This involved designing fabric, getting it custom printed, making a pattern from an existing garment, and sewing the dress. (https://twitter.com/AmeliaMN/status/1162359039784673282?s=20) I learned a lot of useful lessons during this project, including \\\"do unit tests\\\" (make a practice dress) and \\\"document your work\\\" (get your BFF to take pictures of you).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":462,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"38c654f1-517f-4732-9b71-a3a284077946":{"speakerId":"38c654f1-517f-4732-9b71-a3a284077946","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"895592d5-b93e-487c-bcde-e033b9367411"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">After at least a year of dreaming about it, I finally produced the #rstats/#tidyverse dress of my dreams. This involved designing fabric, getting it custom printed, making a pattern from an existing garment, and sewing the dress. (https://twitter.com/AmeliaMN/status/1162359039784673282?s=20) I learned a lot of useful lessons during this project, including \"do unit tests\" (make a practice dress) and \"document your work\" (get your BFF to take pictures of you).</span></p>\r\n</div></div>","id":"895592d5-b93e-487c-bcde-e033b9367411","capacityId":"895592d5-b93e-487c-bcde-e033b9367411","name":"Making a tidy dress","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"1b3d95dc-dbe6-4d44-9c43-7c797b4310be":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"1b3d95dc-dbe6-4d44-9c43-7c797b4310be_waitlist","startTime":"2020-01-30T22:45:00.000Z","endTime":"2020-01-30T22:50:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7g0b\",\"text\":\"In this talk we will demonstrate `livecode`, a new R package for broadcasting code for live code demonstrations. This package implements a simple webserver (using `httpuv`) to dynamically publishes the content of a code file (i.e. `.R` or `.Rmd`) as you edit it live. This enables your students to have near realtime access to your code as you write it. The broadcast file can be viewed with any webbrowser but the package is specifically designed to be used within RStudio leveraging its builtin viewer. This gives students have direct access to the shared code within the IDE, allowing direct copying into their own source files and/or the console and thereby improving their ability to interact and experiment with your code.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":728,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"263678cb-33eb-47c8-b673-947a063570da":{"speakerId":"263678cb-33eb-47c8-b673-947a063570da","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"1b3d95dc-dbe6-4d44-9c43-7c797b4310be"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In this talk we will demonstrate `livecode`, a new R package for broadcasting code for live code demonstrations. This package implements a simple webserver (using `httpuv`) to dynamically publishes the content of a code file (i.e. `.R` or `.Rmd`) as you edit it live. This enables your students to have near realtime access to your code as you write it. The broadcast file can be viewed with any webbrowser but the package is specifically designed to be used within RStudio leveraging its builtin viewer. This gives students have direct access to the shared code within the IDE, allowing direct copying into their own source files and/or the console and thereby improving their ability to interact and experiment with your code.</span></p>\r\n</div></div>","id":"1b3d95dc-dbe6-4d44-9c43-7c797b4310be","capacityId":"1b3d95dc-dbe6-4d44-9c43-7c797b4310be","name":"`livecode`: broadcast your live coding sessions from and to RStudio","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"8a1f808a-2276-4e26-9d5f-a51c8d660b11":{"categoryId":"5950d2ee-cc1c-4d74-a9a9-ff92668deff5","waitlistCapacityId":"8a1f808a-2276-4e26-9d5f-a51c8d660b11_waitlist","startTime":"2020-01-30T22:45:00.000Z","endTime":"2020-01-30T23:30:00.000Z","locationName":"Room 1","locationCode":"Room 11574454580914","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"f250d261-5d20-4055-997c-763213bff94f":{"speakerId":"f250d261-5d20-4055-997c-763213bff94f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"8a1f808a-2276-4e26-9d5f-a51c8d660b11"}},"code":"","description":"","id":"8a1f808a-2276-4e26-9d5f-a51c8d660b11","capacityId":"8a1f808a-2276-4e26-9d5f-a51c8d660b11","name":"Career Advice for Data Scientists","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae_waitlist","startTime":"2020-01-30T22:50:00.000Z","endTime":"2020-01-30T22:55:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"d1soi\",\"text\":\"My 8th grade capstone project introduced me to R. The project was a data visualization about breakfast tacos. I used R and other web based tools. My lightning talk will focus on my experience about using R for class projects and getting the support from my parents to help integrate R into the classroom. I will show how students can get started when they have no clue on how to use R. I will talk about the project’s toolkit which includes RStudio cloud, Google sheets, chomebook, measurement tools, my phone and how R is being used in my school.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":547,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"8a50c4a4-6eba-48cd-a3c4-d287478d131a":{"speakerId":"8a50c4a4-6eba-48cd-a3c4-d287478d131a","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">My 8th grade capstone project introduced me to R. The project was a data visualization about breakfast tacos. I used R and other web based tools. My lightning talk will focus on my experience about using R for class projects and getting the support from my parents to help integrate R into the classroom. I will show how students can get started when they have no clue on how to use R. I will talk about the project’s toolkit which includes RStudio cloud, Google sheets, chomebook, measurement tools, my phone and how R is being used in my school.</span></p>\r\n</div></div>","id":"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae","capacityId":"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae","name":"A high school student’s journey to bring R into the classroom.","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d98ac3da-c488-470f-ab68-1a311a2fc728":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"d98ac3da-c488-470f-ab68-1a311a2fc728_waitlist","startTime":"2020-01-30T22:50:00.000Z","endTime":"2020-01-30T22:55:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"ai2nu\",\"text\":\"Open source code is an essential piece in making science reproducible. Tools like 'rmarkdown' and GitHub facilitate running and sharing outcomes with colleagues and with the broad scientific community at large. However, it is less clear what tools should be used to retrieve, store and share datasets; while it is possible to make datasets part of your workflows today, it is usually hard and we are often left with manually sharing or downloading links to datasets. Not only that, but it's also hard to share or discover datasets. In this talk we will introduce for the first time the 'pins' package. A package designed to: pin, discover and share resources. Meaning that, you can use 'pins' to simplify your data science workflows by easily fetching resources from GitHub, Kaggle, CRAN and RStudio Connect. We will present a 'pin' as a generic resource that can contain tabular datasets like CSVs, unstructured data like JSON files, image archives as ZIP files and so on. This talk will be highly interactive showing you how to get started by installing 'pins' from CRAN, retrieve and cache resources, share and discover useful and fun data resources to improve and enhance your day-to-day workflows.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1202,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"2d5709df-4584-46f9-9e14-aefce656db42":{"speakerId":"2d5709df-4584-46f9-9e14-aefce656db42","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d98ac3da-c488-470f-ab68-1a311a2fc728"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Open source code is an essential piece in making science reproducible. Tools like 'rmarkdown' and GitHub facilitate running and sharing outcomes with colleagues and with the broad scientific community at large. However, it is less clear what tools should be used to retrieve, store and share datasets; while it is possible to make datasets part of your workflows today, it is usually hard and we are often left with manually sharing or downloading links to datasets. Not only that, but it's also hard to share or discover datasets. In this talk we will introduce for the first time the 'pins' package. A package designed to: pin, discover and share resources. Meaning that, you can use 'pins' to simplify your data science workflows by easily fetching resources from GitHub, Kaggle, CRAN and RStudio Connect. We will present a 'pin' as a generic resource that can contain tabular datasets like CSVs, unstructured data like JSON files, image archives as ZIP files and so on. This talk will be highly interactive showing you how to get started by installing 'pins' from CRAN, retrieve and cache resources, share and discover useful and fun data resources to improve and enhance your day-to-day workflows.</span></p>\r\n</div></div>","id":"d98ac3da-c488-470f-ab68-1a311a2fc728","capacityId":"d98ac3da-c488-470f-ab68-1a311a2fc728","name":"Datasets in Reproducible Research with 'pins'","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"d6f33f06-1b40-4d6b-9c16-4719c3987023":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"d6f33f06-1b40-4d6b-9c16-4719c3987023_waitlist","startTime":"2020-01-30T22:55:00.000Z","endTime":"2020-01-30T23:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"fhi2t\",\"text\":\"In this talk, I will introduce a suite of three packages designed to aid course material creation in R: {demoR} for displaying code in knitted R Markdown with custom highlighting and formatting; {shindig} for shortcuts to creating simple educational Shiny apps; and {curricular} for easy creation of syllabi, homework exercises, exams, etc. Together, we will explore how these new tools - in conjunction with other existing resources - have been used to create a clean and consistent ecosystem for my R-based Introductory Statistics course. I will share some metrics on student outcomes, as well as my own experiences with the advantages and challenges in building the course.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":676,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"c93fc245-6167-45dd-afbe-55fd9d63492f":{"speakerId":"c93fc245-6167-45dd-afbe-55fd9d63492f","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"d6f33f06-1b40-4d6b-9c16-4719c3987023"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In this talk, I will introduce a suite of three packages designed to aid course material creation in R: {demoR} for displaying code in knitted R Markdown with custom highlighting and formatting; {shindig} for shortcuts to creating simple educational Shiny apps; and {curricular} for easy creation of syllabi, homework exercises, exams, etc. Together, we will explore how these new tools - in conjunction with other existing resources - have been used to create a clean and consistent ecosystem for my R-based Introductory Statistics course. I will share some metrics on student outcomes, as well as my own experiences with the advantages and challenges in building the course.</span></p>\r\n</div></div>","id":"d6f33f06-1b40-4d6b-9c16-4719c3987023","capacityId":"d6f33f06-1b40-4d6b-9c16-4719c3987023","name":"Course Material Creation in the R Ecosystem","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"9e699e37-317e-4094-8180-ee8088894a8f":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"9e699e37-317e-4094-8180-ee8088894a8f_waitlist","startTime":"2020-01-30T22:55:00.000Z","endTime":"2020-01-30T23:00:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"13chf\",\"text\":\"Blogging is an excellent way to learn, improve your communication skills, and gain exposure in the R and data science communities. In this talk, I will discuss how and why I started blogging, and why you should too. I will guide you through choosing topics, writing your blog using RStudio and blogdown, hosting it on netlify, and sharing your blog with the world. This talk is for you if you've wanted to start a blog on R, data science, or to showcase your data analyses, but don't know where to start.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":504,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"f32327f3-a71b-488d-aaf4-9aae4f5c4419":{"speakerId":"f32327f3-a71b-488d-aaf4-9aae4f5c4419","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"9e699e37-317e-4094-8180-ee8088894a8f"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Blogging is an excellent way to learn, improve your communication skills, and gain exposure in the R and data science communities. In this talk, I will discuss how and why I started blogging, and why you should too. I will guide you through choosing topics, writing your blog using RStudio and blogdown, hosting it on netlify, and sharing your blog with the world. This talk is for you if you've wanted to start a blog on R, data science, or to showcase your data analyses, but don't know where to start.</span></p>\r\n</div></div>","id":"9e699e37-317e-4094-8180-ee8088894a8f","capacityId":"9e699e37-317e-4094-8180-ee8088894a8f","name":"Becoming an R blogger","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"b4794b73-bf31-4c8f-8d4a-f3459a6b048c":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"b4794b73-bf31-4c8f-8d4a-f3459a6b048c_waitlist","startTime":"2020-01-30T23:00:00.000Z","endTime":"2020-01-30T23:05:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"rgi3\",\"text\":\"The software engineering world is full of claims about best practices, languages, packages, styles, and workflows, but most software engineering students are never taught how to find, read, and interpret actual evidence on those topics. Is agile development really the secret to success? Do some languages actually cause more defects than others? This talk describes a series of meaningful lessons that explore research in software engineering for the beginner R programmer by teaching students to interpret and replicate research findings while learning meaningful results for their field in addition to common statistical methods. The lessons serve as a primer for software engineers to participate in a data-driven society; from advertising and business to combating misinformation and helping user experience.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":813,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"052287fa-220b-4c6a-8598-266eb9c53ebf":{"speakerId":"052287fa-220b-4c6a-8598-266eb9c53ebf","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"b4794b73-bf31-4c8f-8d4a-f3459a6b048c"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">The software engineering world is full of claims about best practices, languages, packages, styles, and workflows, but most software engineering students are never taught how to find, read, and interpret actual evidence on those topics. Is agile development really the secret to success? Do some languages actually cause more defects than others? This talk describes a series of meaningful lessons that explore research in software engineering for the beginner R programmer by teaching students to interpret and replicate research findings while learning meaningful results for their field in addition to common statistical methods. The lessons serve as a primer for software engineers to participate in a data-driven society; from advertising and business to combating misinformation and helping user experience.</span></p>\r\n</div></div>","id":"b4794b73-bf31-4c8f-8d4a-f3459a6b048c","capacityId":"b4794b73-bf31-4c8f-8d4a-f3459a6b048c","name":"Data Science for Software Engineers: busting software myths with R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"e4dba08a-1902-4187-a5aa-0a5975079248":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"e4dba08a-1902-4187-a5aa-0a5975079248_waitlist","startTime":"2020-01-30T23:00:00.000Z","endTime":"2020-01-30T23:05:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"42ltt\",\"text\":\"In Mexico the elections take place on a Sunday, and the official results are presented a week later. To prevent unjustified victory claims during that period the electoral authority organizes a quick count the same night of the election. The quick count consists in selecting a random sample of the polling stations and estimating the percentage of votes in favor of each candidate. With highly competitive electoral processes the quick count has become very important, the rapidity and precision of its results auspicious an environment of trust, and it serves as a tool against fraud. In this application reproducibility is very important. On the scientific side, it is crucial to examine the veracity and robustness of the conclusions of the methodologies. However, in this case, reproducibility is more important still, as it helps to achieve transparency in the electoral procedure. Anyone can download the sample and compute the same results that were announced the night of the election. This transparency fosters trust in institutions and gives legitimacy to the outcome of the quick count. We believe that developing an R package with detailed vignettes made the procedure accessible for the public. The package also facilitated code development and estimation on the election night, when the models were run with partial samples every five minutes, for three different state elections and for the presidential election. Our models were one of 9 different approaches to do the estimation and yet our code is the only publicly available, we are championing for more openness on procedures by sharing our experience. As for the model we developed Bayesian hierarchical models that include demographic and geographic covariates, the purpose of the models is to reduce the biases associated to such covariates due to the fact that complete samples are rarely available to publish the results in a timely manner hence the results are announced using partial samples which have biases.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1988,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"10d0509e-2780-4828-b1c1-bb7d95965249":{"speakerId":"10d0509e-2780-4828-b1c1-bb7d95965249","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"e4dba08a-1902-4187-a5aa-0a5975079248"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In Mexico the elections take place on a Sunday, and the official results are presented a week later. To prevent unjustified victory claims during that period the electoral authority organizes a quick count the same night of the election. The quick count consists in selecting a random sample of the polling stations and estimating the percentage of votes in favor of each candidate. With highly competitive electoral processes the quick count has become very important, the rapidity and precision of its results auspicious an environment of trust, and it serves as a tool against fraud. In this application reproducibility is very important. On the scientific side, it is crucial to examine the veracity and robustness of the conclusions of the methodologies. However, in this case, reproducibility is more important still, as it helps to achieve transparency in the electoral procedure. Anyone can download the sample and compute the same results that were announced the night of the election. This transparency fosters trust in institutions and gives legitimacy to the outcome of the quick count. We believe that developing an R package with detailed vignettes made the procedure accessible for the public. The package also facilitated code development and estimation on the election night, when the models were run with partial samples every five minutes, for three different state elections and for the presidential election. Our models were one of 9 different approaches to do the estimation and yet our code is the only publicly available, we are championing for more openness on procedures by sharing our experience. As for the model we developed Bayesian hierarchical models that include demographic and geographic covariates, the purpose of the models is to reduce the biases associated to such covariates due to the fact that complete samples are rarely available to publish the results in a timely manner hence the results are announced using partial samples which have biases.</span></p>\r\n</div></div>","id":"e4dba08a-1902-4187-a5aa-0a5975079248","capacityId":"e4dba08a-1902-4187-a5aa-0a5975079248","name":"Mexican electoral quick count night with R","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1_waitlist","startTime":"2020-01-30T23:05:00.000Z","endTime":"2020-01-30T23:10:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"elh18\",\"text\":\"Even though I’ve completed 4 marathons, you certainly shouldn’t come to me for a training plan on how to achieve your goals for any race you’re about to run. So why do we often turn to “experienced R users” to help us learn R or train an organization? The RStudio certified trainers have been taught modern, evidence-based teaching practices which they use in planning training sessions in order to help delegates achieve THEIR learning goals effectively in a given time-frame. My talk will illustrate some of these teaching concepts and how, by becoming a certified trainer, you can help others learn about R more effectively.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":627,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"41dac1bc-80df-4111-b44c-1ec2887e4fa2":{"speakerId":"41dac1bc-80df-4111-b44c-1ec2887e4fa2","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Even though I’ve completed 4 marathons, you certainly shouldn’t come to me for a training plan on how to achieve your goals for any race you’re about to run. So why do we often turn to “experienced R users” to help us learn R or train an organization? The RStudio certified trainers have been taught modern, evidence-based teaching practices which they use in planning training sessions in order to help delegates achieve THEIR learning goals effectively in a given time-frame. My talk will illustrate some of these teaching concepts and how, by becoming a certified trainer, you can help others learn about R more effectively.</span></p>\r\n</div></div>","id":"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1","capacityId":"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1","name":"Learn to teach, for goodness sake.","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"225f8bda-d991-4d46-b67f-e7bb69c40af3":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"225f8bda-d991-4d46-b67f-e7bb69c40af3_waitlist","startTime":"2020-01-30T23:05:00.000Z","endTime":"2020-01-30T23:10:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"rj9d\",\"text\":\"Many teams and organizations have tasks and structures that are standard across projects. Lack of consistency and documentation can lead to lost productivity when team members join collaborations or previous work is consulted by your future self. Setting up folder structures can be particularly tedious. This talk will demonstrate using Rstudio project templates as part of an organizational package to automatically setup file structures, establish git repositories and add standardized readme files. It will also show how including report templates for Rmarkdown files can lead to more consistent and professional reports. Project info can be optionally stored so that project information can be easily added automatically to the top of reports and included in snippets for code file headers. Creating standard, easy to implement documentation and procedures can be particularly effective in encouraging skeptical collaborators to use git and Rmarkdown. Organizational packages can also be a great place to house functions that are specific and common to an organizations needs. The talk will showcase this functionality using the CIDAtools package that we developed. While the CIDAtools package was developed to address issues that sometimes arise from the less structured environment of academia, the tools presented can be equally useful in an industry setting.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1367,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"799d743b-9c68-464d-ad55-2b3e5a98399c":{"speakerId":"799d743b-9c68-464d-ad55-2b3e5a98399c","speakerCategoryId":"4d782f1f-021e-4c86-a902-deb06dd7d9ee","sessionId":"225f8bda-d991-4d46-b67f-e7bb69c40af3"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Many teams and organizations have tasks and structures that are standard across projects. Lack of consistency and documentation can lead to lost productivity when team members join collaborations or previous work is consulted by your future self. Setting up folder structures can be particularly tedious. This talk will demonstrate using Rstudio project templates as part of an organizational package to automatically setup file structures, establish git repositories and add standardized readme files. It will also show how including report templates for Rmarkdown files can lead to more consistent and professional reports. Project info can be optionally stored so that project information can be easily added automatically to the top of reports and included in snippets for code file headers. Creating standard, easy to implement documentation and procedures can be particularly effective in encouraging skeptical collaborators to use git and Rmarkdown. Organizational packages can also be a great place to house functions that are specific and common to an organizations needs. The talk will showcase this functionality using the CIDAtools package that we developed. While the CIDAtools package was developed to address issues that sometimes arise from the less structured environment of academia, the tools presented can be equally useful in an industry setting.</span></p>\r\n</div></div>","id":"225f8bda-d991-4d46-b67f-e7bb69c40af3","capacityId":"225f8bda-d991-4d46-b67f-e7bb69c40af3","name":"Rproject templates to automate and standardize your workflow","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"c6593c42-1a58-48ca-bb19-2816cc125e99":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"c6593c42-1a58-48ca-bb19-2816cc125e99_waitlist","startTime":"2020-01-30T23:10:00.000Z","endTime":"2020-01-30T23:15:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"e1pfi\",\"text\":\"I host a weekly R Office Hour on the R4DS Online Learning Community Slack. By doing so, I have learned more about R than I ever would have thought. Here I'll present concrete examples of how R users can participate in the R community to expand their skills. R users of all skill levels can develop their skills by helping one another learn. Committing to help people with their coding challenges leads to exploration of answers in areas you might otherwise not examine.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":469,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"6a6fff1a-ab45-4b12-9278-7657a09577cc":{"speakerId":"6a6fff1a-ab45-4b12-9278-7657a09577cc","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"c6593c42-1a58-48ca-bb19-2816cc125e99"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">I host a weekly R Office Hour on the R4DS Online Learning Community Slack. By doing so, I have learned more about R than I ever would have thought. Here I'll present concrete examples of how R users can participate in the R community to expand their skills. R users of all skill levels can develop their skills by helping one another learn. Committing to help people with their coding challenges leads to exploration of answers in areas you might otherwise not examine.</span></p>\r\n</div></div>","id":"c6593c42-1a58-48ca-bb19-2816cc125e99","capacityId":"c6593c42-1a58-48ca-bb19-2816cc125e99","name":"Learning by Teaching: Mentoring at the R4DS Online Learning Community","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"0fa64705-d9f8-43f1-849a-14189afe0d41":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"0fa64705-d9f8-43f1-849a-14189afe0d41_waitlist","startTime":"2020-01-30T23:10:00.000Z","endTime":"2020-01-30T23:15:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"au1lo\",\"text\":\"We observed a huge improvements of Machine Learning tools but the main effort were to help at post annotated dataset step. We still struggle to build a trusty pipeline to make these annotations. The package wavesurfer brings to R users the ability to annotate audio files with ease and reliability, exploring the friendly user interface of Shiny to make this hard and laborious part of the project more joyful and efficient.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":424,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"41fd527f-6e3d-46db-96d8-ce8a24c01d5c":{"speakerId":"41fd527f-6e3d-46db-96d8-ce8a24c01d5c","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"0fa64705-d9f8-43f1-849a-14189afe0d41"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">We observed a huge improvements of Machine Learning tools but the main effort were to help at post annotated dataset step. We still struggle to build a trusty pipeline to make these annotations. The package wavesurfer brings to R users the ability to annotate audio files with ease and reliability, exploring the friendly user interface of Shiny to make this hard and laborious part of the project more joyful and efficient.</span></p>\r\n</div></div>","id":"0fa64705-d9f8-43f1-849a-14189afe0d41","capacityId":"0fa64705-d9f8-43f1-849a-14189afe0d41","name":"Sound annotation with Shiny and wavesurfer","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd_waitlist","startTime":"2020-01-30T23:15:00.000Z","endTime":"2020-01-30T23:20:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"fhruj\",\"text\":\"As a rotating curation, @WeAreRLadies is a twitter account that has a different curator (i.e., tweeter) each week with a mission to highlight female and minority genders and their work in R. So far, curators have tweeted from 18 different countries and represent a variety of domains and levels of R expertise, ranging from R novices to those developing their own packages. With 45 R-Ladies curators to date, the account has become a popular R-related twitter resource, gaining more than 13,000 followers in the past year and hundreds of interactions each week. This talk will present a text analysis and reflection on over a year of Twitter text data from @WeAreRLadies. As the founder and maintainer of this account, I witness firsthand the bidirectional relationship between one’s learning journey and their use of R. In this talk, I will attempt to quantify this through a text analysis that explores how one’s experiences learning and using R relates to how they talk (or tweet) about it. By analyzing tweet text as well as other metrics provided by twitter (e.g., number of likes, replies, and clicks), I will showcase different ways curators have engaged with the R Twitter community and explore how account engagement has changed as the number of curators and followers continue to grow. I will also discuss how curators’ different areas of expertise have resulted in tweets and discussions that both demonstrate the variety of tools available in R, and spotlight unifying ideas and best practices in R programming. Finally, I will reflect on lessons learned and future directions for @WeAreRLadies, as well as its contribution to the R-Ladies Global initiative. Overall, this talk will discuss how diverse perspectives of @WeAreRLadies curators have enriched the conversations in the R Twitter community by validating different learning journeys and by promoting and amplifying underrepresented voices.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1911,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"3561599d-1f5d-484e-a4c4-174638fb4fef":{"speakerId":"3561599d-1f5d-484e-a4c4-174638fb4fef","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">As a rotating curation, @WeAreRLadies is a twitter account that has a different curator (i.e., tweeter) each week with a mission to highlight female and minority genders and their work in R. So far, curators have tweeted from 18 different countries and represent a variety of domains and levels of R expertise, ranging from R novices to those developing their own packages. With 45 R-Ladies curators to date, the account has become a popular R-related twitter resource, gaining more than 13,000 followers in the past year and hundreds of interactions each week. This talk will present a text analysis and reflection on over a year of Twitter text data from @WeAreRLadies. As the founder and maintainer of this account, I witness firsthand the bidirectional relationship between one’s learning journey and their use of R. In this talk, I will attempt to quantify this through a text analysis that explores how one’s experiences learning and using R relates to how they talk (or tweet) about it. By analyzing tweet text as well as other metrics provided by twitter (e.g., number of likes, replies, and clicks), I will showcase different ways curators have engaged with the R Twitter community and explore how account engagement has changed as the number of curators and followers continue to grow. I will also discuss how curators’ different areas of expertise have resulted in tweets and discussions that both demonstrate the variety of tools available in R, and spotlight unifying ideas and best practices in R programming. Finally, I will reflect on lessons learned and future directions for @WeAreRLadies, as well as its contribution to the R-Ladies Global initiative. Overall, this talk will discuss how diverse perspectives of @WeAreRLadies curators have enriched the conversations in the R Twitter community by validating different learning journeys and by promoting and amplifying underrepresented voices.</span></p>\r\n</div></div>","id":"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd","capacityId":"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd","name":"Every voice matters: An analysis of @WeAreRLadies","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"5d786f67-72c4-4ae9-b056-22d95922b4d2":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"5d786f67-72c4-4ae9-b056-22d95922b4d2_waitlist","startTime":"2020-01-30T23:15:00.000Z","endTime":"2020-01-30T23:20:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7caiv\",\"text\":\"Peer review enables instructors of large data science classes to provide substantive feedback to students beyond what is feasible with standard code review via automated grading and continuous integration. It facilitates peer learning, which is shown in literature to have positive learning outcomes, and can reduce the burden of grading by course staff. The ghclass package provides a suite of functions to manage courses via GitHub repositories. The package has recently been supplemented with the functionality to implement peer review. Developed during my 2019 summer internship with RStudio in collaboration with my mentor Mine Çetinkaya-Rundel, the peer review functions in ghclass interface with the GitHub API to create review repositories, move files between authors and reviewers, submit feedback, and collect grades. In this presentation, I will give a demonstration of the peer review functions in ghclass. A set of six functions allows instructors to 1) create a random review roster, 2) set up the review repository infrastructure within a GitHub organization, 3) move assignments from authors to reviewers, 4) collect grades, 5) return the feedback, and 6) obtain a rating of the review from the authors. I reflect on the pedagogy of implementing peer review in introductory data science classes and talk about lessons learned from a real-world test run of the package in the Fall semester 2019 at the University of Edinburgh, conducted by Mine Çetinkaya-Rundel. The presentation highlights ghclass as an R command-line based, open source, low profile, and powerful solution to enable peer review in classes ranging from a size of two to approximately 400 students.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1680,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"a14c16b0-611f-480a-8cf9-470ac0979362":{"speakerId":"a14c16b0-611f-480a-8cf9-470ac0979362","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"5d786f67-72c4-4ae9-b056-22d95922b4d2"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Peer review enables instructors of large data science classes to provide substantive feedback to students beyond what is feasible with standard code review via automated grading and continuous integration. It facilitates peer learning, which is shown in literature to have positive learning outcomes, and can reduce the burden of grading by course staff. The ghclass package provides a suite of functions to manage courses via GitHub repositories. The package has recently been supplemented with the functionality to implement peer review. Developed during my 2019 summer internship with RStudio in collaboration with my mentor Mine Çetinkaya-Rundel, the peer review functions in ghclass interface with the GitHub API to create review repositories, move files between authors and reviewers, submit feedback, and collect grades. In this presentation, I will give a demonstration of the peer review functions in ghclass. A set of six functions allows instructors to 1) create a random review roster, 2) set up the review repository infrastructure within a GitHub organization, 3) move assignments from authors to reviewers, 4) collect grades, 5) return the feedback, and 6) obtain a rating of the review from the authors. I reflect on the pedagogy of implementing peer review in introductory data science classes and talk about lessons learned from a real-world test run of the package in the Fall semester 2019 at the University of Edinburgh, conducted by Mine Çetinkaya-Rundel. The presentation highlights ghclass as an R command-line based, open source, low profile, and powerful solution to enable peer review in classes ranging from a size of two to approximately 400 students.</span></p>\r\n</div></div>","id":"5d786f67-72c4-4ae9-b056-22d95922b4d2","capacityId":"5d786f67-72c4-4ae9-b056-22d95922b4d2","name":"Peer review in data science courses","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"247af970-1756-499b-923a-c688658f2b37":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"247af970-1756-499b-923a-c688658f2b37_waitlist","startTime":"2020-01-30T23:20:00.000Z","endTime":"2020-01-30T23:25:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"7183f\",\"text\":\"In this talk, I will outline a unified philosophy of data science education, and provide tips and tools for implementing these principles in the classroom using R and RStudio. Although data science as a professional discipline is well-established, its pedagogy is still in a period of growth. Even within a single university, multiple data science courses may be offered across different departments leading to inevitable redundancy of efforts amidst rich domain-specific innovations. My experience as an instructor in many such courses has lead me to five principles that transcend domain, context, and choice of language: reproducibility, communication, version control, practical application, and data ethics. For each of these full-stack themes, I will share examples of how to leverage tools in R and RStudio to enhance learning.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":834,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"9c56b5ea-d63c-4736-8e54-fb1823a8daf4":{"speakerId":"9c56b5ea-d63c-4736-8e54-fb1823a8daf4","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"247af970-1756-499b-923a-c688658f2b37"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In this talk, I will outline a unified philosophy of data science education, and provide tips and tools for implementing these principles in the classroom using R and RStudio. Although data science as a professional discipline is well-established, its pedagogy is still in a period of growth. Even within a single university, multiple data science courses may be offered across different departments leading to inevitable redundancy of efforts amidst rich domain-specific innovations. My experience as an instructor in many such courses has lead me to five principles that transcend domain, context, and choice of language: reproducibility, communication, version control, practical application, and data ethics. For each of these full-stack themes, I will share examples of how to leverage tools in R and RStudio to enhance learning.</span></p>\r\n</div></div>","id":"247af970-1756-499b-923a-c688658f2b37","capacityId":"247af970-1756-499b-923a-c688658f2b37","name":"The Five Principles of Data Science Education","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"3b5ecb40-f46d-4275-95df-acdba038b2e0":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"3b5ecb40-f46d-4275-95df-acdba038b2e0_waitlist","startTime":"2020-01-30T23:20:00.000Z","endTime":"2020-01-30T23:25:00.000Z","locationName":"Room 3","locationCode":"Room 31574418071836","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"cojeb\",\"text\":\"Forming good development habits for R projects is pretty straight-forward if you follow the lessons I've learned from my cat, whose advice includes \\\"be lazy\\\", \\\"keep your claws sharp\\\", and \\\"land on your feet\\\". Attendees of this talk will learn how to make life easier on colleagues and their future selves by using simple software engineering best practices to build their current projects. Each point will come with cat photos and code samples, the two best parts of the Internet!\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":480,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"51dea1d2-341c-47a1-be87-7af1080be903":{"speakerId":"51dea1d2-341c-47a1-be87-7af1080be903","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"3b5ecb40-f46d-4275-95df-acdba038b2e0"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">Forming good development habits for R projects is pretty straight-forward if you follow the lessons I've learned from my cat, whose advice includes \"be lazy\", \"keep your claws sharp\", and \"land on your feet\". Attendees of this talk will learn how to make life easier on colleagues and their future selves by using simple software engineering best practices to build their current projects. Each point will come with cat photos and code samples, the two best parts of the Internet!</span></p>\r\n</div></div>","id":"3b5ecb40-f46d-4275-95df-acdba038b2e0","capacityId":"3b5ecb40-f46d-4275-95df-acdba038b2e0","name":"Lessons about R I learned from my cat","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"58e23df9-0db8-4c65-a10d-bdb74c5a25b6":{"categoryId":"583522d1-1b71-4aaa-a3ae-e78dcd13a40e","waitlistCapacityId":"58e23df9-0db8-4c65-a10d-bdb74c5a25b6_waitlist","startTime":"2020-01-30T23:25:00.000Z","endTime":"2020-01-30T23:30:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"8v1a4\",\"text\":\"As an intern at RStudio, I developed a blocks-based coding language mimicking the verb-driven programming of the tidyverse. Blocks-based coding environments are a popular way to introduce programming to novices. Instead of typing in code, users click blocks together to create loops, conditionals, and expressions. Studies have shown that students are more successful and more interested in coding when introduced through a block-based language like Scratch or Snap! rather than a text-based language. However, it's much easier to express control flow with these tools than to manipulate data: adding 1 to a variable requires several steps, and there are no built-in capabilities for working with tabular data. On the other hand, R's tidyverse libraries provide a predictable, consistent grammar for doing these tasks. As an intern at RStudio, I developed a blocks-based coding language mimicking the verb driven programming of the tidyverse. Tabular data can be imported and transformed using verbs like filter, select, and summarize, and functions can be strung together using pipes, which users can think of as meaning \\\"and then\\\". The talk will include a demo of TidyBlocks and a description of how we're testing and improving it.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":1233,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"bd836ef6-064f-4cae-8c47-b6cb5da21507":{"speakerId":"bd836ef6-064f-4cae-8c47-b6cb5da21507","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"58e23df9-0db8-4c65-a10d-bdb74c5a25b6"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">As an intern at RStudio, I developed a blocks-based coding language mimicking the verb-driven programming of the tidyverse. Blocks-based coding environments are a popular way to introduce programming to novices. Instead of typing in code, users click blocks together to create loops, conditionals, and expressions. Studies have shown that students are more successful and more interested in coding when introduced through a block-based language like Scratch or Snap! rather than a text-based language. However, it's much easier to express control flow with these tools than to manipulate data: adding 1 to a variable requires several steps, and there are no built-in capabilities for working with tabular data. On the other hand, R's tidyverse libraries provide a predictable, consistent grammar for doing these tasks. As an intern at RStudio, I developed a blocks-based coding language mimicking the verb driven programming of the tidyverse. Tabular data can be imported and transformed using verbs like filter, select, and summarize, and functions can be strung together using pipes, which users can think of as meaning \"and then\". The talk will include a demo of TidyBlocks and a description of how we're testing and improving it.</span></p>\r\n</div></div>","id":"58e23df9-0db8-4c65-a10d-bdb74c5a25b6","capacityId":"58e23df9-0db8-4c65-a10d-bdb74c5a25b6","name":"TidyBlocks: using the language of the tidyverse in a blocks-based interface","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd":{"categoryId":"c32f17f6-2464-476b-859b-d8ab4d26556b","waitlistCapacityId":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd_waitlist","startTime":"2020-01-31T00:00:00.000Z","endTime":"2020-01-31T01:00:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"richTextDescription":"{\"format\":\"draftjs-nucleus\",\"version\":1,\"content\":{\"blocks\":[{\"key\":\"egjdr\",\"text\":\"In episode 100 of Not So Standard Deviations, the first ever episode prepared in advance, Hilary and Roger discuss creativity, its role in data science, and how it can be fostered through conversation. Also, follow up on coffee and oat milk.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"offset\":0,\"length\":241,\"style\":\"color-rgb(0,0,0)\"}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}}","displayPriority":0,"showOnAgenda":true,"speakerIds":{"a30e5247-4c3a-4463-8e00-1aed04a3377b":{"speakerId":"a30e5247-4c3a-4463-8e00-1aed04a3377b","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd"},"13e03b25-f230-47b7-8661-ff4a2ca7e7d1":{"speakerId":"13e03b25-f230-47b7-8661-ff4a2ca7e7d1","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd"}},"code":"","description":"<div class=\"ag87-crtemvc-hsbk\"><div class=css-zuif4x><p class=\"carina-rte-public-DraftStyleDefault-block\"><span style=\"color: rgb(0,0,0);\">In episode 100 of Not So Standard Deviations, the first ever episode prepared in advance, Hilary and Roger discuss creativity, its role in data science, and how it can be fostered through conversation. Also, follow up on coffee and oat milk.</span></p>\r\n</div></div>","id":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd","capacityId":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd","name":"NSSD Episode 100","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"},"15f13b56-fac6-4dfa-ba14-f5168917d79c":{"categoryId":"00000000-0000-0000-0000-000000000000","waitlistCapacityId":"15f13b56-fac6-4dfa-ba14-f5168917d79c_waitlist","startTime":"2020-01-31T01:00:00.000Z","endTime":"2020-01-31T01:05:00.000Z","locationName":"Room 2","locationCode":"Room 21578074754834","isOpenForRegistration":true,"isIncludedSession":false,"isWaitlistEnabled":false,"associatedRegistrationTypes":[],"sessionCustomFieldValues":{},"displayPriority":0,"showOnAgenda":true,"speakerIds":{"94513fe9-5def-41c2-9cb0-022850f30285":{"speakerId":"94513fe9-5def-41c2-9cb0-022850f30285","speakerCategoryId":"86502b84-9704-4416-baf2-ec9edc15fd4f","sessionId":"15f13b56-fac6-4dfa-ba14-f5168917d79c"}},"code":"","description":"","id":"15f13b56-fac6-4dfa-ba14-f5168917d79c","capacityId":"15f13b56-fac6-4dfa-ba14-f5168917d79c","name":"Wrap up","status":2,"type":"Session","defaultFeeId":"00000000-0000-0000-0000-000000000000","fees":{},"closedReasonType":"NotClosed"}},"sortKeys":{"cf7b4ef5-4280-414e-9389-7d23eb8c0367":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"81b467b6-5239-4f3a-b67a-d8f58d33efbc":["2020-01-29 00:00:00:000","11:30","0000000000","Case Study","9223372036854775807"],"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d":["2020-01-29 00:00:00:000","12:39","0000000000","Education","9223372036854775807"],"31bb43be-554e-4488-81b3-8e07c7ba33c9":["2020-01-30 00:00:00:000","13:00","0000000000","Organizational Thinking","9223372036854775807"],"23235ff7-392d-430f-802c-4b4c849c8d0f":["2020-01-29 00:00:00:000","15:01","0000000000","Interface","9223372036854775807"],"895592d5-b93e-487c-bcde-e033b9367411":["2020-01-30 00:00:00:000","14:45","0000000000","Lightning Talks","9223372036854775807"],"f6bc2b7a-ea99-4778-a513-9659f50c9d68":["2020-01-29 00:00:00:000","12:39","0000000000","Programming","9223372036854775807"],"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd":["2020-01-30 00:00:00:000","15:15","0000000000","Lightning Talks","9223372036854775807"],"c6593c42-1a58-48ca-bb19-2816cc125e99":["2020-01-30 00:00:00:000","15:10","0000000000","Lightning Talks","9223372036854775807"],"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be":["2020-01-30 00:00:00:000","13:23","0000000000","Organizational Thinking","9223372036854775807"],"66b0d4a2-35ec-44be-92f2-ab8272ee34cf":["2020-01-30 00:00:00:000","13:46","0000000000","ggplot2","9223372036854775807"],"362fca53-0b9d-462c-b702-ea85c9ea10b2":["2020-01-29 00:00:00:000","09:05","0000000000","Keynote","9223372036854775807"],"15f13b56-fac6-4dfa-ba14-f5168917d79c":["2020-01-30 00:00:00:000","17:00","2147483647","","9223372036854775807"],"9ba940f7-ec0d-432f-8357-73ec0f0a31de":["2020-01-30 00:00:00:000","10:30","0000000000","Communication","9223372036854775807"],"0455609a-cf61-44d1-a95b-3b97080c32a4":["2020-01-29 00:00:00:000","15:01","0000000000","Community","9223372036854775807"],"1a28b485-9971-4c62-ac32-6603f7a6ce35":["2020-01-29 00:00:00:000","11:30","0000000000","Education","9223372036854775807"],"d8acadca-5e06-49b9-8372-ac0ef1c9a74e":["2020-01-30 00:00:00:000","11:39","0000000000","Medicine","9223372036854775807"],"5de2683c-bb4d-46b5-8415-24556b46d105":["2020-01-28 00:00:00:000","09:00","0000000000","1 Day Workshop","9223372036854775807"],"6ad3db7d-89ab-4c72-aeac-e228ce58098e":["2020-01-30 00:00:00:000","14:09","0000000000","Programming","9223372036854775807"],"b8e20e44-a193-494a-9ee7-4183d4bfa583":["2020-01-29 00:00:00:000","15:01","0000000000","Shiny","9223372036854775807"],"b6430542-cb37-4d31-8371-42ad803918ca":["2020-01-29 00:00:00:000","12:16","0000000000","Education","9223372036854775807"],"c49e47f4-0a47-4934-b786-ab914840a460":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"fd78d01e-f85c-458d-9e47-b65bc02cc1a9":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"4b9a8f5f-7916-4232-86ea-ba308cb61bbf":["2020-01-30 00:00:00:000","14:09","0000000000","ggplot2","9223372036854775807"],"914fa687-23c1-45ae-8a2f-fa5889cc9f20":["2020-01-29 00:00:00:000","16:00","0000000000","Case Study","9223372036854775807"],"6ebe4d66-1a7e-4f69-9665-204c61f9d920":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"ac2b3992-fbfc-45d1-ac8a-8946719b5bfc":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"89a098cc-e64c-478d-815f-77acab171676":["2020-01-29 00:00:00:000","16:00","0000000000","Pharma","9223372036854775807"],"5fec742c-53f3-45b6-8c87-ff4bad5e5257":["2020-01-29 00:00:00:000","12:16","0000000000","Programming","9223372036854775807"],"38bfec49-eddf-47aa-8d13-659296f7d8b4":["2020-01-29 00:00:00:000","17:09","0000000000","Pharma","9223372036854775807"],"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae":["2020-01-30 00:00:00:000","14:50","0000000000","Lightning Talks","9223372036854775807"],"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1":["2020-01-30 00:00:00:000","15:05","0000000000","Lightning Talks","9223372036854775807"],"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd":["2020-01-30 00:00:00:000","16:00","0000000000","Keynote","9223372036854775807"],"c003961a-ff90-4665-9abb-e663485b7826":["2020-01-29 00:00:00:000","17:09","0000000000","Case Study","9223372036854775807"],"5d786f67-72c4-4ae9-b056-22d95922b4d2":["2020-01-30 00:00:00:000","15:15","0000000000","Lightning Talks","9223372036854775807"],"a556e0c4-c3d8-41b7-a947-bd1f291b77f0":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"08421d97-b1e7-4db0-9de2-5701d84c9662":["2020-01-30 00:00:00:000","10:53","0000000000","Workflow","9223372036854775807"],"430f24c8-2860-4158-840c-49198318dfa2":["2020-01-29 00:00:00:000","09:00","2147483647","","9223372036854775807"],"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7":["2020-01-30 00:00:00:000","13:23","0000000000","Modeling","9223372036854775807"],"d2148603-58e1-4d62-ae8a-cfc267028184":["2020-01-30 00:00:00:000","13:23","0000000000","ggplot2","9223372036854775807"],"facdb7b2-d84f-4db6-ba51-9bb39daef896":["2020-01-29 00:00:00:000","14:38","0000000000","Community","9223372036854775807"],"b4794b73-bf31-4c8f-8d4a-f3459a6b048c":["2020-01-30 00:00:00:000","15:00","0000000000","Lightning Talks","9223372036854775807"],"adc756af-1e58-459f-8a95-9f06b3b341d0":["2020-01-30 00:00:00:000","11:39","0000000000","Communication","9223372036854775807"],"dd568377-e7e0-4baf-b63e-470e13508466":["2020-01-29 00:00:00:000","11:53","0000000000","Education","9223372036854775807"],"e4dba08a-1902-4187-a5aa-0a5975079248":["2020-01-30 00:00:00:000","15:00","0000000000","Lightning Talks","9223372036854775807"],"ccae356c-f8ba-4549-ad55-5a1993a446b0":["2020-01-29 00:00:00:000","16:23","0000000000","Case Study","9223372036854775807"],"d6f33f06-1b40-4d6b-9c16-4719c3987023":["2020-01-30 00:00:00:000","14:55","0000000000","Lightning Talks","9223372036854775807"],"03d95381-eafd-47d2-9fc5-1603b17254ae":["2020-01-29 00:00:00:000","14:15","0000000000","Community","9223372036854775807"],"a401221d-297b-432f-b612-ed488632e150":["2020-01-30 00:00:00:000","13:46","0000000000","Modeling","9223372036854775807"],"4f68c74e-57cc-4ce4-b940-0730ce426b4d":["2020-01-29 00:00:00:000","11:30","0000000000","Production","9223372036854775807"],"9071622c-13bc-4f15-964a-8d3b537a248e":["2020-01-29 00:00:00:000","12:16","0000000000","Case Study","9223372036854775807"],"3b1ed201-fae3-4986-b31b-3bc0b855a881":["2020-01-29 00:00:00:000","14:38","0000000000","Finance","9223372036854775807"],"ed336435-51ae-4af8-adc0-4e755d531fca":["2020-01-29 00:00:00:000","11:53","0000000000","Case Study","9223372036854775807"],"82240a2e-0cd3-48c0-b643-6358ac8bd4f5":["2020-01-30 00:00:00:000","10:30","0000000000","Medicine","9223372036854775807"],"34e68e07-d564-4612-8025-bf112576d6a8":["2020-01-30 00:00:00:000","11:39","0000000000","Workflow","9223372036854775807"],"a63f3f87-a6e1-4f63-bc0a-adb664886871":["2020-01-29 00:00:00:000","17:09","0000000000","Programming","9223372036854775807"],"135530e9-722e-4889-9b2f-30f09bbfbdfa":["2020-01-30 00:00:00:000","13:00","0000000000","ggplot2","9223372036854775807"],"cab92973-3018-48e8-afba-7f21ce41d662":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"1b3d95dc-dbe6-4d44-9c43-7c797b4310be":["2020-01-30 00:00:00:000","14:45","0000000000","Lightning Talks","9223372036854775807"],"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67":["2020-01-30 00:00:00:000","14:09","0000000000","Organizational Thinking","9223372036854775807"],"5c780b5f-34ed-44c3-9c96-9e64637f8703":["2020-01-29 00:00:00:000","16:23","0000000000","Pharma","9223372036854775807"],"a572c454-fd91-4ed3-8609-abd06af157c4":["2020-01-29 00:00:00:000","11:53","0000000000","Production","9223372036854775807"],"d98ac3da-c488-470f-ab68-1a311a2fc728":["2020-01-30 00:00:00:000","14:50","0000000000","Lightning Talks","9223372036854775807"],"dde422a6-90a4-4afa-af7a-035a7f876737":["2020-01-29 00:00:00:000","15:24","0000000000","Finance","9223372036854775807"],"09d8197b-cb6a-4b38-a345-3bb8231d3d9f":["2020-01-29 00:00:00:000","16:23","0000000000","Programming","9223372036854775807"],"4821ea1e-a51e-47d1-b7b8-f34e50043f8c":["2020-01-30 00:00:00:000","10:30","0000000000","Workflow","9223372036854775807"],"58e23df9-0db8-4c65-a10d-bdb74c5a25b6":["2020-01-30 00:00:00:000","15:25","0000000000","Lightning Talks","9223372036854775807"],"0b879607-6d0d-4e66-8811-e8b853f79624":["2020-01-29 00:00:00:000","11:30","0000000000","Programming","9223372036854775807"],"b023451f-66c2-42c2-be21-18cd10ba3ef8":["2020-01-29 00:00:00:000","16:00","0000000000","Learning and Using R","9223372036854775807"],"e056bbd6-c45e-4d83-bfb8-6878748f9984":["2020-01-29 00:00:00:000","14:15","0000000000","Finance","9223372036854775807"],"0fa64705-d9f8-43f1-849a-14189afe0d41":["2020-01-30 00:00:00:000","15:10","0000000000","Lightning Talks","9223372036854775807"],"748ff65d-fbbb-45e0-833d-418169cddc58":["2020-01-30 00:00:00:000","10:53","0000000000","Medicine","9223372036854775807"],"225f8bda-d991-4d46-b67f-e7bb69c40af3":["2020-01-30 00:00:00:000","15:05","0000000000","Lightning Talks","9223372036854775807"],"e7677084-4afd-4f68-8ced-2b0a159f56a0":["2020-01-30 00:00:00:000","11:16","0000000000","Workflow","9223372036854775807"],"90ef231d-c201-41cb-a91e-8918c05b22d7":["2020-01-29 00:00:00:000","11:53","0000000000","Programming","9223372036854775807"],"9e699e37-317e-4094-8180-ee8088894a8f":["2020-01-30 00:00:00:000","14:55","0000000000","Lightning Talks","9223372036854775807"],"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c":["2020-01-30 00:00:00:000","11:16","0000000000","Medicine","9223372036854775807"],"577654d1-fcb3-4f67-9be3-bc46ab816ce3":["2020-01-29 00:00:00:000","12:39","0000000000","Case Study","9223372036854775807"],"4723a69d-7a95-4e44-94bf-964972e221cf":["2020-01-29 00:00:00:000","14:15","0000000000","Shiny","9223372036854775807"],"1ba2254d-cfa9-403d-9e43-bd58014f9c9b":["2020-01-30 00:00:00:000","11:16","0000000000","Visualization","9223372036854775807"],"ad815977-9392-4542-8274-f006cf237fcc":["2020-01-29 00:00:00:000","12:16","0000000000","Production","9223372036854775807"],"cbe85c76-9313-43d7-bcd3-ba4f7816526f":["2020-01-29 00:00:00:000","12:39","0000000000","Production","9223372036854775807"],"f84a21b9-ab4f-4886-90f4-42a6f5990f31":["2020-01-30 00:00:00:000","09:00","0000000000","Keynote","9223372036854775807"],"971192eb-91b7-4882-aa64-90b45dc58d1b":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"5eae945f-2285-44fb-ae67-1a9e8c74b4c6":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"8e583082-de3d-4ba0-90c7-5b0a42c0b28e":["2020-01-29 00:00:00:000","16:00","0000000000","Programming","9223372036854775807"],"f8673901-97c6-4edf-9cf7-e93d77da8fa8":["2020-01-29 00:00:00:000","16:46","0000000000","Pharma","9223372036854775807"],"247af970-1756-499b-923a-c688658f2b37":["2020-01-30 00:00:00:000","15:20","0000000000","Lightning Talks","9223372036854775807"],"bf7a9b49-cfcd-437d-a992-45359714bdff":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d":["2020-01-29 00:00:00:000","16:23","0000000000","Learning and Using R","9223372036854775807"],"d8d901d9-bdb6-4392-83a9-3ad5addbbf53":["2020-01-29 00:00:00:000","10:00","0000000000","Keynote","9223372036854775807"],"de26c627-2d43-46fe-89c9-60ae17ea97e4":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"7ae003b1-016e-4706-9dd0-60bec53ab0b4":["2020-01-29 00:00:00:000","14:38","0000000000","Interface","9223372036854775807"],"3b5ecb40-f46d-4275-95df-acdba038b2e0":["2020-01-30 00:00:00:000","15:20","0000000000","Lightning Talks","9223372036854775807"],"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9":["2020-01-29 00:00:00:000","17:09","0000000000","Learning and Using R","9223372036854775807"],"9ee77f71-184c-40e2-b7cf-c0974427749b":["2020-01-29 00:00:00:000","14:15","0000000000","Interface","9223372036854775807"],"a908e1ea-a021-4a4a-9144-539f8d21c5af":["2020-01-30 00:00:00:000","14:09","0000000000","Modeling","9223372036854775807"],"56b9aa0a-8bcc-4367-8300-1830fe7bc48e":["2020-01-30 00:00:00:000","10:30","0000000000","Visualization","9223372036854775807"],"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2":["2020-01-29 00:00:00:000","15:01","0000000000","Finance","9223372036854775807"],"f34b33b5-37c3-4873-8712-63a4c80e4a29":["2020-01-30 00:00:00:000","13:00","0000000000","Programming","9223372036854775807"],"422c5e4a-aff6-4277-bbff-71f9a34e804f":["2020-01-30 00:00:00:000","11:39","0000000000","Visualization","9223372036854775807"],"2a03d211-bb38-4617-a4c9-48ff1e9ab273":["2020-01-29 00:00:00:000","15:24","0000000000","Interface","9223372036854775807"],"5b009813-1888-4c1c-bbfc-8e9b91262b25":["2020-01-29 00:00:00:000","16:46","0000000000","Programming","9223372036854775807"],"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff":["2020-01-30 00:00:00:000","10:53","0000000000","Visualization","9223372036854775807"],"23129cb7-1186-49c3-9287-9bf9fd22b25f":["2020-01-30 00:00:00:000","13:23","0000000000","Programming","9223372036854775807"],"4ba63dde-c0aa-4d2a-8172-c839c49d7dca":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"c3b70a5f-07f8-4762-a830-3e8f9e32831a":["2020-01-29 00:00:00:000","16:46","0000000000","Learning and Using R","9223372036854775807"],"e12072bb-806d-4f62-92e1-fd1849191693":["2020-01-30 00:00:00:000","13:46","0000000000","Organizational Thinking","9223372036854775807"],"a01cabb8-3e45-451b-a13d-8904abede0c9":["2020-01-30 00:00:00:000","13:46","0000000000","Programming","9223372036854775807"],"c152e08a-9995-4eab-b1f4-c139203af0ff":["2020-01-30 00:00:00:000","10:53","0000000000","Communication","9223372036854775807"],"8a1f808a-2276-4e26-9d5f-a51c8d660b11":["2020-01-30 00:00:00:000","14:45","0000000000","Panel","9223372036854775807"],"8bfe8930-02b0-42bd-95f8-d39974cd159c":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"b68c60bd-4f3f-423b-aec5-d6fa140187fd":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"0bc552f1-b70a-439c-90cc-4f3c83b45b10":["2020-01-29 00:00:00:000","15:24","0000000000","Shiny","9223372036854775807"],"df93fafe-1d66-46be-839b-aa653ff36d4f":["2020-01-30 00:00:00:000","13:00","0000000000","Modeling","9223372036854775807"],"5ebec1c3-9bf6-411d-8339-5b00db5c200b":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"a42a7a38-4446-40ae-ac33-20f211442286":["2020-01-30 00:00:00:000","11:16","0000000000","Communication","9223372036854775807"],"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d":["2020-01-29 00:00:00:000","15:24","0000000000","Community","9223372036854775807"],"5ac2387d-4ea5-48ac-90a1-8b9333eb7592":["2020-01-29 00:00:00:000","14:38","0000000000","Shiny","9223372036854775807"],"c45f84a9-65a5-4c33-ba42-fe3a8f2291c4":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"98251367-affe-4d4f-b30a-678291d4bb50":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"a76ade59-68e4-4325-9d3b-6e7f0375af3c":["2020-01-27 00:00:00:000","09:00","0000000000","2 Day Workshop","9223372036854775807"],"ad69c123-b268-4016-b58a-57f1901bb1ab":["2020-01-29 00:00:00:000","16:46","0000000000","Case Study","9223372036854775807"]},"quantityItems":{}}